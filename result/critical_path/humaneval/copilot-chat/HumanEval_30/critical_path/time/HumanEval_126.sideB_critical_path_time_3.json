[
  {
    "status": "success",
    "task_file": "HumanEval_126.py",
    "total_cumtime_hint": 0.001577585,
    "total_tottime_sum_topk": 0.001303473,
    "top_all": [
      {
        "func": "check",
        "file": "HumanEval_126.py",
        "line": 7,
        "calls_primitive": 1,
        "calls_total": 1,
        "tottime": 7.3002e-05,
        "cumtime": 0.001577585,
        "pct_cumtime": 100.0
      },
      {
        "func": "is_sorted",
        "file": "HumanEval_126.py",
        "line": 1,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 0.000422111,
        "cumtime": 0.001504583,
        "pct_cumtime": 95.37254727954438
      },
      {
        "func": "__init__",
        "file": "__init__.py",
        "line": 599,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 0.000137591,
        "cumtime": 0.00045762600000000004,
        "pct_cumtime": 29.008009077165415
      },
      {
        "func": "update",
        "file": "__init__.py",
        "line": 673,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 9.448300000000001e-05,
        "cumtime": 0.00032003500000000004,
        "pct_cumtime": 20.286387104339862
      },
      {
        "func": "<built-in method builtins.any>",
        "file": "~",
        "line": 0,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 0.00014013,
        "cumtime": 0.00023656500000000002,
        "pct_cumtime": 14.995388521062258
      },
      {
        "func": "<built-in method builtins.isinstance>",
        "file": "~",
        "line": 0,
        "calls_primitive": 780,
        "calls_total": 780,
        "tottime": 8.9152e-05,
        "cumtime": 0.000172558,
        "pct_cumtime": 10.938111100194286
      },
      {
        "func": "<built-in method builtins.all>",
        "file": "~",
        "line": 0,
        "calls_primitive": 330,
        "calls_total": 330,
        "tottime": 9.6348e-05,
        "cumtime": 0.000165262,
        "pct_cumtime": 10.475632057860592
      },
      {
        "func": "_handle_fromlist",
        "file": "<frozen importlib._bootstrap>",
        "line": 1390,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 0.00010711100000000001,
        "cumtime": 0.00016236900000000002,
        "pct_cumtime": 10.292250496803659
      },
      {
        "func": "<genexpr>",
        "file": "HumanEval_126.py",
        "line": 4,
        "calls_primitive": 1770,
        "calls_total": 1770,
        "tottime": 9.643500000000001e-05,
        "cumtime": 9.643500000000001e-05,
        "pct_cumtime": 6.112824348608791
      },
      {
        "func": "__instancecheck__",
        "file": "<frozen abc>",
        "line": 117,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 4.711e-05,
        "cumtime": 8.340600000000001e-05,
        "pct_cumtime": 5.286941749572923
      }
    ],
    "top_ownfile": [
      {
        "func": "check",
        "file": "HumanEval_126.py",
        "line": 7,
        "calls_primitive": 1,
        "calls_total": 1,
        "tottime": 7.3002e-05,
        "cumtime": 0.001577585,
        "pct_cumtime": 100.0
      },
      {
        "func": "is_sorted",
        "file": "HumanEval_126.py",
        "line": 1,
        "calls_primitive": 390,
        "calls_total": 390,
        "tottime": 0.000422111,
        "cumtime": 0.001504583,
        "pct_cumtime": 95.37254727954438
      },
      {
        "func": "<genexpr>",
        "file": "HumanEval_126.py",
        "line": 4,
        "calls_primitive": 1770,
        "calls_total": 1770,
        "tottime": 9.643500000000001e-05,
        "cumtime": 9.643500000000001e-05,
        "pct_cumtime": 6.112824348608791
      },
      {
        "func": "<genexpr>",
        "file": "HumanEval_126.py",
        "line": 6,
        "calls_primitive": 1080,
        "calls_total": 1080,
        "tottime": 6.8914e-05,
        "cumtime": 6.8914e-05,
        "pct_cumtime": 4.3683224675691
      }
    ]
  }
]