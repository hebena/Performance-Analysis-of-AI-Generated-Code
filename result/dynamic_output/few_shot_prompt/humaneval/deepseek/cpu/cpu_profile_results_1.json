[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.1216956056872,
    "kernel_usage": 6.878802987677725,
    "cpu_runtime": 0.000885881,
    "total_runtime": 0.0004024505615234375
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 163.33748068304095,
    "kernel_usage": 5.10429627134503,
    "cpu_runtime": 6.6592e-05,
    "total_runtime": 4.076957702636719e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 199.58465139138758,
    "kernel_usage": 6.237020355980862,
    "cpu_runtime": 9.945200000000001e-05,
    "total_runtime": 4.982948303222656e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 200.27685735248616,
    "kernel_usage": 6.2586517922651925,
    "cpu_runtime": 8.642699999999999e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.04839543300974,
    "kernel_usage": 6.7515123572815545,
    "cpu_runtime": 0.00021222100000000004,
    "total_runtime": 9.822845458984375e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.51050040519485,
    "kernel_usage": 6.672203137662339,
    "cpu_runtime": 0.00015678700000000003,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.4893563268994,
    "kernel_usage": 10.109042385215606,
    "cpu_runtime": 0.00037560299999999996,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 165.9507446518519,
    "kernel_usage": 5.185960770370372,
    "cpu_runtime": 4.273100000000001e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 213.02606605603867,
    "kernel_usage": 6.6570645642512085,
    "cpu_runtime": 0.000105134,
    "total_runtime": 4.935264587402344e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.66683054779116,
    "kernel_usage": 6.208338454618474,
    "cpu_runtime": 0.000117941,
    "total_runtime": 5.936622619628906e-05
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 321.90705037794487,
    "kernel_usage": 10.059595324310777,
    "cpu_runtime": 0.0009186810000000001,
    "total_runtime": 0.0002853870391845703
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 258.97400743140497,
    "kernel_usage": 8.092937732231405,
    "cpu_runtime": 0.000149421,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 207.75093683960398,
    "kernel_usage": 6.492216776237624,
    "cpu_runtime": 5.002700000000001e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 153.23190613333335,
    "kernel_usage": 4.788497066666667,
    "cpu_runtime": 2.8496000000000003e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.58187460809245,
    "kernel_usage": 8.299433581502889,
    "cpu_runtime": 0.00010954299999999999,
    "total_runtime": 4.124641418457031e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 201.43559651073443,
    "kernel_usage": 6.294862390960451,
    "cpu_runtime": 8.500599999999999e-05,
    "total_runtime": 4.220008850097656e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.72384893024068,
    "kernel_usage": 6.241370279070021,
    "cpu_runtime": 0.017511474000000003,
    "total_runtime": 0.008767843246459961
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 363.4561893999095,
    "kernel_usage": 11.358005918747171,
    "cpu_runtime": 0.9918029970000001,
    "total_runtime": 0.27288103103637695
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 178.70126529122808,
    "kernel_usage": 5.584414540350878,
    "cpu_runtime": 0.000194282,
    "total_runtime": 0.0001087188720703125
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 178.28635595932207,
    "kernel_usage": 5.5714486237288146,
    "cpu_runtime": 2.5079e-05,
    "total_runtime": 1.4066696166992188e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 157.68001929846156,
    "kernel_usage": 4.927500603076924,
    "cpu_runtime": 2.4436000000000005e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.7332436913742,
    "kernel_usage": 11.429163865355443,
    "cpu_runtime": 0.18451797,
    "total_runtime": 0.05045151710510254
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 196.9865537084746,
    "kernel_usage": 6.155829803389831,
    "cpu_runtime": 5.5419000000000006e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 135.85452956097564,
    "kernel_usage": 4.245454048780489,
    "cpu_runtime": 1.3280000000000002e-05,
    "total_runtime": 9.775161743164062e-06
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.4557765665574,
    "kernel_usage": 6.482993017704919,
    "cpu_runtime": 0.000150857,
    "total_runtime": 7.271766662597656e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.53308111698115,
    "kernel_usage": 4.735408784905661,
    "cpu_runtime": 3.8296e-05,
    "total_runtime": 2.5272369384765625e-05
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 155.37003696551724,
    "kernel_usage": 4.855313655172414,
    "cpu_runtime": 4.297e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.35915429771944,
    "kernel_usage": 9.354973571803733,
    "cpu_runtime": 0.016524227000000002,
    "total_runtime": 0.005519866943359375
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.64455278792636,
    "kernel_usage": 6.238892274622699,
    "cpu_runtime": 0.00545627,
    "total_runtime": 0.002732992172241211
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 206.6650384202532,
    "kernel_usage": 6.458282450632913,
    "cpu_runtime": 0.00015570200000000002,
    "total_runtime": 7.534027099609375e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 188.2213338074074,
    "kernel_usage": 5.881916681481481,
    "cpu_runtime": 9.6931e-05,
    "total_runtime": 5.14984130859375e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 204.16957938054475,
    "kernel_usage": 6.380299355642023,
    "cpu_runtime": 0.000125102,
    "total_runtime": 6.127357482910156e-05
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 192.60206010497737,
    "kernel_usage": 6.018814378280543,
    "cpu_runtime": 0.000101483,
    "total_runtime": 5.269050598144531e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.29933323861005,
    "kernel_usage": 6.915604163706564,
    "cpu_runtime": 0.000546613,
    "total_runtime": 0.00024700164794921875
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 204.57871510146632,
    "kernel_usage": 6.393084846920822,
    "cpu_runtime": 0.00016632400000000003,
    "total_runtime": 8.130073547363281e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 163.92738133333333,
    "kernel_usage": 5.1227306666666665,
    "cpu_runtime": 7.973e-05,
    "total_runtime": 4.863739013671875e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.95372440701755,
    "kernel_usage": 6.342303887719298,
    "cpu_runtime": 0.00022064900000000003,
    "total_runtime": 0.0001087188720703125
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.39903726412214,
    "kernel_usage": 6.043719914503817,
    "cpu_runtime": 0.000241616,
    "total_runtime": 0.00012493133544921875
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.89297507796613,
    "kernel_usage": 5.8091554711864415,
    "cpu_runtime": 5.2298000000000006e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.4405258386635,
    "kernel_usage": 6.076266432458234,
    "cpu_runtime": 0.000194241,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.73075408469055,
    "kernel_usage": 6.7728360651465795,
    "cpu_runtime": 0.00015863500000000002,
    "total_runtime": 7.319450378417969e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.4072977767277,
    "kernel_usage": 7.04397805552274,
    "cpu_runtime": 0.00090984,
    "total_runtime": 0.0004036426544189453
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 282.30560829504736,
    "kernel_usage": 8.82205025922023,
    "cpu_runtime": 0.0012774849999999999,
    "total_runtime": 0.0004525184631347656
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.28188164439305,
    "kernel_usage": 6.602558801387283,
    "cpu_runtime": 0.000435731,
    "total_runtime": 0.00020623207092285156
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.11022878632483,
    "kernel_usage": 5.753444649572651,
    "cpu_runtime": 0.00010271500000000002,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 147.40144570810813,
    "kernel_usage": 4.606295178378379,
    "cpu_runtime": 3.9009e-05,
    "total_runtime": 2.6464462280273438e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.16825414699335,
    "kernel_usage": 6.255257942093542,
    "cpu_runtime": 0.0017142400000000001,
    "total_runtime": 0.0008563995361328125
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.47604330247657,
    "kernel_usage": 6.889876353202393,
    "cpu_runtime": 0.0006155430000000001,
    "total_runtime": 0.0002791881561279297
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.48566740091883,
    "kernel_usage": 6.952677106278713,
    "cpu_runtime": 0.000346382,
    "total_runtime": 0.0001556873321533203
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 276.717641361194,
    "kernel_usage": 8.647426292537313,
    "cpu_runtime": 0.000618842,
    "total_runtime": 0.00022363662719726562
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 226.6410192234801,
    "kernel_usage": 7.082531850733753,
    "cpu_runtime": 0.00025774900000000004,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 245.36316254442704,
    "kernel_usage": 7.667598829513345,
    "cpu_runtime": 0.0007452790000000001,
    "total_runtime": 0.0003037452697753906
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 184.73806576863754,
    "kernel_usage": 5.773064555269923,
    "cpu_runtime": 0.000171335,
    "total_runtime": 9.274482727050781e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 142.5682059636364,
    "kernel_usage": 4.455256436363637,
    "cpu_runtime": 3.365100000000001e-05,
    "total_runtime": 2.3603439331054688e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 211.19240827881322,
    "kernel_usage": 6.599762758712913,
    "cpu_runtime": 0.001204928,
    "total_runtime": 0.0005705356597900391
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.00630540220322,
    "kernel_usage": 6.312697043818851,
    "cpu_runtime": 0.00039348400000000004,
    "total_runtime": 0.00019478797912597656
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.36902467368424,
    "kernel_usage": 6.105282021052632,
    "cpu_runtime": 0.00014160200000000003,
    "total_runtime": 7.2479248046875e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.0291568901169,
    "kernel_usage": 6.782161152816153,
    "cpu_runtime": 0.00048690900000000005,
    "total_runtime": 0.0002243518829345703
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.65993068010548,
    "kernel_usage": 6.239372833753296,
    "cpu_runtime": 0.011372746,
    "total_runtime": 0.00569605827331543
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 190.79527910819675,
    "kernel_usage": 5.9623524721311485,
    "cpu_runtime": 0.00022198700000000004,
    "total_runtime": 0.0001163482666015625
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 167.82989535870445,
    "kernel_usage": 5.244684229959514,
    "cpu_runtime": 9.8834e-05,
    "total_runtime": 5.888938903808594e-05
  }
]