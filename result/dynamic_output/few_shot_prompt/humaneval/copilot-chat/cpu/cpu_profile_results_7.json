[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.42697548903922,
    "kernel_usage": 6.607092984032476,
    "cpu_runtime": 0.000372516,
    "total_runtime": 0.0001761913299560547
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 200.56279704340048,
    "kernel_usage": 6.267587407606265,
    "cpu_runtime": 0.000427492,
    "total_runtime": 0.00021314620971679688
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 137.79615951392407,
    "kernel_usage": 4.306129984810127,
    "cpu_runtime": 2.5954000000000003e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.98223274666668,
    "kernel_usage": 5.218194773333334,
    "cpu_runtime": 7.1661e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 285.08601232475246,
    "kernel_usage": 8.908937885148514,
    "cpu_runtime": 0.000411897,
    "total_runtime": 0.00014448165893554688
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 192.10809497326204,
    "kernel_usage": 6.003377967914439,
    "cpu_runtime": 8.565000000000001e-05,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_6.py",
    "status": "success",
    "cpu_usage": 223.51912049777778,
    "kernel_usage": 6.9849725155555555,
    "cpu_runtime": 0.000431658,
    "total_runtime": 0.00019311904907226562
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.13990374010154,
    "kernel_usage": 6.316871991878173,
    "cpu_runtime": 9.4942e-05,
    "total_runtime": 4.696846008300781e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 182.01639129385475,
    "kernel_usage": 5.688012227932961,
    "cpu_runtime": 7.7679e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 194.1758151804878,
    "kernel_usage": 6.067994224390244,
    "cpu_runtime": 0.000113886,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 186.1241327364621,
    "kernel_usage": 5.81637914801444,
    "cpu_runtime": 0.00012292,
    "total_runtime": 6.604194641113281e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 321.59009134484216,
    "kernel_usage": 10.049690354526318,
    "cpu_runtime": 0.0003641970000000001,
    "total_runtime": 0.00011324882507324219
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 200.58927750736845,
    "kernel_usage": 6.268414922105264,
    "cpu_runtime": 9.086600000000001e-05,
    "total_runtime": 4.5299530029296875e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 158.2059204923077,
    "kernel_usage": 4.943935015384616,
    "cpu_runtime": 2.9421000000000002e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 208.7522028484305,
    "kernel_usage": 6.523506339013453,
    "cpu_runtime": 0.00011098800000000002,
    "total_runtime": 5.316734313964844e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 300.262385519192,
    "kernel_usage": 9.38319954747475,
    "cpu_runtime": 0.00028348900000000005,
    "total_runtime": 9.441375732421875e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.69883527710843,
    "kernel_usage": 6.209338602409638,
    "cpu_runtime": 0.00011796,
    "total_runtime": 5.936622619628906e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 221.6390070857143,
    "kernel_usage": 6.926218971428572,
    "cpu_runtime": 0.000233037,
    "total_runtime": 0.00010514259338378906
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 218.49729994105266,
    "kernel_usage": 6.828040623157896,
    "cpu_runtime": 0.000395913,
    "total_runtime": 0.0001811981201171875
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 254.1236615941115,
    "kernel_usage": 7.941364424815984,
    "cpu_runtime": 0.0005761900000000001,
    "total_runtime": 0.00022673606872558594
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 210.23714558318005,
    "kernel_usage": 6.569910799474377,
    "cpu_runtime": 0.00038144700000000004,
    "total_runtime": 0.00018143653869628906
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.55961722605366,
    "kernel_usage": 6.986238038314177,
    "cpu_runtime": 0.00027823,
    "total_runtime": 0.00012445449829101562
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 214.24965182439024,
    "kernel_usage": 6.695301619512195,
    "cpu_runtime": 8.3773e-05,
    "total_runtime": 3.910064697265625e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 172.3858944,
    "kernel_usage": 5.3870592,
    "cpu_runtime": 2.6715e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 175.37282071676302,
    "kernel_usage": 5.480400647398844,
    "cpu_runtime": 7.2335e-05,
    "total_runtime": 4.124641418457031e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.53620036194505,
    "kernel_usage": 6.173006261310783,
    "cpu_runtime": 0.000445531,
    "total_runtime": 0.00022554397583007812
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 331.69370159803447,
    "kernel_usage": 10.365428174938577,
    "cpu_runtime": 0.0006437270000000001,
    "total_runtime": 0.00019407272338867188
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 207.17764608000002,
    "kernel_usage": 6.4743014400000005,
    "cpu_runtime": 4.9395000000000004e-05,
    "total_runtime": 2.384185791015625e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 175.69530255609754,
    "kernel_usage": 5.490478204878048,
    "cpu_runtime": 3.4349e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 266.43617109333337,
    "kernel_usage": 8.326130346666668,
    "cpu_runtime": 0.00011434200000000001,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 208.54360670391063,
    "kernel_usage": 6.516987709497207,
    "cpu_runtime": 8.900000000000001e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 183.90588506058637,
    "kernel_usage": 5.747058908143324,
    "cpu_runtime": 0.00026921800000000005,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 192.8840572342857,
    "kernel_usage": 6.027626788571428,
    "cpu_runtime": 3.2191e-05,
    "total_runtime": 1.6689300537109375e-05
  },
  {
    "task_id": "HumanEval_36.py",
    "status": "success",
    "cpu_usage": 403.30967641236464,
    "kernel_usage": 12.603427387886395,
    "cpu_runtime": 0.9669941970000001,
    "total_runtime": 0.23976469039916992
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 220.83765966380787,
    "kernel_usage": 6.901176864493996,
    "cpu_runtime": 0.00030696,
    "total_runtime": 0.00013899803161621094
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 364.46112458099515,
    "kernel_usage": 11.389410143156098,
    "cpu_runtime": 0.197400396,
    "total_runtime": 0.05416226387023926
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 290.17925709156276,
    "kernel_usage": 9.068101784111336,
    "cpu_runtime": 0.037333830000000005,
    "total_runtime": 0.012865781784057617
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 189.40117815776537,
    "kernel_usage": 5.918786817430168,
    "cpu_runtime": 0.00040415300000000003,
    "total_runtime": 0.00021338462829589844
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 131.6360615724138,
    "kernel_usage": 4.1136269241379315,
    "cpu_runtime": 1.8203000000000002e-05,
    "total_runtime": 1.3828277587890625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 200.16082221176475,
    "kernel_usage": 6.2550256941176485,
    "cpu_runtime": 6.490200000000001e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 183.29823926311303,
    "kernel_usage": 5.728069976972282,
    "cpu_runtime": 0.00020496100000000003,
    "total_runtime": 0.00011181831359863281
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 203.2133093653516,
    "kernel_usage": 6.350415917667237,
    "cpu_runtime": 0.000564925,
    "total_runtime": 0.0002779960632324219
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 131.75834065454546,
    "kernel_usage": 4.117448145454546,
    "cpu_runtime": 1.3822e-05,
    "total_runtime": 1.049041748046875e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 206.12114383622048,
    "kernel_usage": 6.44128574488189,
    "cpu_runtime": 0.00024964700000000003,
    "total_runtime": 0.00012111663818359375
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 203.685105480597,
    "kernel_usage": 6.365159546268656,
    "cpu_runtime": 0.000130147,
    "total_runtime": 6.389617919921875e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 152.19604014545453,
    "kernel_usage": 4.756126254545454,
    "cpu_runtime": 3.9915e-05,
    "total_runtime": 2.6226043701171875e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 255.73301720207255,
    "kernel_usage": 7.991656787564767,
    "cpu_runtime": 0.00023535000000000003,
    "total_runtime": 9.202957153320312e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.91912294910173,
    "kernel_usage": 11.24747259215943,
    "cpu_runtime": 0.253103316,
    "total_runtime": 0.07032227516174316
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 217.5831622201097,
    "kernel_usage": 6.799473819378428,
    "cpu_runtime": 0.000283761,
    "total_runtime": 0.0001304149627685547
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 273.7490935674797,
    "kernel_usage": 8.55465917398374,
    "cpu_runtime": 0.00032111300000000004,
    "total_runtime": 0.00011730194091796875
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 295.7937594064046,
    "kernel_usage": 9.243554981450144,
    "cpu_runtime": 0.017419819,
    "total_runtime": 0.005889177322387695
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.03708980512823,
    "kernel_usage": 5.501159056410257,
    "cpu_runtime": 9.821100000000001e-05,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 179.90398647547167,
    "kernel_usage": 5.62199957735849,
    "cpu_runtime": 9.093199999999999e-05,
    "total_runtime": 5.054473876953125e-05
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 187.87500508432956,
    "kernel_usage": 5.871093908885299,
    "cpu_runtime": 0.000277268,
    "total_runtime": 0.0001475811004638672
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 268.6074358216561,
    "kernel_usage": 8.393982369426753,
    "cpu_runtime": 0.0008043550000000001,
    "total_runtime": 0.0002994537353515625
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.95817525461848,
    "kernel_usage": 5.9361929767068276,
    "cpu_runtime": 0.00011277100000000001,
    "total_runtime": 5.936622619628906e-05
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 197.55936758662617,
    "kernel_usage": 6.173730237082068,
    "cpu_runtime": 0.00015496500000000002,
    "total_runtime": 7.843971252441406e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 145.36022770526316,
    "kernel_usage": 4.542507115789474,
    "cpu_runtime": 2.6339e-05,
    "total_runtime": 1.811981201171875e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 188.25636102564104,
    "kernel_usage": 5.8830112820512825,
    "cpu_runtime": 0.000280075,
    "total_runtime": 0.000148773193359375
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 202.5322940672783,
    "kernel_usage": 6.3291341896024464,
    "cpu_runtime": 0.0001579,
    "total_runtime": 7.796287536621094e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 206.5198100784845,
    "kernel_usage": 6.453744064952641,
    "cpu_runtime": 0.0003638700000000001,
    "total_runtime": 0.0001761913299560547
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 253.93543688231514,
    "kernel_usage": 7.935482402572348,
    "cpu_runtime": 0.00037657700000000006,
    "total_runtime": 0.00014829635620117188
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 366.9239277037037,
    "kernel_usage": 11.466372740740741,
    "cpu_runtime": 0.00108652,
    "total_runtime": 0.0002961158752441406
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 305.93253375999996,
    "kernel_usage": 9.560391679999999,
    "cpu_runtime": 0.000864339,
    "total_runtime": 0.00028252601623535156
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 249.79155396715794,
    "kernel_usage": 7.805986061473686,
    "cpu_runtime": 0.0005657720000000001,
    "total_runtime": 0.00022649765014648438
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 335.7824514834176,
    "kernel_usage": 10.4932016088568,
    "cpu_runtime": 0.006652718000000001,
    "total_runtime": 0.0019812583923339844
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 237.9723401597877,
    "kernel_usage": 7.436635629993366,
    "cpu_runtime": 0.0017100540000000003,
    "total_runtime": 0.0007185935974121094
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 201.03118671827954,
    "kernel_usage": 6.282224584946236,
    "cpu_runtime": 0.000178298,
    "total_runtime": 8.869171142578125e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 174.55295146666668,
    "kernel_usage": 5.454779733333334,
    "cpu_runtime": 7.491000000000001e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 181.358304172973,
    "kernel_usage": 5.667447005405406,
    "cpu_runtime": 0.00015998500000000002,
    "total_runtime": 8.821487426757812e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 300.58131802827154,
    "kernel_usage": 9.393166188383486,
    "cpu_runtime": 0.001024081,
    "total_runtime": 0.0003407001495361328
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 166.66971220550457,
    "kernel_usage": 5.208428506422018,
    "cpu_runtime": 8.6627e-05,
    "total_runtime": 5.1975250244140625e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 200.75736502857146,
    "kernel_usage": 6.273667657142858,
    "cpu_runtime": 0.000207731,
    "total_runtime": 0.00010347366333007812
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 292.05137457823304,
    "kernel_usage": 9.126605455569782,
    "cpu_runtime": 0.000543814,
    "total_runtime": 0.0001862049102783203
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.83549906356592,
    "kernel_usage": 5.776109345736435,
    "cpu_runtime": 5.684800000000001e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 204.5491525957958,
    "kernel_usage": 6.392161018618618,
    "cpu_runtime": 0.000324797,
    "total_runtime": 0.00015878677368164062
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 192.73238086274515,
    "kernel_usage": 6.022886901960786,
    "cpu_runtime": 0.00023435000000000003,
    "total_runtime": 0.00012159347534179688
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 230.11818133204355,
    "kernel_usage": 7.191193166626361,
    "cpu_runtime": 0.00045372900000000005,
    "total_runtime": 0.0001971721649169922
  },
  {
    "task_id": "HumanEval_83.py",
    "status": "success",
    "cpu_usage": 166.92977457478992,
    "kernel_usage": 5.216555455462185,
    "cpu_runtime": 4.7361e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 278.7934377197935,
    "kernel_usage": 8.712294928743546,
    "cpu_runtime": 0.00038618800000000004,
    "total_runtime": 0.0001385211944580078
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 279.75040693487034,
    "kernel_usage": 8.742200216714698,
    "cpu_runtime": 0.00023144100000000004,
    "total_runtime": 8.273124694824219e-05
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 227.1579039984291,
    "kernel_usage": 7.0986844999509096,
    "cpu_runtime": 0.0011032120000000001,
    "total_runtime": 0.0004856586456298828
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 195.95673375561645,
    "kernel_usage": 6.123647929863014,
    "cpu_runtime": 0.00017052700000000002,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 227.0334938876133,
    "kernel_usage": 7.094796683987916,
    "cpu_runtime": 0.0026875049999999998,
    "total_runtime": 0.0011837482452392578
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.96884030877197,
    "kernel_usage": 6.436526259649124,
    "cpu_runtime": 0.000223927,
    "total_runtime": 0.0001087188720703125
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 294.76894508751366,
    "kernel_usage": 9.211529533984802,
    "cpu_runtime": 0.0006472640000000002,
    "total_runtime": 0.00021958351135253906
  },
  {
    "task_id": "HumanEval_94.py",
    "status": "success",
    "cpu_usage": 333.02763587057973,
    "kernel_usage": 10.407113620955617,
    "cpu_runtime": 0.003273661,
    "total_runtime": 0.0009829998016357422
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 296.0840014896877,
    "kernel_usage": 9.25262504655274,
    "cpu_runtime": 0.0011979450000000002,
    "total_runtime": 0.00040459632873535156
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 353.4886876352611,
    "kernel_usage": 11.04652148860191,
    "cpu_runtime": 0.004502988,
    "total_runtime": 0.0012738704681396484
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 193.36687523609024,
    "kernel_usage": 6.04271485112782,
    "cpu_runtime": 0.00012263200000000001,
    "total_runtime": 6.341934204101562e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 247.39264041663654,
    "kernel_usage": 7.731020013019892,
    "cpu_runtime": 0.000326176,
    "total_runtime": 0.00013184547424316406
  },
  {
    "task_id": "HumanEval_99.py",
    "status": "success",
    "cpu_usage": 198.02303709690727,
    "kernel_usage": 6.188219909278352,
    "cpu_runtime": 0.00013738800000000003,
    "total_runtime": 6.937980651855469e-05
  },
  {
    "task_id": "HumanEval_100.py",
    "status": "success",
    "cpu_usage": 201.02935785826773,
    "kernel_usage": 6.282167433070867,
    "cpu_runtime": 0.00018261000000000002,
    "total_runtime": 9.083747863769531e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 301.1587194563707,
    "kernel_usage": 9.411209983011585,
    "cpu_runtime": 0.000743867,
    "total_runtime": 0.00024700164794921875
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 152.34047672320003,
    "kernel_usage": 4.760639897600001,
    "cpu_runtime": 4.5401e-05,
    "total_runtime": 2.9802322387695312e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 201.28740069025847,
    "kernel_usage": 6.290231271570577,
    "cpu_runtime": 0.000241393,
    "total_runtime": 0.00011992454528808594
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 402.8686387738948,
    "kernel_usage": 12.589644961684213,
    "cpu_runtime": 0.001368732,
    "total_runtime": 0.00033974647521972656
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 226.73040002006272,
    "kernel_usage": 7.08532500062696,
    "cpu_runtime": 0.000344882,
    "total_runtime": 0.00015211105346679688
  },
  {
    "task_id": "HumanEval_106.py",
    "status": "success",
    "cpu_usage": 214.39793940143065,
    "kernel_usage": 6.699935606294708,
    "cpu_runtime": 0.000357304,
    "total_runtime": 0.0001666545867919922
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 197.40595889929077,
    "kernel_usage": 6.1689362156028364,
    "cpu_runtime": 0.001459964,
    "total_runtime": 0.0007395744323730469
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 199.15275999295153,
    "kernel_usage": 6.223523749779735,
    "cpu_runtime": 0.000215567,
    "total_runtime": 0.00010824203491210938
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 286.4510140727705,
    "kernel_usage": 8.951594189774077,
    "cpu_runtime": 0.0005743629999999999,
    "total_runtime": 0.00020051002502441406
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 304.6639119147929,
    "kernel_usage": 9.520747247337278,
    "cpu_runtime": 0.001964119,
    "total_runtime": 0.000644683837890625
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 282.08875438079997,
    "kernel_usage": 8.815273574399999,
    "cpu_runtime": 0.000672552,
    "total_runtime": 0.0002384185791015625
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 264.24057743780827,
    "kernel_usage": 8.257518044931508,
    "cpu_runtime": 0.00045989900000000005,
    "total_runtime": 0.00017404556274414062
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 233.30339679488165,
    "kernel_usage": 7.2907311498400516,
    "cpu_runtime": 0.000869401,
    "total_runtime": 0.0003726482391357422
  },
  {
    "task_id": "HumanEval_115.py",
    "status": "success",
    "cpu_usage": 207.8231028622222,
    "kernel_usage": 6.494471964444444,
    "cpu_runtime": 0.000267564,
    "total_runtime": 0.00012874603271484375
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 441.49648559162176,
    "kernel_usage": 13.79676517473818,
    "cpu_runtime": 0.0033167730000000003,
    "total_runtime": 0.0007512569427490234
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 314.32734460394374,
    "kernel_usage": 9.822729518873242,
    "cpu_runtime": 0.0021283380000000005,
    "total_runtime": 0.0006771087646484375
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 186.76856565875707,
    "kernel_usage": 5.836517676836158,
    "cpu_runtime": 0.00031526600000000003,
    "total_runtime": 0.00016880035400390625
  },
  {
    "task_id": "HumanEval_119.py",
    "status": "success",
    "cpu_usage": 248.15373996472664,
    "kernel_usage": 7.7548043738977075,
    "cpu_runtime": 0.000670925,
    "total_runtime": 0.0002703666687011719
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 212.73364802012586,
    "kernel_usage": 6.647926500628933,
    "cpu_runtime": 0.00032257700000000005,
    "total_runtime": 0.00015163421630859375
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 279.6883607212435,
    "kernel_usage": 8.74026127253886,
    "cpu_runtime": 0.000386094,
    "total_runtime": 0.0001380443572998047
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 279.9280576318408,
    "kernel_usage": 8.747751800995024,
    "cpu_runtime": 0.000268295,
    "total_runtime": 9.584426879882812e-05
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 205.9891582137214,
    "kernel_usage": 6.437161194178794,
    "cpu_runtime": 0.000236227,
    "total_runtime": 0.00011467933654785156
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 197.44439813695925,
    "kernel_usage": 6.170137441779977,
    "cpu_runtime": 0.00038083200000000006,
    "total_runtime": 0.00019288063049316406
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 314.40963844098184,
    "kernel_usage": 9.825301201280682,
    "cpu_runtime": 0.002809542,
    "total_runtime": 0.0008935928344726562
  },
  {
    "task_id": "HumanEval_127.py",
    "status": "success",
    "cpu_usage": 223.11756114512397,
    "kernel_usage": 6.972423785785124,
    "cpu_runtime": 0.00032183200000000003,
    "total_runtime": 0.0001442432403564453
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 328.6167657309879,
    "kernel_usage": 10.269273929093371,
    "cpu_runtime": 0.0023159770000000003,
    "total_runtime": 0.0007047653198242188
  },
  {
    "task_id": "HumanEval_130.py",
    "status": "success",
    "cpu_usage": 255.22709276522542,
    "kernel_usage": 7.975846648913294,
    "cpu_runtime": 0.0026597920000000007,
    "total_runtime": 0.0010421276092529297
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 240.8627681483444,
    "kernel_usage": 7.5269615046357625,
    "cpu_runtime": 0.000346854,
    "total_runtime": 0.00014400482177734375
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 340.19817742642994,
    "kernel_usage": 10.631193044575936,
    "cpu_runtime": 0.001644902,
    "total_runtime": 0.00048351287841796875
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 232.1047134784155,
    "kernel_usage": 7.2532722962004845,
    "cpu_runtime": 0.000684532,
    "total_runtime": 0.0002949237823486328
  },
  {
    "task_id": "HumanEval_137.py",
    "status": "success",
    "cpu_usage": 256.75028383091484,
    "kernel_usage": 8.023446369716089,
    "cpu_runtime": 0.000388097,
    "total_runtime": 0.00015115737915039062
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.60814180392157,
    "kernel_usage": 4.550254431372549,
    "cpu_runtime": 3.541e-05,
    "total_runtime": 2.4318695068359375e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 204.75412480000003,
    "kernel_usage": 6.398566400000001,
    "cpu_runtime": 0.00015621500000000002,
    "total_runtime": 7.62939453125e-05
  },
  {
    "task_id": "HumanEval_140.py",
    "status": "success",
    "cpu_usage": 305.2831701077845,
    "kernel_usage": 9.540099065868265,
    "cpu_runtime": 0.0004862050000000001,
    "total_runtime": 0.00015926361083984375
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 190.86272046939354,
    "kernel_usage": 5.964460014668548,
    "cpu_runtime": 0.0006452640000000001,
    "total_runtime": 0.0003380775451660156
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 303.55123133258843,
    "kernel_usage": 9.485975979143388,
    "cpu_runtime": 0.001165917,
    "total_runtime": 0.0003840923309326172
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 257.60947277513947,
    "kernel_usage": 8.050296024223108,
    "cpu_runtime": 0.0007708070000000001,
    "total_runtime": 0.00029921531677246094
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 319.71510959318573,
    "kernel_usage": 9.991097174787054,
    "cpu_runtime": 0.0017897870000000004,
    "total_runtime": 0.0005598068237304688
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 205.0685690980392,
    "kernel_usage": 6.408392784313725,
    "cpu_runtime": 0.00024935,
    "total_runtime": 0.00012159347534179688
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 286.75275601901285,
    "kernel_usage": 8.961023625594152,
    "cpu_runtime": 0.0007479370000000002,
    "total_runtime": 0.0002608299255371094
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 185.50311264203822,
    "kernel_usage": 5.796972270063694,
    "cpu_runtime": 0.000277748,
    "total_runtime": 0.00014972686767578125
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 320.8340570112,
    "kernel_usage": 10.0260642816,
    "cpu_runtime": 0.003059712,
    "total_runtime": 0.00095367431640625
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 237.73781105777778,
    "kernel_usage": 7.4293065955555555,
    "cpu_runtime": 0.000204052,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 610.3646503779379,
    "kernel_usage": 19.07389532431056,
    "cpu_runtime": 0.013139206000000002,
    "total_runtime": 0.002152681350708008
  },
  {
    "task_id": "HumanEval_154.py",
    "status": "success",
    "cpu_usage": 188.84741009892474,
    "kernel_usage": 5.901481565591398,
    "cpu_runtime": 0.00016749200000000002,
    "total_runtime": 8.869171142578125e-05
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 302.0645207238345,
    "kernel_usage": 9.439516272619828,
    "cpu_runtime": 0.001096831,
    "total_runtime": 0.0003631114959716797
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 190.4260827428572,
    "kernel_usage": 5.950815085714288,
    "cpu_runtime": 0.0006101910000000002,
    "total_runtime": 0.0003204345703125
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 198.55374326816144,
    "kernel_usage": 6.204804477130045,
    "cpu_runtime": 0.00042226300000000003,
    "total_runtime": 0.00021266937255859375
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 199.16272303982203,
    "kernel_usage": 6.223835094994438,
    "cpu_runtime": 0.000426882,
    "total_runtime": 0.0002143383026123047
  },
  {
    "task_id": "HumanEval_159.py",
    "status": "success",
    "cpu_usage": 207.60851549090913,
    "kernel_usage": 6.48776610909091,
    "cpu_runtime": 0.000152453,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 342.9576310668678,
    "kernel_usage": 10.717425970839619,
    "cpu_runtime": 0.0016263550000000003,
    "total_runtime": 0.0004742145538330078
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 224.97922979807078,
    "kernel_usage": 7.030600931189712,
    "cpu_runtime": 0.00016681800000000003,
    "total_runtime": 7.414817810058594e-05
  }
]