[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.50112102369212,
    "kernel_usage": 6.609410031990379,
    "cpu_runtime": 0.000838581,
    "total_runtime": 0.00039649009704589844
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.1112260923077,
    "kernel_usage": 6.878475815384616,
    "cpu_runtime": 0.000873244,
    "total_runtime": 0.000396728515625
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.6710738823529,
    "kernel_usage": 4.083471058823529,
    "cpu_runtime": 2.1184999999999998e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 164.85861668571425,
    "kernel_usage": 5.15183177142857,
    "cpu_runtime": 6.6033e-05,
    "total_runtime": 4.00543212890625e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 389.3802413419355,
    "kernel_usage": 12.168132541935485,
    "cpu_runtime": 0.0008921490000000001,
    "total_runtime": 0.00022912025451660156
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 201.4568361768421,
    "kernel_usage": 6.295526130526316,
    "cpu_runtime": 9.1259e-05,
    "total_runtime": 4.5299530029296875e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 151.34079011929828,
    "kernel_usage": 4.729399691228071,
    "cpu_runtime": 4.1134e-05,
    "total_runtime": 2.7179718017578125e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.86122535879397,
    "kernel_usage": 6.745663292462312,
    "cpu_runtime": 0.000204832,
    "total_runtime": 9.489059448242188e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 212.53059229281047,
    "kernel_usage": 6.641581009150327,
    "cpu_runtime": 0.000155054,
    "total_runtime": 7.295608520507812e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.3790649099366,
    "kernel_usage": 10.105595778435518,
    "cpu_runtime": 0.000364681,
    "total_runtime": 0.00011277198791503906
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.7992793561562,
    "kernel_usage": 9.274977479879881,
    "cpu_runtime": 0.00023563900000000003,
    "total_runtime": 7.939338684082031e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.1665760864865,
    "kernel_usage": 4.848955502702703,
    "cpu_runtime": 2.7376e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 198.73265563278687,
    "kernel_usage": 6.21039548852459,
    "cpu_runtime": 0.000115611,
    "total_runtime": 5.817413330078125e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.99430766394053,
    "kernel_usage": 7.374822114498142,
    "cpu_runtime": 0.000151354,
    "total_runtime": 6.413459777832031e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.176439628692,
    "kernel_usage": 6.193013738396625,
    "cpu_runtime": 0.00011198000000000001,
    "total_runtime": 5.650520324707031e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 214.94621950025711,
    "kernel_usage": 6.717069359383035,
    "cpu_runtime": 0.0011961090000000003,
    "total_runtime": 0.0005564689636230469
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.66217425454548,
    "kernel_usage": 7.020692945454546,
    "cpu_runtime": 0.000259248,
    "total_runtime": 0.00011539459228515625
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 258.5986911868313,
    "kernel_usage": 8.081209099588477,
    "cpu_runtime": 0.00014982100000000001,
    "total_runtime": 5.793571472167969e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 171.6639240393443,
    "kernel_usage": 5.364497626229509,
    "cpu_runtime": 2.4966000000000005e-05,
    "total_runtime": 1.4543533325195312e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 198.20960669238582,
    "kernel_usage": 6.194050209137057,
    "cpu_runtime": 0.0006516720000000002,
    "total_runtime": 0.0003287792205810547
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 210.28032727578946,
    "kernel_usage": 6.571260227368421,
    "cpu_runtime": 4.7628e-05,
    "total_runtime": 2.2649765014648438e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 174.36246016,
    "kernel_usage": 5.44882688,
    "cpu_runtime": 3.3257000000000004e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 266.50607616,
    "kernel_usage": 8.32831488,
    "cpu_runtime": 0.00010801800000000001,
    "total_runtime": 4.0531158447265625e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 204.52188904727268,
    "kernel_usage": 6.391309032727271,
    "cpu_runtime": 8.045699999999999e-05,
    "total_runtime": 3.933906555175781e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.74360192832603,
    "kernel_usage": 6.241987560260188,
    "cpu_runtime": 0.017131749,
    "total_runtime": 0.00857686996459961
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 363.3023656974297,
    "kernel_usage": 11.353198928044678,
    "cpu_runtime": 1.039811384,
    "total_runtime": 0.2862110137939453
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 176.96033389490836,
    "kernel_usage": 5.530010434215886,
    "cpu_runtime": 0.000207156,
    "total_runtime": 0.00011706352233886719
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 178.00232960000002,
    "kernel_usage": 5.562572800000001,
    "cpu_runtime": 2.7161000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 158.33184592238808,
    "kernel_usage": 4.947870185074628,
    "cpu_runtime": 2.5292e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 205.79457838455596,
    "kernel_usage": 6.431080574517374,
    "cpu_runtime": 0.000254158,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 167.3330688,
    "kernel_usage": 5.2291584,
    "cpu_runtime": 5.1066e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 198.4566312314961,
    "kernel_usage": 6.201769725984253,
    "cpu_runtime": 6.0091000000000005e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 169.44493743025538,
    "kernel_usage": 5.295154294695481,
    "cpu_runtime": 0.00020563,
    "total_runtime": 0.00012135505676269531
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.3598021818182,
    "kernel_usage": 4.167493818181819,
    "cpu_runtime": 1.3990000000000002e-05,
    "total_runtime": 1.049041748046875e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 215.2522678959441,
    "kernel_usage": 6.726633371748253,
    "cpu_runtime": 0.00036693900000000005,
    "total_runtime": 0.0001704692840576172
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.2535589623003,
    "kernel_usage": 6.4766737175718845,
    "cpu_runtime": 0.000154663,
    "total_runtime": 7.462501525878906e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.22305527017542,
    "kernel_usage": 4.725720477192982,
    "cpu_runtime": 4.1102e-05,
    "total_runtime": 2.7179718017578125e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 258.8055337447619,
    "kernel_usage": 8.087672929523809,
    "cpu_runtime": 0.000259157,
    "total_runtime": 0.00010013580322265625
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 358.7761518407634,
    "kernel_usage": 11.211754745023857,
    "cpu_runtime": 0.24490300400000004,
    "total_runtime": 0.06826066970825195
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.0868571048499,
    "kernel_usage": 8.72146428452656,
    "cpu_runtime": 0.0005762320000000001,
    "total_runtime": 0.00020647048950195312
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 154.96262028387096,
    "kernel_usage": 4.8425818838709676,
    "cpu_runtime": 4.5812999999999997e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.30833377600396,
    "kernel_usage": 9.353385430500124,
    "cpu_runtime": 0.017379177,
    "total_runtime": 0.005806446075439453
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.24569399008263,
    "kernel_usage": 5.507677937190082,
    "cpu_runtime": 0.000101689,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62755928830143,
    "kernel_usage": 6.23836122775942,
    "cpu_runtime": 0.005760889000000001,
    "total_runtime": 0.0028858184814453125
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 184.9849949417544,
    "kernel_usage": 5.780781091929825,
    "cpu_runtime": 0.000251392,
    "total_runtime": 0.00013589859008789062
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 190.4612986380488,
    "kernel_usage": 5.951915582439025,
    "cpu_runtime": 0.00018617900000000002,
    "total_runtime": 9.775161743164062e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.19221131543088,
    "kernel_usage": 6.193506603607215,
    "cpu_runtime": 0.000235791,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 202.29504313085647,
    "kernel_usage": 6.321720097839265,
    "cpu_runtime": 0.019174193,
    "total_runtime": 0.009478330612182617
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 217.8264427354839,
    "kernel_usage": 6.807076335483872,
    "cpu_runtime": 9.659700000000001e-05,
    "total_runtime": 4.4345855712890625e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 184.69559944220185,
    "kernel_usage": 5.771737482568808,
    "cpu_runtime": 0.00023999000000000004,
    "total_runtime": 0.00012993812561035156
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 203.911067810072,
    "kernel_usage": 6.37222086906475,
    "cpu_runtime": 0.00013515300000000003,
    "total_runtime": 6.628036499023438e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.8993227280373,
    "kernel_usage": 6.246853835251166,
    "cpu_runtime": 0.029241140000000002,
    "total_runtime": 0.014627933502197266
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 362.4869991198561,
    "kernel_usage": 11.327718722495502,
    "cpu_runtime": 0.0014406820000000002,
    "total_runtime": 0.0003974437713623047
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.69133383434826,
    "kernel_usage": 6.396604182323383,
    "cpu_runtime": 0.0016509790000000003,
    "total_runtime": 0.0008065700531005859
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 203.53792227555556,
    "kernel_usage": 6.360560071111111,
    "cpu_runtime": 0.000174698,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.16611054869895,
    "kernel_usage": 6.098940954646842,
    "cpu_runtime": 0.00012516900000000003,
    "total_runtime": 6.413459777832031e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.0918814661597,
    "kernel_usage": 6.03412129581749,
    "cpu_runtime": 0.000242153,
    "total_runtime": 0.00012540817260742188
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.07377082014386,
    "kernel_usage": 6.033555338129496,
    "cpu_runtime": 0.00025593999999999997,
    "total_runtime": 0.00013256072998046875
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.72840476220475,
    "kernel_usage": 5.804012648818898,
    "cpu_runtime": 5.6237000000000004e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.7997030744395,
    "kernel_usage": 6.118740721076234,
    "cpu_runtime": 0.000208203,
    "total_runtime": 0.00010633468627929688
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.47808000000003,
    "kernel_usage": 6.077440000000001,
    "cpu_runtime": 0.00023740000000000002,
    "total_runtime": 0.0001220703125
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 278.8836766182444,
    "kernel_usage": 8.715114894320138,
    "cpu_runtime": 0.000386313,
    "total_runtime": 0.0001385211944580078
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.4139826086956,
    "kernel_usage": 6.731686956521737,
    "cpu_runtime": 0.00016537499999999997,
    "total_runtime": 7.677078247070312e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 288.0586537431005,
    "kernel_usage": 9.00183292947189,
    "cpu_runtime": 0.0008062859999999999,
    "total_runtime": 0.0002799034118652344
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 278.10077211558075,
    "kernel_usage": 8.690649128611899,
    "cpu_runtime": 0.001404327,
    "total_runtime": 0.0005049705505371094
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.48709229877372,
    "kernel_usage": 7.046471634336679,
    "cpu_runtime": 0.0009644600000000001,
    "total_runtime": 0.0004277229309082031
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 202.8392745704261,
    "kernel_usage": 6.338727330325816,
    "cpu_runtime": 0.00019295900000000003,
    "total_runtime": 9.512901306152344e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.3641099304843,
    "kernel_usage": 6.167628435327634,
    "cpu_runtime": 0.00016516399999999998,
    "total_runtime": 8.368492126464844e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 283.9723505542357,
    "kernel_usage": 8.874135954819865,
    "cpu_runtime": 0.0013906460000000002,
    "total_runtime": 0.0004897117614746094
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 210.81375165701849,
    "kernel_usage": 6.587929739281828,
    "cpu_runtime": 0.000461907,
    "total_runtime": 0.00021910667419433594
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.21018650852562,
    "kernel_usage": 6.287818328391426,
    "cpu_runtime": 0.002931584,
    "total_runtime": 0.0014569759368896484
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 190.92436263050848,
    "kernel_usage": 5.96638633220339,
    "cpu_runtime": 0.000107427,
    "total_runtime": 5.626678466796875e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.43420453770491,
    "kernel_usage": 5.763568891803279,
    "cpu_runtime": 0.000107293,
    "total_runtime": 5.817413330078125e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.98741388034188,
    "kernel_usage": 4.655856683760684,
    "cpu_runtime": 4.156e-05,
    "total_runtime": 2.7894973754882812e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.0776283848777,
    "kernel_usage": 6.252425887027428,
    "cpu_runtime": 0.0019305090000000002,
    "total_runtime": 0.0009648799896240234
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 275.2793325268293,
    "kernel_usage": 8.602479141463416,
    "cpu_runtime": 0.0009687240000000001,
    "total_runtime": 0.00035190582275390625
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 218.78137484003153,
    "kernel_usage": 6.836917963750985,
    "cpu_runtime": 0.00066193,
    "total_runtime": 0.0003025531768798828
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.3454208386707,
    "kernel_usage": 6.979544401208459,
    "cpu_runtime": 0.000352513,
    "total_runtime": 0.00015783309936523438
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.1434843136,
    "kernel_usage": 8.5669838848,
    "cpu_runtime": 0.0006536090000000001,
    "total_runtime": 0.0002384185791015625
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 240.9744480980502,
    "kernel_usage": 7.530451503064069,
    "cpu_runtime": 0.0008250220000000001,
    "total_runtime": 0.00034236907958984375
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 368.19736741366455,
    "kernel_usage": 11.506167731677017,
    "cpu_runtime": 0.001978676,
    "total_runtime": 0.0005373954772949219
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.15274824118617,
    "kernel_usage": 5.754773382537068,
    "cpu_runtime": 0.000266506,
    "total_runtime": 0.00014472007751464844
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 224.2701853518887,
    "kernel_usage": 7.008443292246522,
    "cpu_runtime": 0.00026895500000000003,
    "total_runtime": 0.00011992454528808594
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.64998881432837,
    "kernel_usage": 6.3328121504477615,
    "cpu_runtime": 0.000323714,
    "total_runtime": 0.00015974044799804688
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.7920672721805,
    "kernel_usage": 8.21225210225564,
    "cpu_runtime": 0.000499983,
    "total_runtime": 0.00019025802612304688
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 264.39839010819776,
    "kernel_usage": 8.26244969088118,
    "cpu_runtime": 0.002053131,
    "total_runtime": 0.0007765293121337891
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.20361476286155,
    "kernel_usage": 7.631362961339423,
    "cpu_runtime": 0.0007650460000000001,
    "total_runtime": 0.0003132820129394531
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.57627555337424,
    "kernel_usage": 6.674258611042945,
    "cpu_runtime": 0.001162007,
    "total_runtime": 0.0005440711975097656
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.09019862375735,
    "kernel_usage": 6.284068706992417,
    "cpu_runtime": 0.000569091,
    "total_runtime": 0.0002830028533935547
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 210.72305090671512,
    "kernel_usage": 6.585095340834847,
    "cpu_runtime": 0.00027682400000000006,
    "total_runtime": 0.00013136863708496094
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.44117082595494,
    "kernel_usage": 6.982536588311092,
    "cpu_runtime": 0.0011576120000000001,
    "total_runtime": 0.0005180835723876953
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 143.895986482243,
    "kernel_usage": 4.496749577570093,
    "cpu_runtime": 3.6709e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.17882307249118,
    "kernel_usage": 6.3180882210153495,
    "cpu_runtime": 0.0004082810000000001,
    "total_runtime": 0.00020194053649902344
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.17702128650964,
    "kernel_usage": 5.724281915203426,
    "cpu_runtime": 0.000203952,
    "total_runtime": 0.00011134147644042969
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.048067356254,
    "kernel_usage": 6.251502104882937,
    "cpu_runtime": 0.5311296640000001,
    "total_runtime": 0.2655010223388672
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.4432237714286,
    "kernel_usage": 6.1388507428571435,
    "cpu_runtime": 0.00015081100000000002,
    "total_runtime": 7.677078247070312e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.23352134585417,
    "kernel_usage": 6.788547542057943,
    "cpu_runtime": 0.000518443,
    "total_runtime": 0.00023865699768066406
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6703864728484,
    "kernel_usage": 6.239699577276513,
    "cpu_runtime": 0.012008394000000002,
    "total_runtime": 0.006014108657836914
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 255.39450930945273,
    "kernel_usage": 7.981078415920398,
    "cpu_runtime": 0.000244781,
    "total_runtime": 9.584426879882812e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.58194160618217,
    "kernel_usage": 9.361935675193193,
    "cpu_runtime": 0.008226121,
    "total_runtime": 0.0027458667755126953
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 190.52252908774705,
    "kernel_usage": 5.953829033992095,
    "cpu_runtime": 0.00022984600000000002,
    "total_runtime": 0.00012063980102539062
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 167.45635358117647,
    "kernel_usage": 5.233011049411765,
    "cpu_runtime": 0.000101808,
    "total_runtime": 6.079673767089844e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 273.09894161713333,
    "kernel_usage": 8.534341925535417,
    "cpu_runtime": 0.0007904579999999997,
    "total_runtime": 0.0002894401550292969
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 233.34419214826258,
    "kernel_usage": 7.292006004633206,
    "cpu_runtime": 0.00028818200000000005,
    "total_runtime": 0.00012350082397460938
  }
]