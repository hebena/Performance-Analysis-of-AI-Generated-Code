[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.34838888586268,
    "kernel_usage": 6.604637152683209,
    "cpu_runtime": 0.0008732480000000001,
    "total_runtime": 0.0004131793975830078
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.32628885775267,
    "kernel_usage": 6.885196526804771,
    "cpu_runtime": 0.0008368010000000001,
    "total_runtime": 0.00037980079650878906
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 129.48415634285715,
    "kernel_usage": 4.046379885714286,
    "cpu_runtime": 2.161e-05,
    "total_runtime": 1.6689300537109375e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 163.99210824691357,
    "kernel_usage": 5.124753382716049,
    "cpu_runtime": 6.334e-05,
    "total_runtime": 3.8623809814453125e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 389.0257660600613,
    "kernel_usage": 12.157055189376916,
    "cpu_runtime": 0.000908032,
    "total_runtime": 0.0002334117889404297
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 201.55013457582416,
    "kernel_usage": 6.298441705494505,
    "cpu_runtime": 8.7457e-05,
    "total_runtime": 4.3392181396484375e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 154.24264361100916,
    "kernel_usage": 4.820082612844036,
    "cpu_runtime": 4.0084e-05,
    "total_runtime": 2.5987625122070312e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 214.1620292795866,
    "kernel_usage": 6.692563414987081,
    "cpu_runtime": 0.00019760300000000003,
    "total_runtime": 9.226799011230469e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.24792821443302,
    "kernel_usage": 6.663997756701032,
    "cpu_runtime": 0.000147951,
    "total_runtime": 6.937980651855469e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.89046888602155,
    "kernel_usage": 10.121577152688173,
    "cpu_runtime": 0.00035908000000000007,
    "total_runtime": 0.00011086463928222656
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 295.64585715877445,
    "kernel_usage": 9.238933036211701,
    "cpu_runtime": 0.00025305000000000005,
    "total_runtime": 8.559226989746094e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.84106551351354,
    "kernel_usage": 4.870033297297298,
    "cpu_runtime": 2.7495000000000007e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 198.22176281493776,
    "kernel_usage": 6.194430087966805,
    "cpu_runtime": 0.00011389600000000001,
    "total_runtime": 5.745887756347656e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.18288678787877,
    "kernel_usage": 7.349465212121212,
    "cpu_runtime": 0.00014803,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.43303166963565,
    "kernel_usage": 6.201032239676114,
    "cpu_runtime": 0.00011685600000000001,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 214.9110965946781,
    "kernel_usage": 6.715971768583691,
    "cpu_runtime": 0.001193864,
    "total_runtime": 0.0005555152893066406
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.01181800414082,
    "kernel_usage": 7.031619312629401,
    "cpu_runtime": 0.00025911500000000003,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.6730460117155,
    "kernel_usage": 8.114782687866109,
    "cpu_runtime": 0.000147967,
    "total_runtime": 5.698204040527344e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 168.83426601290324,
    "kernel_usage": 5.276070812903226,
    "cpu_runtime": 2.4957000000000002e-05,
    "total_runtime": 1.4781951904296875e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 198.34169821353385,
    "kernel_usage": 6.198178069172933,
    "cpu_runtime": 0.0006289350000000001,
    "total_runtime": 0.0003170967102050781
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 209.91207549387755,
    "kernel_usage": 6.5597523591836735,
    "cpu_runtime": 4.9046000000000004e-05,
    "total_runtime": 2.3365020751953125e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 173.5220729518987,
    "kernel_usage": 5.422564779746835,
    "cpu_runtime": 3.2683e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 262.6915199233534,
    "kernel_usage": 8.209109997604793,
    "cpu_runtime": 0.00010459300000000002,
    "total_runtime": 3.981590270996094e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 204.18332222439025,
    "kernel_usage": 6.380728819512195,
    "cpu_runtime": 7.9837e-05,
    "total_runtime": 3.910064697265625e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.7460189148566,
    "kernel_usage": 6.2420630910892685,
    "cpu_runtime": 0.01778106,
    "total_runtime": 0.008901834487915039
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 363.06412839716063,
    "kernel_usage": 11.34575401241127,
    "cpu_runtime": 1.0025851010000002,
    "total_runtime": 0.27614545822143555
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 176.8543359163399,
    "kernel_usage": 5.526697997385622,
    "cpu_runtime": 0.000193539,
    "total_runtime": 0.00010943412780761719
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 177.73001622068966,
    "kernel_usage": 5.554063006896552,
    "cpu_runtime": 2.4577000000000002e-05,
    "total_runtime": 1.3828277587890625e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 157.2012032,
    "kernel_usage": 4.9125376,
    "cpu_runtime": 2.3987000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 204.81273347128314,
    "kernel_usage": 6.400397920977598,
    "cpu_runtime": 0.00023976100000000004,
    "total_runtime": 0.00011706352233886719
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 167.1464523540984,
    "kernel_usage": 5.223326636065575,
    "cpu_runtime": 4.861800000000001e-05,
    "total_runtime": 2.9087066650390625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 198.17020051525424,
    "kernel_usage": 6.192818766101695,
    "cpu_runtime": 5.5752000000000004e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 169.56025802105265,
    "kernel_usage": 5.298758063157895,
    "cpu_runtime": 0.000192025,
    "total_runtime": 0.00011324882507324219
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.59345949767442,
    "kernel_usage": 4.1747956093023255,
    "cpu_runtime": 1.3696e-05,
    "total_runtime": 1.0251998901367188e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.13889308444448,
    "kernel_usage": 6.75434040888889,
    "cpu_runtime": 0.000371027,
    "total_runtime": 0.000171661376953125
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.94208954648835,
    "kernel_usage": 6.498190298327761,
    "cpu_runtime": 0.00014823600000000002,
    "total_runtime": 7.128715515136719e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.89711504905662,
    "kernel_usage": 4.7467848452830195,
    "cpu_runtime": 3.8388000000000006e-05,
    "total_runtime": 2.5272369384765625e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 259.4415940050633,
    "kernel_usage": 8.107549812658227,
    "cpu_runtime": 0.00024433,
    "total_runtime": 9.417533874511719e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 358.9856692282478,
    "kernel_usage": 11.218302163382743,
    "cpu_runtime": 0.246842532,
    "total_runtime": 0.06876111030578613
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 280.5076963587126,
    "kernel_usage": 8.76586551120977,
    "cpu_runtime": 0.0006025730000000001,
    "total_runtime": 0.0002148151397705078
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 154.01414960661157,
    "kernel_usage": 4.8129421752066115,
    "cpu_runtime": 4.4431e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.16012067024565,
    "kernel_usage": 9.317503770945176,
    "cpu_runtime": 0.01747885,
    "total_runtime": 0.005862236022949219
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.76135316420235,
    "kernel_usage": 5.523792286381323,
    "cpu_runtime": 0.00010830800000000001,
    "total_runtime": 6.127357482910156e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6299295113189,
    "kernel_usage": 6.238435297228715,
    "cpu_runtime": 0.005701939000000001,
    "total_runtime": 0.0028562545776367188
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 185.05698646581357,
    "kernel_usage": 5.783030827056674,
    "cpu_runtime": 0.00024134200000000005,
    "total_runtime": 0.0001304149627685547
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 191.43320289668247,
    "kernel_usage": 5.982287590521327,
    "cpu_runtime": 0.00019260600000000003,
    "total_runtime": 0.00010061264038085938
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.34038367545642,
    "kernel_usage": 6.198136989858013,
    "cpu_runtime": 0.00023313,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 202.23898270310326,
    "kernel_usage": 6.319968209471977,
    "cpu_runtime": 0.019313532,
    "total_runtime": 0.009549856185913086
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 216.81092460206187,
    "kernel_usage": 6.775341393814434,
    "cpu_runtime": 0.00010028200000000001,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 185.11469523478263,
    "kernel_usage": 5.784834226086957,
    "cpu_runtime": 0.00023347300000000002,
    "total_runtime": 0.00012612342834472656
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.6053548288973,
    "kernel_usage": 6.456417338403041,
    "cpu_runtime": 0.00012954999999999998,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89691433852863,
    "kernel_usage": 6.24677857307902,
    "cpu_runtime": 0.027985446000000004,
    "total_runtime": 0.01399993896484375
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.3735233151671,
    "kernel_usage": 11.292922603598972,
    "cpu_runtime": 0.001340621,
    "total_runtime": 0.00037097930908203125
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.4434624686485,
    "kernel_usage": 6.388858202145266,
    "cpu_runtime": 0.0015904880000000001,
    "total_runtime": 0.0007779598236083984
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.42318974144925,
    "kernel_usage": 6.325724679420289,
    "cpu_runtime": 0.00016650199999999999,
    "total_runtime": 8.225440979003906e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.30361579271255,
    "kernel_usage": 6.134487993522267,
    "cpu_runtime": 0.00011560200000000001,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 192.48792582231238,
    "kernel_usage": 6.015247681947262,
    "cpu_runtime": 0.000226251,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 192.921206784,
    "kernel_usage": 6.028787712,
    "cpu_runtime": 0.000241479,
    "total_runtime": 0.0001251697540283203
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 183.07070611525427,
    "kernel_usage": 5.720959566101696,
    "cpu_runtime": 5.150400000000001e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.46968894205608,
    "kernel_usage": 6.0771777794392525,
    "cpu_runtime": 0.000198443,
    "total_runtime": 0.00010204315185546875
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 192.47176116186614,
    "kernel_usage": 6.014742536308317,
    "cpu_runtime": 0.000226232,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 281.4808958355963,
    "kernel_usage": 8.796277994862384,
    "cpu_runtime": 0.000365751,
    "total_runtime": 0.00012993812561035156
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.79029398871475,
    "kernel_usage": 6.774696687147336,
    "cpu_runtime": 0.00016488100000000002,
    "total_runtime": 7.605552673339844e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.0292728096056,
    "kernel_usage": 9.032164775300174,
    "cpu_runtime": 0.0008034900000000001,
    "total_runtime": 0.0002779960632324219
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.36012967204357,
    "kernel_usage": 8.667504052251362,
    "cpu_runtime": 0.001336443,
    "total_runtime": 0.0004818439483642578
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.42808965677114,
    "kernel_usage": 7.044627801774098,
    "cpu_runtime": 0.000908849,
    "total_runtime": 0.0004031658172607422
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 204.67525195902968,
    "kernel_usage": 6.3961016237196775,
    "cpu_runtime": 0.00018104200000000002,
    "total_runtime": 8.845329284667969e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.91593984,
    "kernel_usage": 6.12237312,
    "cpu_runtime": 0.000154143,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.0964780648021,
    "kernel_usage": 8.878014939525066,
    "cpu_runtime": 0.001283557,
    "total_runtime": 0.00045180320739746094
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.5595380390356,
    "kernel_usage": 6.6112355637198625,
    "cpu_runtime": 0.00043933000000000004,
    "total_runtime": 0.00020766258239746094
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.30604607417774,
    "kernel_usage": 6.2908139398180545,
    "cpu_runtime": 0.0027434,
    "total_runtime": 0.0013628005981445312
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.19562930973453,
    "kernel_usage": 6.006113415929204,
    "cpu_runtime": 0.00010356,
    "total_runtime": 5.3882598876953125e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.4680209655172,
    "kernel_usage": 5.764625655172413,
    "cpu_runtime": 0.000102035,
    "total_runtime": 5.53131103515625e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.76814987636365,
    "kernel_usage": 4.649004683636364,
    "cpu_runtime": 3.9016e-05,
    "total_runtime": 2.6226043701171875e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.090978722502,
    "kernel_usage": 6.2528430850781875,
    "cpu_runtime": 0.001799925,
    "total_runtime": 0.0008995532989501953
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.01562930269097,
    "kernel_usage": 8.656738415709093,
    "cpu_runtime": 0.0009081280000000001,
    "total_runtime": 0.00032782554626464844
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 218.2134357968569,
    "kernel_usage": 6.8191698686517785,
    "cpu_runtime": 0.0006289959999999999,
    "total_runtime": 0.00028824806213378906
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.21561599999998,
    "kernel_usage": 6.9754879999999995,
    "cpu_runtime": 0.0003406,
    "total_runtime": 0.000152587890625
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 277.32522494903645,
    "kernel_usage": 8.66641327965739,
    "cpu_runtime": 0.0006175560000000001,
    "total_runtime": 0.00022268295288085938
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 240.9444401708738,
    "kernel_usage": 7.529513755339806,
    "cpu_runtime": 0.000769197,
    "total_runtime": 0.0003192424774169922
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.02384534377626,
    "kernel_usage": 11.563245166993008,
    "cpu_runtime": 0.0018923310000000001,
    "total_runtime": 0.0005114078521728516
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 183.76303392933107,
    "kernel_usage": 5.742594810291596,
    "cpu_runtime": 0.000255427,
    "total_runtime": 0.00013899803161621094
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 225.9581097579618,
    "kernel_usage": 7.0611909299363065,
    "cpu_runtime": 0.00025374,
    "total_runtime": 0.00011229515075683594
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.5271212669797,
    "kernel_usage": 6.328972539593115,
    "cpu_runtime": 0.00030854900000000003,
    "total_runtime": 0.00015234947204589844
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 261.3675840421608,
    "kernel_usage": 8.167737001317525,
    "cpu_runtime": 0.0004729700000000001,
    "total_runtime": 0.00018095970153808594
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 264.652927597231,
    "kernel_usage": 8.270403987413468,
    "cpu_runtime": 0.00200526,
    "total_runtime": 0.0007576942443847656
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.2575465785124,
    "kernel_usage": 7.633048330578513,
    "cpu_runtime": 0.000775115,
    "total_runtime": 0.0003173351287841797
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.4650956104812,
    "kernel_usage": 6.6707842378275375,
    "cpu_runtime": 0.001068266,
    "total_runtime": 0.0005004405975341797
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.4703335254833,
    "kernel_usage": 6.2959479226713535,
    "cpu_runtime": 0.00054663,
    "total_runtime": 0.0002713203430175781
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.20880005828778,
    "kernel_usage": 6.600275001821493,
    "cpu_runtime": 0.000276455,
    "total_runtime": 0.0001308917999267578
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 222.61996309200575,
    "kernel_usage": 6.95687384662518,
    "cpu_runtime": 0.001108773,
    "total_runtime": 0.0004980564117431641
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 142.51998268235295,
    "kernel_usage": 4.45374945882353,
    "cpu_runtime": 3.4659e-05,
    "total_runtime": 2.4318695068359375e-05
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.9311634639363,
    "kernel_usage": 6.310348858248009,
    "cpu_runtime": 0.000423187,
    "total_runtime": 0.00020956993103027344
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 182.55450313442626,
    "kernel_usage": 5.7048282229508205,
    "cpu_runtime": 0.00021239900000000002,
    "total_runtime": 0.0001163482666015625
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.04934274276667,
    "kernel_usage": 6.251541960711458,
    "cpu_runtime": 0.5101675480000001,
    "total_runtime": 0.2550208568572998
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 194.7003732273292,
    "kernel_usage": 6.084386663354038,
    "cpu_runtime": 0.000149473,
    "total_runtime": 7.677078247070312e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.48995413333333,
    "kernel_usage": 6.7965610666666665,
    "cpu_runtime": 0.000497795,
    "total_runtime": 0.0002288818359375
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6648357815649,
    "kernel_usage": 6.239526118173903,
    "cpu_runtime": 0.011480610000000002,
    "total_runtime": 0.005749940872192383
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 254.281034749354,
    "kernel_usage": 7.946282335917313,
    "cpu_runtime": 0.00023462,
    "total_runtime": 9.226799011230469e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.20064530265745,
    "kernel_usage": 9.350020165708045,
    "cpu_runtime": 0.007838289,
    "total_runtime": 0.0026197433471679688
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.35121257094733,
    "kernel_usage": 5.979725392842104,
    "cpu_runtime": 0.00021670299999999997,
    "total_runtime": 0.00011324882507324219
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.1796553886179,
    "kernel_usage": 5.2556142308943095,
    "cpu_runtime": 9.8639e-05,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 274.20644030779897,
    "kernel_usage": 8.568951259618718,
    "cpu_runtime": 0.0007544380000000001,
    "total_runtime": 0.0002751350402832031
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 232.19857988902692,
    "kernel_usage": 7.256205621532091,
    "cpu_runtime": 0.000267391,
    "total_runtime": 0.00011515617370605469
  }
]