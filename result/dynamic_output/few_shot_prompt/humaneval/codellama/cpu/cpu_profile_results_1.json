[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.53207955778427,
    "kernel_usage": 6.6103774861807585,
    "cpu_runtime": 0.0008649290000000001,
    "total_runtime": 0.0004088878631591797
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.02598903456496,
    "kernel_usage": 6.875812157330155,
    "cpu_runtime": 0.0008802500000000001,
    "total_runtime": 0.0004000663757324219
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 129.45835804444445,
    "kernel_usage": 4.045573688888889,
    "cpu_runtime": 2.2223e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 163.60006113882355,
    "kernel_usage": 5.112501910588236,
    "cpu_runtime": 6.6309e-05,
    "total_runtime": 4.0531158447265625e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 389.098894311811,
    "kernel_usage": 12.159340447244094,
    "cpu_runtime": 0.0009425270000000001,
    "total_runtime": 0.0002422332763671875
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 200.9332401740933,
    "kernel_usage": 6.279163755440416,
    "cpu_runtime": 9.245900000000002e-05,
    "total_runtime": 4.601478576660156e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 154.0047454814815,
    "kernel_usage": 4.812648296296297,
    "cpu_runtime": 3.9655000000000006e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.40673721271392,
    "kernel_usage": 6.73146053789731,
    "cpu_runtime": 0.00021005,
    "total_runtime": 9.751319885253906e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.5509809848185,
    "kernel_usage": 6.673468155775578,
    "cpu_runtime": 0.000154271,
    "total_runtime": 7.224082946777344e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.07240877252525,
    "kernel_usage": 10.096012774141414,
    "cpu_runtime": 0.00038128099999999997,
    "total_runtime": 0.00011801719665527344
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.18591157994103,
    "kernel_usage": 9.255809736873157,
    "cpu_runtime": 0.00023938900000000004,
    "total_runtime": 8.082389831542969e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 154.40071884800005,
    "kernel_usage": 4.825022464000002,
    "cpu_runtime": 2.7609000000000006e-05,
    "total_runtime": 1.7881393432617188e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 198.98713956972108,
    "kernel_usage": 6.218348111553784,
    "cpu_runtime": 0.00011907999999999999,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 238.84784032542368,
    "kernel_usage": 7.46399501016949,
    "cpu_runtime": 0.00016798999999999997,
    "total_runtime": 7.033348083496094e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.87086812862745,
    "kernel_usage": 6.214714629019608,
    "cpu_runtime": 0.000120907,
    "total_runtime": 6.079673767089844e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.398351120499,
    "kernel_usage": 6.731198472515594,
    "cpu_runtime": 0.0012350870000000002,
    "total_runtime": 0.0005733966827392578
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.67117691106637,
    "kernel_usage": 6.989724278470824,
    "cpu_runtime": 0.000265037,
    "total_runtime": 0.00011849403381347656
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 258.95497048097167,
    "kernel_usage": 8.092342827530365,
    "cpu_runtime": 0.000152497,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 172.01889280000003,
    "kernel_usage": 5.375590400000001,
    "cpu_runtime": 2.6248000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 198.03598093004356,
    "kernel_usage": 6.188624404063861,
    "cpu_runtime": 0.000650629,
    "total_runtime": 0.0003285408020019531
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 206.391116082243,
    "kernel_usage": 6.449722377570094,
    "cpu_runtime": 5.2652000000000003e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 172.0329590634146,
    "kernel_usage": 5.3760299707317065,
    "cpu_runtime": 3.3632999999999995e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.5862833005715,
    "kernel_usage": 8.26832135314286,
    "cpu_runtime": 0.00011039400000000001,
    "total_runtime": 4.172325134277344e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.09947498426968,
    "kernel_usage": 6.315608593258427,
    "cpu_runtime": 8.576800000000001e-05,
    "total_runtime": 4.2438507080078125e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.73295164834977,
    "kernel_usage": 6.24165473901093,
    "cpu_runtime": 0.017602274,
    "total_runtime": 0.008812904357910156
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 363.1896772206447,
    "kernel_usage": 11.349677413145146,
    "cpu_runtime": 1.0336283670000002,
    "total_runtime": 0.28459739685058594
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 174.31930217286015,
    "kernel_usage": 5.44747819290188,
    "cpu_runtime": 0.000199077,
    "total_runtime": 0.00011420249938964844
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 177.3337513220339,
    "kernel_usage": 5.541679728813559,
    "cpu_runtime": 2.4945e-05,
    "total_runtime": 1.4066696166992188e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 160.13721600000002,
    "kernel_usage": 5.004288000000001,
    "cpu_runtime": 2.4435000000000002e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 204.90173683809525,
    "kernel_usage": 6.403179276190476,
    "cpu_runtime": 0.000246216,
    "total_runtime": 0.0001201629638671875
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 166.31790541639347,
    "kernel_usage": 5.197434544262296,
    "cpu_runtime": 4.837700000000001e-05,
    "total_runtime": 2.9087066650390625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 197.4246182787879,
    "kernel_usage": 6.169519321212122,
    "cpu_runtime": 6.213200000000001e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 169.61313815320912,
    "kernel_usage": 5.300410567287785,
    "cpu_runtime": 0.00019532000000000002,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 134.48736182857144,
    "kernel_usage": 4.202730057142857,
    "cpu_runtime": 1.3467000000000002e-05,
    "total_runtime": 1.0013580322265625e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.146267256899,
    "kernel_usage": 6.754570851778094,
    "cpu_runtime": 0.000362279,
    "total_runtime": 0.00016760826110839844
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.43288140200673,
    "kernel_usage": 6.48227754381271,
    "cpu_runtime": 0.00014787300000000003,
    "total_runtime": 7.128715515136719e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 152.87842390943396,
    "kernel_usage": 4.777450747169811,
    "cpu_runtime": 3.8636e-05,
    "total_runtime": 2.5272369384765625e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 260.1146970352941,
    "kernel_usage": 8.128584282352941,
    "cpu_runtime": 0.000253026,
    "total_runtime": 9.72747802734375e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.36435279045236,
    "kernel_usage": 11.230136024701636,
    "cpu_runtime": 0.24451969299999998,
    "total_runtime": 0.06804227828979492
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.768834138022,
    "kernel_usage": 8.742776066813187,
    "cpu_runtime": 0.000606989,
    "total_runtime": 0.00021696090698242188
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 155.1925506015748,
    "kernel_usage": 4.849767206299212,
    "cpu_runtime": 4.6991e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.24196142765425,
    "kernel_usage": 9.320061294614195,
    "cpu_runtime": 0.017453783000000004,
    "total_runtime": 0.005852222442626953
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.90680403934428,
    "kernel_usage": 5.528337626229509,
    "cpu_runtime": 0.000102914,
    "total_runtime": 5.817413330078125e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.65092933947918,
    "kernel_usage": 6.239091541858724,
    "cpu_runtime": 0.005721103000000001,
    "total_runtime": 0.0028655529022216797
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 185.05751709684603,
    "kernel_usage": 5.783047409276438,
    "cpu_runtime": 0.000237813,
    "total_runtime": 0.0001285076141357422
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 190.97732122755343,
    "kernel_usage": 5.968041288361045,
    "cpu_runtime": 0.000191692,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.20788252269938,
    "kernel_usage": 6.193996328834356,
    "cpu_runtime": 0.000231084,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 202.2947450097769,
    "kernel_usage": 6.321710781555528,
    "cpu_runtime": 0.019130757,
    "total_runtime": 0.009456872940063477
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 217.6625322666667,
    "kernel_usage": 6.801954133333334,
    "cpu_runtime": 9.963800000000001e-05,
    "total_runtime": 4.57763671875e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 185.44493757629633,
    "kernel_usage": 5.79515429925926,
    "cpu_runtime": 0.00023875300000000002,
    "total_runtime": 0.00012874603271484375
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 202.72008420805864,
    "kernel_usage": 6.335002631501832,
    "cpu_runtime": 0.00013194700000000002,
    "total_runtime": 6.508827209472656e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90010436069366,
    "kernel_usage": 6.246878261271677,
    "cpu_runtime": 0.029022972,
    "total_runtime": 0.01451873779296875
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.79170741933035,
    "kernel_usage": 11.305990856854073,
    "cpu_runtime": 0.001365462,
    "total_runtime": 0.00037741661071777344
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.73074244276805,
    "kernel_usage": 6.3978357013365015,
    "cpu_runtime": 0.0016434870000000001,
    "total_runtime": 0.0008027553558349609
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 203.22334947555558,
    "kernel_usage": 6.350729671111112,
    "cpu_runtime": 0.00017442800000000002,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.95765526840148,
    "kernel_usage": 6.154926727137546,
    "cpu_runtime": 0.000126318,
    "total_runtime": 6.413459777832031e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 192.838400927163,
    "kernel_usage": 6.026200028973844,
    "cpu_runtime": 0.00022850200000000003,
    "total_runtime": 0.00011849403381347656
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.2252026434783,
    "kernel_usage": 6.038287582608697,
    "cpu_runtime": 0.000254298,
    "total_runtime": 0.0001316070556640625
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.84896914285716,
    "kernel_usage": 5.776530285714286,
    "cpu_runtime": 5.5530000000000005e-05,
    "total_runtime": 3.0040740966796875e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.5782401394336,
    "kernel_usage": 6.0805700043573,
    "cpu_runtime": 0.00021293500000000003,
    "total_runtime": 0.00010943412780761719
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.2929375166333,
    "kernel_usage": 6.07165429739479,
    "cpu_runtime": 0.000231152,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 280.8825457395974,
    "kernel_usage": 8.777579554362418,
    "cpu_runtime": 0.00039912700000000004,
    "total_runtime": 0.00014209747314453125
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.55311529638556,
    "kernel_usage": 6.736034853012049,
    "cpu_runtime": 0.000170621,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 288.9160440065253,
    "kernel_usage": 9.028626375203915,
    "cpu_runtime": 0.000844505,
    "total_runtime": 0.0002923011779785156
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.88391930395056,
    "kernel_usage": 8.683872478248455,
    "cpu_runtime": 0.0013919690000000003,
    "total_runtime": 0.0005009174346923828
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.87011285357755,
    "kernel_usage": 7.0584410266742985,
    "cpu_runtime": 0.000940788,
    "total_runtime": 0.0004165172576904297
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 204.47232,
    "kernel_usage": 6.38976,
    "cpu_runtime": 0.00018915000000000002,
    "total_runtime": 9.250640869140625e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.18677204114286,
    "kernel_usage": 6.130836626285714,
    "cpu_runtime": 0.000163711,
    "total_runtime": 8.344650268554688e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 283.496195281073,
    "kernel_usage": 8.859256102533532,
    "cpu_runtime": 0.001360602,
    "total_runtime": 0.0004799365997314453
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.82886149446807,
    "kernel_usage": 6.619651921702127,
    "cpu_runtime": 0.000474737,
    "total_runtime": 0.00022411346435546875
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.34916068874173,
    "kernel_usage": 6.292161271523179,
    "cpu_runtime": 0.0028995250000000005,
    "total_runtime": 0.0014400482177734375
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 190.0285174278481,
    "kernel_usage": 5.938391169620253,
    "cpu_runtime": 0.000107376,
    "total_runtime": 5.650520324707031e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 183.94505383183676,
    "kernel_usage": 5.748282932244899,
    "cpu_runtime": 0.000107447,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.73918386554624,
    "kernel_usage": 4.64809949579832,
    "cpu_runtime": 4.22e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.18037881027752,
    "kernel_usage": 6.255636837821172,
    "cpu_runtime": 0.0018575240000000002,
    "total_runtime": 0.0009279251098632812
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.4149884679864,
    "kernel_usage": 8.669218389624575,
    "cpu_runtime": 0.0009689640000000001,
    "total_runtime": 0.00034928321838378906
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.50455736682775,
    "kernel_usage": 6.890767417713367,
    "cpu_runtime": 0.0006529490000000001,
    "total_runtime": 0.0002961158752441406
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.0161719391813,
    "kernel_usage": 6.969255373099416,
    "cpu_runtime": 0.000363691,
    "total_runtime": 0.00016307830810546875
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 276.4626174191726,
    "kernel_usage": 8.639456794349144,
    "cpu_runtime": 0.000653206,
    "total_runtime": 0.00023627281188964844
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 241.8220063729578,
    "kernel_usage": 7.556937699154931,
    "cpu_runtime": 0.0008186990000000001,
    "total_runtime": 0.00033855438232421875
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 369.8521489253918,
    "kernel_usage": 11.557879653918494,
    "cpu_runtime": 0.001969051,
    "total_runtime": 0.0005323886871337891
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.10732925490194,
    "kernel_usage": 5.753354039215686,
    "cpu_runtime": 0.000268635,
    "total_runtime": 0.00014591217041015625
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 227.52479617267332,
    "kernel_usage": 7.110149880396041,
    "cpu_runtime": 0.00027394300000000007,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 201.38263923406754,
    "kernel_usage": 6.293207476064611,
    "cpu_runtime": 0.000326971,
    "total_runtime": 0.00016236305236816406
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 260.507212115508,
    "kernel_usage": 8.140850378609626,
    "cpu_runtime": 0.000464581,
    "total_runtime": 0.00017833709716796875
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 263.4454845745258,
    "kernel_usage": 8.23267139295393,
    "cpu_runtime": 0.00208593,
    "total_runtime": 0.0007917881011962891
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.03432902942055,
    "kernel_usage": 7.626072782169392,
    "cpu_runtime": 0.0007831340000000001,
    "total_runtime": 0.0003209114074707031
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.31164502567813,
    "kernel_usage": 6.665988907052442,
    "cpu_runtime": 0.0011249670000000002,
    "total_runtime": 0.0005273818969726562
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.51129529541288,
    "kernel_usage": 6.2972279779816525,
    "cpu_runtime": 0.0005760480000000001,
    "total_runtime": 0.00028586387634277344
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.77226484672568,
    "kernel_usage": 6.617883276460177,
    "cpu_runtime": 0.00028527100000000003,
    "total_runtime": 0.0001347064971923828
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.27861650885245,
    "kernel_usage": 6.977456765901639,
    "cpu_runtime": 0.001136541,
    "total_runtime": 0.0005090236663818359
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 142.77244704950496,
    "kernel_usage": 4.46163897029703,
    "cpu_runtime": 3.438e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.91471638505493,
    "kernel_usage": 6.309834887032967,
    "cpu_runtime": 0.000438076,
    "total_runtime": 0.00021696090698242188
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 182.50521413618844,
    "kernel_usage": 5.703287941755889,
    "cpu_runtime": 0.00020320400000000001,
    "total_runtime": 0.00011134147644042969
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.0506448102599,
    "kernel_usage": 6.251582650320622,
    "cpu_runtime": 0.5341976230000001,
    "total_runtime": 0.267031192779541
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.8739968,
    "kernel_usage": 6.1210624,
    "cpu_runtime": 0.00014150099999999999,
    "total_runtime": 7.224082946777344e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.26030094179256,
    "kernel_usage": 6.789384404431018,
    "cpu_runtime": 0.000514363,
    "total_runtime": 0.00023674964904785156
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.65168425824783,
    "kernel_usage": 6.239115133070245,
    "cpu_runtime": 0.01206201,
    "total_runtime": 0.006041526794433594
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 252.7198905137157,
    "kernel_usage": 7.897496578553616,
    "cpu_runtime": 0.000241615,
    "total_runtime": 9.560585021972656e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 298.32753816902107,
    "kernel_usage": 9.322735567781908,
    "cpu_runtime": 0.008035909,
    "total_runtime": 0.002693653106689453
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.09503224242425,
    "kernel_usage": 5.971719757575758,
    "cpu_runtime": 0.00022552500000000002,
    "total_runtime": 0.00011801719665527344
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 167.66974094883722,
    "kernel_usage": 5.239679404651163,
    "cpu_runtime": 0.00010313700000000001,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 273.63293009738857,
    "kernel_usage": 8.551029065543393,
    "cpu_runtime": 0.0007743890000000005,
    "total_runtime": 0.0002830028533935547
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 233.71032469076306,
    "kernel_usage": 7.303447646586346,
    "cpu_runtime": 0.00027749000000000003,
    "total_runtime": 0.00011873245239257812
  }
]