[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.28745928489045,
    "kernel_usage": 6.602733102652826,
    "cpu_runtime": 0.0008735,
    "total_runtime": 0.0004134178161621094
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.21037426769055,
    "kernel_usage": 6.88157419586533,
    "cpu_runtime": 0.0008888630000000002,
    "total_runtime": 0.0004036426544189453
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 128.19117541052634,
    "kernel_usage": 4.005974231578948,
    "cpu_runtime": 2.3228000000000005e-05,
    "total_runtime": 1.811981201171875e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 164.9181048643678,
    "kernel_usage": 5.1536907770114935,
    "cpu_runtime": 6.841599999999999e-05,
    "total_runtime": 4.1484832763671875e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 388.4081316497992,
    "kernel_usage": 12.137754114056225,
    "cpu_runtime": 0.000922333,
    "total_runtime": 0.00023746490478515625
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 199.4996915463918,
    "kernel_usage": 6.234365360824744,
    "cpu_runtime": 9.227500000000002e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.17522634954958,
    "kernel_usage": 4.786725823423424,
    "cpu_runtime": 4.0537e-05,
    "total_runtime": 2.6464462280273438e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.43138223838383,
    "kernel_usage": 6.763480694949495,
    "cpu_runtime": 0.000204341,
    "total_runtime": 9.441375732421875e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 212.10250590684936,
    "kernel_usage": 6.6282033095890425,
    "cpu_runtime": 0.00014766200000000004,
    "total_runtime": 6.961822509765625e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.1413404154786,
    "kernel_usage": 10.066916887983707,
    "cpu_runtime": 0.00037711,
    "total_runtime": 0.00011706352233886719
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.56955667692307,
    "kernel_usage": 9.267798646153846,
    "cpu_runtime": 0.00023899200000000002,
    "total_runtime": 8.058547973632812e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.73940995324676,
    "kernel_usage": 4.866856561038961,
    "cpu_runtime": 2.8591e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 199.0633798008163,
    "kernel_usage": 6.22073061877551,
    "cpu_runtime": 0.000116278,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.8034613372694,
    "kernel_usage": 7.368858166789669,
    "cpu_runtime": 0.000152356,
    "total_runtime": 6.461143493652344e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.1891746816,
    "kernel_usage": 6.2246617088,
    "cpu_runtime": 0.000118726,
    "total_runtime": 5.9604644775390625e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 214.78651096582064,
    "kernel_usage": 6.712078467681895,
    "cpu_runtime": 0.001210583,
    "total_runtime": 0.0005636215209960938
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.56145657831328,
    "kernel_usage": 6.98629551807229,
    "cpu_runtime": 0.00026544000000000003,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.08438635789474,
    "kernel_usage": 8.15888707368421,
    "cpu_runtime": 0.000153751,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 172.71877566984128,
    "kernel_usage": 5.39746173968254,
    "cpu_runtime": 2.5943000000000002e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 198.0450204769344,
    "kernel_usage": 6.1889068899042,
    "cpu_runtime": 0.000640743,
    "total_runtime": 0.0003235340118408203
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 208.95683594343436,
    "kernel_usage": 6.529901123232324,
    "cpu_runtime": 4.9321000000000004e-05,
    "total_runtime": 2.3603439331054688e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 174.22493538461538,
    "kernel_usage": 5.444529230769231,
    "cpu_runtime": 3.24e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 263.18775496091956,
    "kernel_usage": 8.224617342528736,
    "cpu_runtime": 0.00010918300000000001,
    "total_runtime": 4.1484832763671875e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.09961198139536,
    "kernel_usage": 6.315612874418605,
    "cpu_runtime": 8.2877e-05,
    "total_runtime": 4.100799560546875e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.7316754145325,
    "kernel_usage": 6.241614856704141,
    "cpu_runtime": 0.01736692,
    "total_runtime": 0.008695125579833984
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 363.0448240114688,
    "kernel_usage": 11.3451507503584,
    "cpu_runtime": 1.004191949,
    "total_runtime": 0.27660274505615234
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 176.37707801761007,
    "kernel_usage": 5.511783688050315,
    "cpu_runtime": 0.000200586,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 180.31952705084746,
    "kernel_usage": 5.634985220338983,
    "cpu_runtime": 2.5365000000000002e-05,
    "total_runtime": 1.4066696166992188e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 160.7883109587302,
    "kernel_usage": 5.0246347174603185,
    "cpu_runtime": 2.4151000000000003e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 205.36943502222223,
    "kernel_usage": 6.417794844444445,
    "cpu_runtime": 0.000246778,
    "total_runtime": 0.0001201629638671875
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.31551301818183,
    "kernel_usage": 5.259859781818182,
    "cpu_runtime": 5.2971000000000005e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 198.63827431811026,
    "kernel_usage": 6.207446072440946,
    "cpu_runtime": 6.0146e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 169.16130655206615,
    "kernel_usage": 5.286290829752067,
    "cpu_runtime": 0.00019520300000000002,
    "total_runtime": 0.00011539459228515625
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 132.35260132765958,
    "kernel_usage": 4.136018791489362,
    "cpu_runtime": 1.4831e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 215.9573461937677,
    "kernel_usage": 6.748667068555241,
    "cpu_runtime": 0.000363507,
    "total_runtime": 0.00016832351684570312
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 206.46354805152544,
    "kernel_usage": 6.45198587661017,
    "cpu_runtime": 0.000145213,
    "total_runtime": 7.033348083496094e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.48816308148147,
    "kernel_usage": 4.734005096296296,
    "cpu_runtime": 3.9007e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 259.6755318104738,
    "kernel_usage": 8.114860369077306,
    "cpu_runtime": 0.000248265,
    "total_runtime": 9.560585021972656e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 358.98246178338366,
    "kernel_usage": 11.21820193073074,
    "cpu_runtime": 0.237237343,
    "total_runtime": 0.0660860538482666
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.0605489656428,
    "kernel_usage": 8.720642155176337,
    "cpu_runtime": 0.0005848270000000001,
    "total_runtime": 0.00020956993103027344
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 154.63235721680675,
    "kernel_usage": 4.832261163025211,
    "cpu_runtime": 4.387200000000001e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.17763587068816,
    "kernel_usage": 9.318051120959005,
    "cpu_runtime": 0.016664462,
    "total_runtime": 0.0055887699127197266
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.9002456931727,
    "kernel_usage": 5.528132677911647,
    "cpu_runtime": 0.000105019,
    "total_runtime": 5.936622619628906e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.63167946013604,
    "kernel_usage": 6.238489983129251,
    "cpu_runtime": 0.005597278,
    "total_runtime": 0.002803802490234375
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 184.64122800620157,
    "kernel_usage": 5.770038375193799,
    "cpu_runtime": 0.00022715300000000004,
    "total_runtime": 0.00012302398681640625
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 189.759750144,
    "kernel_usage": 5.929992192,
    "cpu_runtime": 0.000180969,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.45608676789587,
    "kernel_usage": 6.201752711496746,
    "cpu_runtime": 0.000218125,
    "total_runtime": 0.00010991096496582031
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 202.31423213818007,
    "kernel_usage": 6.322319754318127,
    "cpu_runtime": 0.018112902,
    "total_runtime": 0.008952856063842773
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 219.07243732154694,
    "kernel_usage": 6.846013666298342,
    "cpu_runtime": 9.4538e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 184.93023808735632,
    "kernel_usage": 5.779069940229885,
    "cpu_runtime": 0.000230154,
    "total_runtime": 0.00012445449829101562
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 204.37477804651164,
    "kernel_usage": 6.386711813953489,
    "cpu_runtime": 0.000125715,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90136201003423,
    "kernel_usage": 6.24691756281357,
    "cpu_runtime": 0.02868858,
    "total_runtime": 0.014351367950439453
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 362.6837114140555,
    "kernel_usage": 11.333865981689234,
    "cpu_runtime": 0.001341158,
    "total_runtime": 0.00036978721618652344
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.3289266619447,
    "kernel_usage": 6.385278958185772,
    "cpu_runtime": 0.0015681620000000001,
    "total_runtime": 0.0007674694061279297
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 205.07089487113706,
    "kernel_usage": 6.408465464723033,
    "cpu_runtime": 0.00016770200000000001,
    "total_runtime": 8.177757263183594e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.3963597322449,
    "kernel_usage": 6.106136241632653,
    "cpu_runtime": 0.00011413599999999999,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.07523663089435,
    "kernel_usage": 6.0336011447154485,
    "cpu_runtime": 0.00022648100000000003,
    "total_runtime": 0.00011730194091796875
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.30548492190476,
    "kernel_usage": 6.040796403809524,
    "cpu_runtime": 0.00024196,
    "total_runtime": 0.0001251697540283203
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.4211204231405,
    "kernel_usage": 5.763160013223141,
    "cpu_runtime": 5.3203000000000005e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.7613009802299,
    "kernel_usage": 6.086290655632184,
    "cpu_runtime": 0.000201991,
    "total_runtime": 0.00010371208190917969
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.43654770459085,
    "kernel_usage": 6.076142115768464,
    "cpu_runtime": 0.00023225000000000003,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 279.4596230664273,
    "kernel_usage": 8.733113220825853,
    "cpu_runtime": 0.00037112,
    "total_runtime": 0.0001327991485595703
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.08947346751597,
    "kernel_usage": 6.752796045859874,
    "cpu_runtime": 0.00016177200000000002,
    "total_runtime": 7.486343383789062e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 287.8751280253545,
    "kernel_usage": 8.996097750792329,
    "cpu_runtime": 0.0008229310000000002,
    "total_runtime": 0.00028586387634277344
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.4740885532124,
    "kernel_usage": 8.671065267287888,
    "cpu_runtime": 0.0013489000000000003,
    "total_runtime": 0.00048613548278808594
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.26197381616632,
    "kernel_usage": 7.039436681755197,
    "cpu_runtime": 0.000930199,
    "total_runtime": 0.00041294097900390625
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 204.21031506843502,
    "kernel_usage": 6.3815723458885945,
    "cpu_runtime": 0.00018355200000000002,
    "total_runtime": 8.988380432128906e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.7584650730539,
    "kernel_usage": 6.117452033532935,
    "cpu_runtime": 0.00015588600000000002,
    "total_runtime": 7.963180541992188e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 283.20051275651724,
    "kernel_usage": 8.850016023641164,
    "cpu_runtime": 0.0012795090000000003,
    "total_runtime": 0.00045180320739746094
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.80309305077262,
    "kernel_usage": 6.618846657836644,
    "cpu_runtime": 0.00045751,
    "total_runtime": 0.00021600723266601562
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.18458344703916,
    "kernel_usage": 6.287018232719974,
    "cpu_runtime": 0.0028674160000000002,
    "total_runtime": 0.0014252662658691406
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 190.85922807017545,
    "kernel_usage": 5.964350877192983,
    "cpu_runtime": 0.00010375000000000001,
    "total_runtime": 5.435943603515625e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.89920659563322,
    "kernel_usage": 5.778100206113538,
    "cpu_runtime": 0.00010095100000000002,
    "total_runtime": 5.459785461425781e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 147.587072,
    "kernel_usage": 4.612096,
    "cpu_runtime": 3.9410000000000004e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.17493373695245,
    "kernel_usage": 6.255466679279764,
    "cpu_runtime": 0.0017758630000000001,
    "total_runtime": 0.0008871555328369141
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 276.1723289898108,
    "kernel_usage": 8.630385280931588,
    "cpu_runtime": 0.0009047050000000001,
    "total_runtime": 0.0003275871276855469
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 219.693449216,
    "kernel_usage": 6.865420288,
    "cpu_runtime": 0.000628548,
    "total_runtime": 0.000286102294921875
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.85904463782148,
    "kernel_usage": 6.964345144931921,
    "cpu_runtime": 0.00035121400000000003,
    "total_runtime": 0.0001575946807861328
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 276.085444427673,
    "kernel_usage": 8.627670138364781,
    "cpu_runtime": 0.00062796,
    "total_runtime": 0.00022745132446289062
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 241.73573274466526,
    "kernel_usage": 7.554241648270789,
    "cpu_runtime": 0.0007832500000000001,
    "total_runtime": 0.00032401084899902344
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.95628587971765,
    "kernel_usage": 11.592383933741177,
    "cpu_runtime": 0.001879411,
    "total_runtime": 0.0005066394805908203
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 183.92451030204083,
    "kernel_usage": 5.747640946938776,
    "cpu_runtime": 0.000257844,
    "total_runtime": 0.00014019012451171875
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 226.33948935095952,
    "kernel_usage": 7.073109042217485,
    "cpu_runtime": 0.000253089,
    "total_runtime": 0.00011181831359863281
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.44861817305866,
    "kernel_usage": 6.326519317908083,
    "cpu_runtime": 0.000304568,
    "total_runtime": 0.00015044212341308594
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 261.06207900762155,
    "kernel_usage": 8.158189968988173,
    "cpu_runtime": 0.000473662,
    "total_runtime": 0.00018143653869628906
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 263.932507079397,
    "kernel_usage": 8.247890846231156,
    "cpu_runtime": 0.0020035770000000003,
    "total_runtime": 0.000759124755859375
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 242.97937978403047,
    "kernel_usage": 7.593105618250952,
    "cpu_runtime": 0.0007617900000000001,
    "total_runtime": 0.0003135204315185547
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.71182986411483,
    "kernel_usage": 6.6784946832535885,
    "cpu_runtime": 0.001064915,
    "total_runtime": 0.0004982948303222656
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.432374270194,
    "kernel_usage": 6.294761695943563,
    "cpu_runtime": 0.000544606,
    "total_runtime": 0.0002703666687011719
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 210.44579627436826,
    "kernel_usage": 6.576431133574008,
    "cpu_runtime": 0.000277965,
    "total_runtime": 0.00013208389282226562
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 221.73202761398608,
    "kernel_usage": 6.929125862937065,
    "cpu_runtime": 0.0011339550000000003,
    "total_runtime": 0.0005114078521728516
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.51323091134023,
    "kernel_usage": 4.516038465979382,
    "cpu_runtime": 3.3421000000000004e-05,
    "total_runtime": 2.3126602172851562e-05
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.96251881005992,
    "kernel_usage": 6.3113287128143725,
    "cpu_runtime": 0.0004020660000000001,
    "total_runtime": 0.0001990795135498047
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.00255355780223,
    "kernel_usage": 5.71882979868132,
    "cpu_runtime": 0.00019852200000000002,
    "total_runtime": 0.00010848045349121094
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.0503512423842,
    "kernel_usage": 6.2515734763245066,
    "cpu_runtime": 0.5109489910000001,
    "total_runtime": 0.25541019439697266
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.44576716083918,
    "kernel_usage": 6.107680223776224,
    "cpu_runtime": 0.00013327,
    "total_runtime": 6.818771362304688e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.5155447097998,
    "kernel_usage": 6.797360772181244,
    "cpu_runtime": 0.000492149,
    "total_runtime": 0.0002262592315673828
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.64651068576708,
    "kernel_usage": 6.238953458930221,
    "cpu_runtime": 0.011337234000000002,
    "total_runtime": 0.005678653717041016
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 252.1907158730479,
    "kernel_usage": 7.880959871032747,
    "cpu_runtime": 0.00023870400000000004,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 298.1543225216914,
    "kernel_usage": 9.317322578802857,
    "cpu_runtime": 0.007766805000000001,
    "total_runtime": 0.002604961395263672
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 190.84259802273687,
    "kernel_usage": 5.963831188210527,
    "cpu_runtime": 0.000216127,
    "total_runtime": 0.00011324882507324219
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 167.34926323305785,
    "kernel_usage": 5.229664476033058,
    "cpu_runtime": 9.6556e-05,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 273.86601394384144,
    "kernel_usage": 8.558312935745045,
    "cpu_runtime": 0.0007580719999999998,
    "total_runtime": 0.00027680397033691406
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 229.9525058189135,
    "kernel_usage": 7.186015806841047,
    "cpu_runtime": 0.00027248,
    "total_runtime": 0.00011849403381347656
  }
]