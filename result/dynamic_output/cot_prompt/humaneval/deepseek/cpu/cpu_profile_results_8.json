[
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 127.87512195121953,
    "kernel_usage": 3.99609756097561,
    "cpu_runtime": 2.5e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.2335008855615,
    "kernel_usage": 5.194796902673797,
    "cpu_runtime": 7.4114e-05,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.98842539903384,
    "kernel_usage": 6.155888293719808,
    "cpu_runtime": 9.721900000000002e-05,
    "total_runtime": 4.935264587402344e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.69608310813402,
    "kernel_usage": 6.396752597129188,
    "cpu_runtime": 0.00010199900000000001,
    "total_runtime": 4.982948303222656e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 217.21815476186612,
    "kernel_usage": 6.788067336308316,
    "cpu_runtime": 0.000255319,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.0497680623377,
    "kernel_usage": 6.689055251948053,
    "cpu_runtime": 0.00015718300000000003,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 321.1223023583166,
    "kernel_usage": 10.035071948697393,
    "cpu_runtime": 0.00038204199999999997,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 298.77851507590026,
    "kernel_usage": 9.336828596121883,
    "cpu_runtime": 0.000257156,
    "total_runtime": 8.606910705566406e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.24691968000002,
    "kernel_usage": 4.851466240000001,
    "cpu_runtime": 2.9611000000000005e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.45943919647578,
    "kernel_usage": 6.608107474889868,
    "cpu_runtime": 0.000114444,
    "total_runtime": 5.412101745605469e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.27577372054796,
    "kernel_usage": 7.383617928767124,
    "cpu_runtime": 0.000164491,
    "total_runtime": 6.961822509765625e-05
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.7245696,
    "kernel_usage": 8.1788928,
    "cpu_runtime": 0.000164736,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.8083352835821,
    "kernel_usage": 5.3377604776119405,
    "cpu_runtime": 2.7285e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.19178032607593,
    "kernel_usage": 5.912243135189873,
    "cpu_runtime": 0.000178172,
    "total_runtime": 9.417533874511719e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 387.58737983760903,
    "kernel_usage": 12.112105619925282,
    "cpu_runtime": 0.0014840730000000002,
    "total_runtime": 0.0003829002380371094
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 155.36530520493827,
    "kernel_usage": 4.855165787654321,
    "cpu_runtime": 3.0004e-05,
    "total_runtime": 1.9311904907226562e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.649418678453,
    "kernel_usage": 6.457794333701656,
    "cpu_runtime": 8.917699999999999e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76236204375684,
    "kernel_usage": 6.242573813867401,
    "cpu_runtime": 0.020070995,
    "total_runtime": 0.010047435760498047
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 178.48328558805972,
    "kernel_usage": 5.577602674626866,
    "cpu_runtime": 2.8511000000000002e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 190.88050784864868,
    "kernel_usage": 5.965015870270271,
    "cpu_runtime": 3.3677e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.3256709710388,
    "kernel_usage": 11.416427217844962,
    "cpu_runtime": 0.19890863300000003,
    "total_runtime": 0.05444693565368652
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 202.28264658823528,
    "kernel_usage": 6.3213327058823525,
    "cpu_runtime": 6.559e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.74475329361704,
    "kernel_usage": 4.179523540425532,
    "cpu_runtime": 1.4987000000000002e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 152.12814192280703,
    "kernel_usage": 4.75400443508772,
    "cpu_runtime": 4.1348000000000005e-05,
    "total_runtime": 2.7179718017578125e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.7813171638743,
    "kernel_usage": 11.243166161371072,
    "cpu_runtime": 0.253505639,
    "total_runtime": 0.07046103477478027
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.2995771733334,
    "kernel_usage": 8.728111786666668,
    "cpu_runtime": 0.0006392660000000001,
    "total_runtime": 0.0002288818359375
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.29600623589744,
    "kernel_usage": 8.446750194871795,
    "cpu_runtime": 0.000326729,
    "total_runtime": 0.00012087821960449219
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.06758003126,
    "kernel_usage": 9.314611875976874,
    "cpu_runtime": 0.017332006,
    "total_runtime": 0.005814790725708008
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.61231958076243,
    "kernel_usage": 6.237884986898826,
    "cpu_runtime": 0.005630525000000001,
    "total_runtime": 0.002820730209350586
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.54145374040817,
    "kernel_usage": 5.923170429387755,
    "cpu_runtime": 0.00011071600000000002,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 212.9157765907692,
    "kernel_usage": 6.653618018461538,
    "cpu_runtime": 9.8988e-05,
    "total_runtime": 4.649162292480469e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 204.79438262857147,
    "kernel_usage": 6.399824457142858,
    "cpu_runtime": 0.000136715,
    "total_runtime": 6.67572021484375e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.8926613485782,
    "kernel_usage": 6.246645667143069,
    "cpu_runtime": 0.029010930000000004,
    "total_runtime": 0.014513254165649414
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.8432128,
    "kernel_usage": 6.9013504,
    "cpu_runtime": 0.000589715,
    "total_runtime": 0.00026702880859375
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.76156839907622,
    "kernel_usage": 5.680049012471132,
    "cpu_runtime": 0.00018764200000000002,
    "total_runtime": 0.00010323524475097656
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.8324577363083,
    "kernel_usage": 6.338514304259634,
    "cpu_runtime": 0.00023841000000000002,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.7133638255639,
    "kernel_usage": 5.772292619548872,
    "cpu_runtime": 5.8572e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.20031374515466,
    "kernel_usage": 6.100009804536083,
    "cpu_runtime": 0.00022571600000000002,
    "total_runtime": 0.00011563301086425781
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.29207100952385,
    "kernel_usage": 6.16537721904762,
    "cpu_runtime": 0.00016792600000000002,
    "total_runtime": 8.511543273925781e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 210.68545379265308,
    "kernel_usage": 6.583920431020409,
    "cpu_runtime": 0.000492267,
    "total_runtime": 0.00023365020751953125
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.3101731495798,
    "kernel_usage": 4.665942910924369,
    "cpu_runtime": 4.2362e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.09534186292922,
    "kernel_usage": 6.252979433216538,
    "cpu_runtime": 0.002042313,
    "total_runtime": 0.001020669937133789
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.03323391126284,
    "kernel_usage": 6.719788559726964,
    "cpu_runtime": 0.00030043,
    "total_runtime": 0.00013971328735351562
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.79401507720928,
    "kernel_usage": 6.89981297116279,
    "cpu_runtime": 0.000679074,
    "total_runtime": 0.0003075599670410156
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.79156513875236,
    "kernel_usage": 7.180986410586011,
    "cpu_runtime": 0.000289821,
    "total_runtime": 0.00012612342834472656
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.84499355878222,
    "kernel_usage": 5.807656048711944,
    "cpu_runtime": 0.00018919900000000003,
    "total_runtime": 0.00010180473327636719
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 143.77918767407408,
    "kernel_usage": 4.493099614814815,
    "cpu_runtime": 3.7022000000000006e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 261.3540967454635,
    "kernel_usage": 8.167315523295734,
    "cpu_runtime": 0.0012705350000000002,
    "total_runtime": 0.00048613548278808594
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.14411813679652,
    "kernel_usage": 6.317003691774891,
    "cpu_runtime": 0.00044532100000000004,
    "total_runtime": 0.00022029876708984375
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 197.41572127030304,
    "kernel_usage": 6.16924128969697,
    "cpu_runtime": 0.000155323,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.3037084485196,
    "kernel_usage": 6.821990889016237,
    "cpu_runtime": 0.000544939,
    "total_runtime": 0.00024962425231933594
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.66825677277643,
    "kernel_usage": 6.2396330241492635,
    "cpu_runtime": 0.013471632,
    "total_runtime": 0.006747007369995117
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.99006160592594,
    "kernel_usage": 5.280939425185186,
    "cpu_runtime": 0.00010878400000000001,
    "total_runtime": 6.437301635742188e-05
  }
]