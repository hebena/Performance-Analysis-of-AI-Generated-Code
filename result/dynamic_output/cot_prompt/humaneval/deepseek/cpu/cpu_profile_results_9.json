[
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 131.39610530909093,
    "kernel_usage": 4.1061282909090915,
    "cpu_runtime": 2.4122e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.35988039788364,
    "kernel_usage": 5.167496262433864,
    "cpu_runtime": 7.451300000000001e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.4003012923077,
    "kernel_usage": 6.137509415384615,
    "cpu_runtime": 9.7397e-05,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.503094272,
    "kernel_usage": 6.328221696,
    "cpu_runtime": 9.6561e-05,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 217.24427711868591,
    "kernel_usage": 6.788883659958935,
    "cpu_runtime": 0.00025224200000000007,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.17686258701295,
    "kernel_usage": 6.661776955844155,
    "cpu_runtime": 0.000156542,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 320.268664832,
    "kernel_usage": 10.008395776,
    "cpu_runtime": 0.00038179,
    "total_runtime": 0.00011920928955078125
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 299.5741079337017,
    "kernel_usage": 9.361690872928179,
    "cpu_runtime": 0.00025855500000000005,
    "total_runtime": 8.630752563476562e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.19319324444442,
    "kernel_usage": 4.912287288888888,
    "cpu_runtime": 3.0356999999999998e-05,
    "total_runtime": 1.9311904907226562e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.53698682434782,
    "kernel_usage": 6.610530838260869,
    "cpu_runtime": 0.00011599900000000001,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 237.28908245034967,
    "kernel_usage": 7.415283826573427,
    "cpu_runtime": 0.000161802,
    "total_runtime": 6.818771362304688e-05
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.62523082105264,
    "kernel_usage": 8.175788463157895,
    "cpu_runtime": 0.000165921,
    "total_runtime": 6.341934204101562e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.33256348656715,
    "kernel_usage": 5.3228926089552235,
    "cpu_runtime": 2.7209e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.64434122105263,
    "kernel_usage": 5.895135663157895,
    "cpu_runtime": 0.00017091,
    "total_runtime": 9.059906005859375e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 387.15613367810795,
    "kernel_usage": 12.098629177440873,
    "cpu_runtime": 0.001522113,
    "total_runtime": 0.00039315223693847656
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 151.61385959024392,
    "kernel_usage": 4.7379331121951225,
    "cpu_runtime": 2.9641000000000003e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 192.10306151361505,
    "kernel_usage": 6.00322067230047,
    "cpu_runtime": 9.755600000000001e-05,
    "total_runtime": 5.078315734863281e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76994138256947,
    "kernel_usage": 6.242810668205296,
    "cpu_runtime": 0.020471839000000002,
    "total_runtime": 0.01024770736694336
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.7411231536232,
    "kernel_usage": 5.616910098550725,
    "cpu_runtime": 2.9569000000000004e-05,
    "total_runtime": 1.6450881958007812e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 193.88752782222224,
    "kernel_usage": 6.058985244444445,
    "cpu_runtime": 3.3283e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.71429184686843,
    "kernel_usage": 11.428571620214639,
    "cpu_runtime": 0.19767282,
    "total_runtime": 0.05405116081237793
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 197.19220662857145,
    "kernel_usage": 6.162256457142858,
    "cpu_runtime": 6.582e-05,
    "total_runtime": 3.337860107421875e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.13063288163266,
    "kernel_usage": 4.160332277551021,
    "cpu_runtime": 1.5553e-05,
    "total_runtime": 1.1682510375976562e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.29707606779664,
    "kernel_usage": 4.728033627118645,
    "cpu_runtime": 4.2565e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.5815454234026,
    "kernel_usage": 11.26817329448133,
    "cpu_runtime": 0.25039945699999994,
    "total_runtime": 0.0694432258605957
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.6818005932973,
    "kernel_usage": 8.70880626854054,
    "cpu_runtime": 0.000614597,
    "total_runtime": 0.0002205371856689453
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 271.83665524363636,
    "kernel_usage": 8.494895476363636,
    "cpu_runtime": 0.000320814,
    "total_runtime": 0.00011801719665527344
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.23536979591836,
    "kernel_usage": 9.351105306122449,
    "cpu_runtime": 0.0178986,
    "total_runtime": 0.0059814453125
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6036140792864,
    "kernel_usage": 6.2376129399777,
    "cpu_runtime": 0.0055484259999999995,
    "total_runtime": 0.002779722213745117
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 187.80651520000004,
    "kernel_usage": 5.868953600000001,
    "cpu_runtime": 0.00011462800000000001,
    "total_runtime": 6.103515625e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 213.33916742433865,
    "kernel_usage": 6.666848982010583,
    "cpu_runtime": 9.613300000000001e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.94891541843006,
    "kernel_usage": 6.435903606825939,
    "cpu_runtime": 0.000143869,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90059756291515,
    "kernel_usage": 6.2468936738410985,
    "cpu_runtime": 0.029003503000000003,
    "total_runtime": 0.014508962631225586
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.8764015676341,
    "kernel_usage": 6.902387548988566,
    "cpu_runtime": 0.000598756,
    "total_runtime": 0.00027108192443847656
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.609470574478,
    "kernel_usage": 5.675295955452437,
    "cpu_runtime": 0.00018661900000000004,
    "total_runtime": 0.00010275840759277344
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.62486946531442,
    "kernel_usage": 6.332027170791076,
    "cpu_runtime": 0.00023816600000000002,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.11067256470585,
    "kernel_usage": 5.784708517647058,
    "cpu_runtime": 6.0021999999999996e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.91456052566735,
    "kernel_usage": 6.091080016427105,
    "cpu_runtime": 0.00022631500000000002,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.0444969626016,
    "kernel_usage": 6.1263905300813,
    "cpu_runtime": 0.000172473,
    "total_runtime": 8.797645568847656e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.49810383653255,
    "kernel_usage": 6.609315744891642,
    "cpu_runtime": 0.000488619,
    "total_runtime": 0.00023102760314941406
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.40081984537815,
    "kernel_usage": 4.637525620168067,
    "cpu_runtime": 4.2104e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.14332484776122,
    "kernel_usage": 6.254478901492538,
    "cpu_runtime": 0.0020461430000000003,
    "total_runtime": 0.0010223388671875
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.10298318451612,
    "kernel_usage": 6.690718224516129,
    "cpu_runtime": 0.000316486,
    "total_runtime": 0.00014781951904296875
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.79155981557633,
    "kernel_usage": 6.8997362442367605,
    "cpu_runtime": 0.000675908,
    "total_runtime": 0.00030612945556640625
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.16443660427188,
    "kernel_usage": 7.130138643883496,
    "cpu_runtime": 0.00028015300000000005,
    "total_runtime": 0.0001227855682373047
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.13478952037914,
    "kernel_usage": 5.785462172511848,
    "cpu_runtime": 0.000186269,
    "total_runtime": 0.00010061264038085938
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.54478460540543,
    "kernel_usage": 4.5170245189189195,
    "cpu_runtime": 3.825300000000001e-05,
    "total_runtime": 2.6464462280273438e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 261.12550184767554,
    "kernel_usage": 8.16017193273986,
    "cpu_runtime": 0.00125884,
    "total_runtime": 0.0004820823669433594
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 200.44542023859654,
    "kernel_usage": 6.263919382456142,
    "cpu_runtime": 0.00043584400000000006,
    "total_runtime": 0.000217437744140625
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.5817856,
    "kernel_usage": 6.1431808,
    "cpu_runtime": 0.00014998,
    "total_runtime": 7.62939453125e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.2595270973964,
    "kernel_usage": 6.820610221793637,
    "cpu_runtime": 0.0005396250000000001,
    "total_runtime": 0.0002472400665283203
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.68486122695822,
    "kernel_usage": 6.240151913342444,
    "cpu_runtime": 0.013238042,
    "total_runtime": 0.006629467010498047
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.21986660674156,
    "kernel_usage": 5.256870831460674,
    "cpu_runtime": 0.000107085,
    "total_runtime": 6.365776062011719e-05
  }
]