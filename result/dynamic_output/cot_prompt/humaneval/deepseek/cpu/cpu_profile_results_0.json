[
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 128.42672872727272,
    "kernel_usage": 4.013335272727272,
    "cpu_runtime": 2.6945e-05,
    "total_runtime": 2.09808349609375e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.56756770049262,
    "kernel_usage": 5.173986490640394,
    "cpu_runtime": 8.0133e-05,
    "total_runtime": 4.839897155761719e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.15060391724143,
    "kernel_usage": 6.129706372413795,
    "cpu_runtime": 0.00010849700000000002,
    "total_runtime": 5.53131103515625e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.09128815774648,
    "kernel_usage": 6.377852754929577,
    "cpu_runtime": 0.000103644,
    "total_runtime": 5.078315734863281e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 217.58346201503764,
    "kernel_usage": 6.799483187969926,
    "cpu_runtime": 0.00027598000000000005,
    "total_runtime": 0.00012683868408203125
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 215.13611616676744,
    "kernel_usage": 6.723003630211482,
    "cpu_runtime": 0.00016977800000000004,
    "total_runtime": 7.891654968261719e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.5887571720227,
    "kernel_usage": 10.08089866162571,
    "cpu_runtime": 0.00040686000000000004,
    "total_runtime": 0.00012612342834472656
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.18758589506496,
    "kernel_usage": 9.25586205922078,
    "cpu_runtime": 0.000271874,
    "total_runtime": 9.179115295410156e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.2953108597701,
    "kernel_usage": 4.8529784643678155,
    "cpu_runtime": 3.2211999999999996e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 210.68156764160003,
    "kernel_usage": 6.583798988800001,
    "cpu_runtime": 0.00012557600000000002,
    "total_runtime": 5.9604644775390625e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.47109223354045,
    "kernel_usage": 7.358471632298139,
    "cpu_runtime": 0.00018077300000000004,
    "total_runtime": 7.677078247070312e-05
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.03138492631575,
    "kernel_usage": 8.094730778947367,
    "cpu_runtime": 0.00017601,
    "total_runtime": 6.794929504394531e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 171.5355423561644,
    "kernel_usage": 5.3604856986301375,
    "cpu_runtime": 2.9855e-05,
    "total_runtime": 1.7404556274414062e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.2745532599034,
    "kernel_usage": 5.914829789371981,
    "cpu_runtime": 0.000186824,
    "total_runtime": 9.870529174804688e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 387.2276498471252,
    "kernel_usage": 12.100864057722662,
    "cpu_runtime": 0.001637797,
    "total_runtime": 0.0004229545593261719
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 154.37449239540229,
    "kernel_usage": 4.824202887356321,
    "cpu_runtime": 3.2021e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 205.9381754748718,
    "kernel_usage": 6.435567983589744,
    "cpu_runtime": 9.5744e-05,
    "total_runtime": 4.649162292480469e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.75667488248337,
    "kernel_usage": 6.242396090077605,
    "cpu_runtime": 0.023504713000000003,
    "total_runtime": 0.011766672134399414
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 183.04910572307693,
    "kernel_usage": 5.720284553846154,
    "cpu_runtime": 3.4041e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 194.32110567619048,
    "kernel_usage": 6.072534552380953,
    "cpu_runtime": 3.8917e-05,
    "total_runtime": 2.002716064453125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.01374269464736,
    "kernel_usage": 11.40667945920773,
    "cpu_runtime": 0.215799386,
    "total_runtime": 0.059120893478393555
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 198.72669808219177,
    "kernel_usage": 6.210209315068493,
    "cpu_runtime": 6.9175e-05,
    "total_runtime": 3.4809112548828125e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 135.1306059294118,
    "kernel_usage": 4.222831435294118,
    "cpu_runtime": 1.6431000000000002e-05,
    "total_runtime": 1.2159347534179688e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.64284461788617,
    "kernel_usage": 4.738838894308943,
    "cpu_runtime": 4.447e-05,
    "total_runtime": 2.9325485229492188e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.9588247979934,
    "kernel_usage": 11.279963274937293,
    "cpu_runtime": 0.307757488,
    "total_runtime": 0.08526110649108887
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.73695468750736,
    "kernel_usage": 8.710529833984605,
    "cpu_runtime": 0.0011224429999999999,
    "total_runtime": 0.00040268898010253906
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.16991872554115,
    "kernel_usage": 8.442809960173161,
    "cpu_runtime": 0.0005951810000000001,
    "total_runtime": 0.00022029876708984375
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.51926539470713,
    "kernel_usage": 9.328727043584598,
    "cpu_runtime": 0.030497433,
    "total_runtime": 0.010216236114501953
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62273751431533,
    "kernel_usage": 6.238210547322354,
    "cpu_runtime": 0.008265134,
    "total_runtime": 0.004140377044677734
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.06205813932587,
    "kernel_usage": 5.9394393168539334,
    "cpu_runtime": 0.00016131900000000002,
    "total_runtime": 8.487701416015625e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 211.13058694981817,
    "kernel_usage": 6.597830842181818,
    "cpu_runtime": 0.00013842799999999998,
    "total_runtime": 6.556510925292969e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.6109200858537,
    "kernel_usage": 6.425341252682928,
    "cpu_runtime": 0.00020098800000000003,
    "total_runtime": 9.775161743164062e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89527326336113,
    "kernel_usage": 6.246727289480035,
    "cpu_runtime": 0.03239174400000001,
    "total_runtime": 0.016204357147216797
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.80913408000004,
    "kernel_usage": 6.900285440000001,
    "cpu_runtime": 0.0006106820000000001,
    "total_runtime": 0.0002765655517578125
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.39795437466063,
    "kernel_usage": 5.668686074208145,
    "cpu_runtime": 0.00019115900000000002,
    "total_runtime": 0.00010538101196289062
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.87691265009863,
    "kernel_usage": 6.339903520315582,
    "cpu_runtime": 0.000245234,
    "total_runtime": 0.00012087821960449219
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.16641780869568,
    "kernel_usage": 5.75520055652174,
    "cpu_runtime": 6.059400000000001e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.0583915469307,
    "kernel_usage": 6.095574735841584,
    "cpu_runtime": 0.000234853,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.581857420274,
    "kernel_usage": 6.143183044383562,
    "cpu_runtime": 0.00017107100000000002,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 212.36641438024688,
    "kernel_usage": 6.636450449382715,
    "cpu_runtime": 0.0004921439999999999,
    "total_runtime": 0.00023174285888671875
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.56022572698413,
    "kernel_usage": 4.673757053968254,
    "cpu_runtime": 4.4929e-05,
    "total_runtime": 3.0040740966796875e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.20658738214703,
    "kernel_usage": 6.256455855692095,
    "cpu_runtime": 0.002058723,
    "total_runtime": 0.001028299331665039
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.32343367344265,
    "kernel_usage": 6.697607302295083,
    "cpu_runtime": 0.00031170200000000007,
    "total_runtime": 0.00014543533325195312
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.60129596049384,
    "kernel_usage": 6.893790498765433,
    "cpu_runtime": 0.000681637,
    "total_runtime": 0.000308990478515625
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.25913143854544,
    "kernel_usage": 7.164347857454545,
    "cpu_runtime": 0.000300628,
    "total_runtime": 0.00013113021850585938
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.36803487706422,
    "kernel_usage": 5.792751089908257,
    "cpu_runtime": 0.000192691,
    "total_runtime": 0.00010395050048828125
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.78861986055048,
    "kernel_usage": 4.555894370642203,
    "cpu_runtime": 3.7887000000000005e-05,
    "total_runtime": 2.5987625122070312e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 261.45084040215585,
    "kernel_usage": 8.17033876256737,
    "cpu_runtime": 0.0012722520000000002,
    "total_runtime": 0.00048661231994628906
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.0430714506438,
    "kernel_usage": 6.2825959828326186,
    "cpu_runtime": 0.00044673,
    "total_runtime": 0.00022220611572265625
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.24385815272726,
    "kernel_usage": 6.132620567272727,
    "cpu_runtime": 0.000154401,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.91454303938815,
    "kernel_usage": 6.80982946998088,
    "cpu_runtime": 0.000543448,
    "total_runtime": 0.0002493858337402344
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.70208183038687,
    "kernel_usage": 6.24069005719959,
    "cpu_runtime": 0.013428206000000002,
    "total_runtime": 0.006724119186401367
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 169.03358127761197,
    "kernel_usage": 5.282299414925374,
    "cpu_runtime": 0.00010800600000000002,
    "total_runtime": 6.389617919921875e-05
  }
]