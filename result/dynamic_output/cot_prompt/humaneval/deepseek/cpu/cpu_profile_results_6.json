[
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 129.66166528,
    "kernel_usage": 4.05192704,
    "cpu_runtime": 2.4731e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.3456123979058,
    "kernel_usage": 5.167050387434556,
    "cpu_runtime": 7.529500000000002e-05,
    "total_runtime": 4.553794860839844e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 194.42089906350714,
    "kernel_usage": 6.075653095734598,
    "cpu_runtime": 9.7806e-05,
    "total_runtime": 5.030632019042969e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 200.30537015652175,
    "kernel_usage": 6.259542817391305,
    "cpu_runtime": 9.8856e-05,
    "total_runtime": 4.935264587402344e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.20876056774193,
    "kernel_usage": 6.756523767741935,
    "cpu_runtime": 0.00025567900000000003,
    "total_runtime": 0.000118255615234375
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.92856901818186,
    "kernel_usage": 6.685267781818183,
    "cpu_runtime": 0.000157094,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.88247715840004,
    "kernel_usage": 10.121327411200001,
    "cpu_runtime": 0.00038609800000000003,
    "total_runtime": 0.00011920928955078125
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 299.8719377983471,
    "kernel_usage": 9.370998056198347,
    "cpu_runtime": 0.000259527,
    "total_runtime": 8.654594421386719e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.71877887999997,
    "kernel_usage": 4.866211839999999,
    "cpu_runtime": 2.9701e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 212.4946254506667,
    "kernel_usage": 6.640457045333334,
    "cpu_runtime": 0.00011399100000000001,
    "total_runtime": 5.364418029785156e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.3439507930796,
    "kernel_usage": 7.385748462283738,
    "cpu_runtime": 0.00016284800000000002,
    "total_runtime": 6.890296936035156e-05
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 262.5634304,
    "kernel_usage": 8.2051072,
    "cpu_runtime": 0.000161508,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 169.20203636363638,
    "kernel_usage": 5.287563636363637,
    "cpu_runtime": 2.6625000000000003e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.68634982400002,
    "kernel_usage": 5.927698432000001,
    "cpu_runtime": 0.00018089900000000002,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 387.51041303803237,
    "kernel_usage": 12.109700407438512,
    "cpu_runtime": 0.001540136,
    "total_runtime": 0.0003974437713623047
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 155.3379068759494,
    "kernel_usage": 4.854309589873418,
    "cpu_runtime": 2.9258e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 204.9539735912088,
    "kernel_usage": 6.404811674725275,
    "cpu_runtime": 8.8934e-05,
    "total_runtime": 4.3392181396484375e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76094984502296,
    "kernel_usage": 6.242529682656968,
    "cpu_runtime": 0.020033228000000004,
    "total_runtime": 0.010028600692749023
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.86051973731347,
    "kernel_usage": 5.620641241791046,
    "cpu_runtime": 2.8731000000000007e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 195.00717397333332,
    "kernel_usage": 6.093974186666666,
    "cpu_runtime": 3.4869999999999996e-05,
    "total_runtime": 1.7881393432617188e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.76278259102685,
    "kernel_usage": 11.430086955969589,
    "cpu_runtime": 0.19864171200000005,
    "total_runtime": 0.05430889129638672
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.89301645373138,
    "kernel_usage": 6.2466567641791055,
    "cpu_runtime": 6.3862e-05,
    "total_runtime": 3.1948089599609375e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 135.4760192,
    "kernel_usage": 4.2336256,
    "cpu_runtime": 1.5181000000000001e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.2279608888889,
    "kernel_usage": 4.725873777777778,
    "cpu_runtime": 4.2185000000000004e-05,
    "total_runtime": 2.7894973754882812e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.96145268145574,
    "kernel_usage": 11.248795396295492,
    "cpu_runtime": 0.25205430700000003,
    "total_runtime": 0.0700225830078125
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.90780532568914,
    "kernel_usage": 8.715868916427786,
    "cpu_runtime": 0.000603126,
    "total_runtime": 0.0002162456512451172
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.4005039370079,
    "kernel_usage": 8.450015748031497,
    "cpu_runtime": 0.00032750000000000005,
    "total_runtime": 0.00012111663818359375
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.71710871839775,
    "kernel_usage": 9.30365964744993,
    "cpu_runtime": 0.017508245,
    "total_runtime": 0.005880832672119141
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6174786670722,
    "kernel_usage": 6.238046208346006,
    "cpu_runtime": 0.005634002000000001,
    "total_runtime": 0.002822399139404297
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.7736522322581,
    "kernel_usage": 5.930426632258065,
    "cpu_runtime": 0.00011220900000000001,
    "total_runtime": 5.91278076171875e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 212.5026645333333,
    "kernel_usage": 6.640708266666666,
    "cpu_runtime": 9.7276e-05,
    "total_runtime": 4.57763671875e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.53576941843974,
    "kernel_usage": 6.422992794326242,
    "cpu_runtime": 0.00013819,
    "total_runtime": 6.723403930664062e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.9004958895906,
    "kernel_usage": 6.246890496549706,
    "cpu_runtime": 0.029298027000000004,
    "total_runtime": 0.014656305313110352
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.6802022217469,
    "kernel_usage": 6.8962563194295905,
    "cpu_runtime": 0.000590332,
    "total_runtime": 0.0002675056457519531
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.1988441629977,
    "kernel_usage": 5.662463880093678,
    "cpu_runtime": 0.000184469,
    "total_runtime": 0.00010180473327636719
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.7309196955466,
    "kernel_usage": 6.335341240485831,
    "cpu_runtime": 0.00023877400000000003,
    "total_runtime": 0.00011777877807617188
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.12132654545454,
    "kernel_usage": 5.785041454545454,
    "cpu_runtime": 5.826e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.99637959753596,
    "kernel_usage": 6.093636862422999,
    "cpu_runtime": 0.00022641000000000002,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.08610874514284,
    "kernel_usage": 6.127690898285714,
    "cpu_runtime": 0.00016362699999999998,
    "total_runtime": 8.344650268554688e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.7435708090032,
    "kernel_usage": 6.61698658778135,
    "cpu_runtime": 0.000471012,
    "total_runtime": 0.0002224445343017578
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.6732095462185,
    "kernel_usage": 4.677287798319328,
    "cpu_runtime": 4.2465e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.09244067913667,
    "kernel_usage": 6.252888771223021,
    "cpu_runtime": 0.002055641,
    "total_runtime": 0.0010273456573486328
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.82487327687298,
    "kernel_usage": 6.713277289902281,
    "cpu_runtime": 0.00031448,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.92498455163806,
    "kernel_usage": 6.903905767238689,
    "cpu_runtime": 0.0006752630000000001,
    "total_runtime": 0.0003056526184082031
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.14688046500956,
    "kernel_usage": 7.129590014531549,
    "cpu_runtime": 0.00028448300000000003,
    "total_runtime": 0.0001246929168701172
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.9635106055046,
    "kernel_usage": 5.811359706422019,
    "cpu_runtime": 0.00019331,
    "total_runtime": 0.00010395050048828125
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 146.03233758504675,
    "kernel_usage": 4.563510549532711,
    "cpu_runtime": 3.7254000000000006e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 260.7517992929494,
    "kernel_usage": 8.148493727904668,
    "cpu_runtime": 0.0012520650000000001,
    "total_runtime": 0.0004801750183105469
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.7868640910285,
    "kernel_usage": 6.30583950284464,
    "cpu_runtime": 0.00043972300000000005,
    "total_runtime": 0.00021791458129882812
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.82303796635514,
    "kernel_usage": 6.119469936448598,
    "cpu_runtime": 0.000149868,
    "total_runtime": 7.653236389160156e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.79218463782738,
    "kernel_usage": 6.8060057699321055,
    "cpu_runtime": 0.000535354,
    "total_runtime": 0.00024580955505371094
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.69893531484104,
    "kernel_usage": 6.240591728588782,
    "cpu_runtime": 0.013326581000000002,
    "total_runtime": 0.006673336029052734
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.20266969358494,
    "kernel_usage": 5.256333427924529,
    "cpu_runtime": 0.00010627200000000002,
    "total_runtime": 6.318092346191406e-05
  }
]