[
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 126.8296889060241,
    "kernel_usage": 3.963427778313253,
    "cpu_runtime": 2.5098000000000003e-05,
    "total_runtime": 1.9788742065429688e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.73785780942407,
    "kernel_usage": 5.210558056544502,
    "cpu_runtime": 7.5929e-05,
    "total_runtime": 4.553794860839844e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.50506639266055,
    "kernel_usage": 6.140783324770642,
    "cpu_runtime": 0.00010213400000000001,
    "total_runtime": 5.1975250244140625e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 203.58362588514848,
    "kernel_usage": 6.36198830891089,
    "cpu_runtime": 9.804699999999999e-05,
    "total_runtime": 4.8160552978515625e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.82255818467914,
    "kernel_usage": 6.744454943271223,
    "cpu_runtime": 0.00024853300000000005,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.94184398451614,
    "kernel_usage": 6.716932624516129,
    "cpu_runtime": 0.000158863,
    "total_runtime": 7.390975952148438e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.00997641669977,
    "kernel_usage": 10.062811763021868,
    "cpu_runtime": 0.000386169,
    "total_runtime": 0.00011992454528808594
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 298.11189477127067,
    "kernel_usage": 9.315996711602208,
    "cpu_runtime": 0.00025729299999999996,
    "total_runtime": 8.630752563476562e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 156.47939467341774,
    "kernel_usage": 4.8899810835443045,
    "cpu_runtime": 2.9473000000000004e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 209.2505723586207,
    "kernel_usage": 6.539080386206897,
    "cpu_runtime": 0.000115743,
    "total_runtime": 5.53131103515625e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.6831669872054,
    "kernel_usage": 7.365098968350169,
    "cpu_runtime": 0.00016688800000000002,
    "total_runtime": 7.081031799316406e-05
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.7747716942085,
    "kernel_usage": 8.180461615444015,
    "cpu_runtime": 0.000161647,
    "total_runtime": 6.175041198730469e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.0666910117647,
    "kernel_usage": 5.314584094117647,
    "cpu_runtime": 2.7572e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.27574516214833,
    "kernel_usage": 5.914867036317135,
    "cpu_runtime": 0.000176446,
    "total_runtime": 9.322166442871094e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 388.14425371511845,
    "kernel_usage": 12.129507928597452,
    "cpu_runtime": 0.0015241470000000002,
    "total_runtime": 0.00039267539978027344
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 155.17862950886078,
    "kernel_usage": 4.849332172151899,
    "cpu_runtime": 2.9228000000000005e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 207.0509968446927,
    "kernel_usage": 6.470343651396647,
    "cpu_runtime": 8.8363e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.7665872251196,
    "kernel_usage": 6.242705850784987,
    "cpu_runtime": 0.020416723000000005,
    "total_runtime": 0.01022028923034668
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 182.8716544,
    "kernel_usage": 5.7147392,
    "cpu_runtime": 2.9648e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 195.0526122666667,
    "kernel_usage": 6.095394133333334,
    "cpu_runtime": 3.3483000000000005e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 366.47557526293946,
    "kernel_usage": 11.452361726966858,
    "cpu_runtime": 0.20178199499999994,
    "total_runtime": 0.05506014823913574
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 201.367588956391,
    "kernel_usage": 6.292737154887218,
    "cpu_runtime": 6.3853e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 134.217728,
    "kernel_usage": 4.194304,
    "cpu_runtime": 1.536e-05,
    "total_runtime": 1.1444091796875e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.4143744,
    "kernel_usage": 4.7316992,
    "cpu_runtime": 4.1876000000000004e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.3438688828108,
    "kernel_usage": 11.260745902587837,
    "cpu_runtime": 0.25098184700000004,
    "total_runtime": 0.06965065002441406
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.5021746122978,
    "kernel_usage": 8.734442956634306,
    "cpu_runtime": 0.0006177390000000001,
    "total_runtime": 0.00022101402282714844
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 271.5736941714286,
    "kernel_usage": 8.486677942857144,
    "cpu_runtime": 0.000326331,
    "total_runtime": 0.0001201629638671875
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.03069752073947,
    "kernel_usage": 9.344709297523108,
    "cpu_runtime": 0.017817202,
    "total_runtime": 0.0059583187103271484
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.61862421150752,
    "kernel_usage": 6.23808200660961,
    "cpu_runtime": 0.005616425,
    "total_runtime": 0.002813577651977539
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.45857958866398,
    "kernel_usage": 5.920580612145749,
    "cpu_runtime": 0.000111571,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 212.23394441237113,
    "kernel_usage": 6.632310762886598,
    "cpu_runtime": 9.8165e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.48680801696116,
    "kernel_usage": 6.421462750530036,
    "cpu_runtime": 0.00013864700000000002,
    "total_runtime": 6.747245788574219e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89635920583225,
    "kernel_usage": 6.246761225182258,
    "cpu_runtime": 0.029417998000000004,
    "total_runtime": 0.014716625213623047
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.8961073380711,
    "kernel_usage": 6.903003354314722,
    "cpu_runtime": 0.000622509,
    "total_runtime": 0.0002818107604980469
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.40027327264366,
    "kernel_usage": 5.668758539770114,
    "cpu_runtime": 0.00018813399999999998,
    "total_runtime": 0.00010371208190917969
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 201.52096218536585,
    "kernel_usage": 6.297530068292683,
    "cpu_runtime": 0.000236388,
    "total_runtime": 0.00011730194091796875
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.93437554626865,
    "kernel_usage": 5.7791992358208955,
    "cpu_runtime": 5.9083e-05,
    "total_runtime": 3.1948089599609375e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.41167985603272,
    "kernel_usage": 6.1066149955010225,
    "cpu_runtime": 0.000227824,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.9375468606061,
    "kernel_usage": 6.12304833939394,
    "cpu_runtime": 0.00016957600000000003,
    "total_runtime": 8.654594421386719e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.39654910616215,
    "kernel_usage": 6.606142159567567,
    "cpu_runtime": 0.00046620799999999997,
    "total_runtime": 0.0002205371856689453
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 150.07289039338843,
    "kernel_usage": 4.689777824793389,
    "cpu_runtime": 4.3294e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.13976852554745,
    "kernel_usage": 6.254367766423358,
    "cpu_runtime": 0.002091915,
    "total_runtime": 0.00104522705078125
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.28419515733333,
    "kernel_usage": 6.6963810986666665,
    "cpu_runtime": 0.000306536,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 219.65841482157168,
    "kernel_usage": 6.864325463174115,
    "cpu_runtime": 0.000679771,
    "total_runtime": 0.0003094673156738281
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.71100308723814,
    "kernel_usage": 7.147218846476192,
    "cpu_runtime": 0.00028627700000000004,
    "total_runtime": 0.0001251697540283203
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.07835175152945,
    "kernel_usage": 5.783698492235295,
    "cpu_runtime": 0.00018753600000000003,
    "total_runtime": 0.00010132789611816406
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 143.65879561481484,
    "kernel_usage": 4.489337362962964,
    "cpu_runtime": 3.6991000000000005e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 260.7578978005787,
    "kernel_usage": 8.148684306268084,
    "cpu_runtime": 0.0012893960000000004,
    "total_runtime": 0.0004944801330566406
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.43110878439873,
    "kernel_usage": 6.29472214951246,
    "cpu_runtime": 0.00044327000000000006,
    "total_runtime": 0.0002200603485107422
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.66756867210034,
    "kernel_usage": 6.114611521003136,
    "cpu_runtime": 0.00014881600000000002,
    "total_runtime": 7.605552673339844e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.8830951923225,
    "kernel_usage": 6.840096724760078,
    "cpu_runtime": 0.000543776,
    "total_runtime": 0.0002484321594238281
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6802425034577,
    "kernel_usage": 6.240007578233053,
    "cpu_runtime": 0.013245353000000001,
    "total_runtime": 0.006633281707763672
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.70213302172286,
    "kernel_usage": 5.271941656928839,
    "cpu_runtime": 0.000107392,
    "total_runtime": 6.365776062011719e-05
  }
]