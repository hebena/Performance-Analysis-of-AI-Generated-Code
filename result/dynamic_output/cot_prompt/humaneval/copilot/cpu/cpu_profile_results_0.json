[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 207.88703631736377,
    "kernel_usage": 6.496469884917618,
    "cpu_runtime": 0.000391061,
    "total_runtime": 0.0001881122589111328
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 225.6642684327502,
    "kernel_usage": 7.0520083885234435,
    "cpu_runtime": 0.001537677,
    "total_runtime": 0.0006814002990722656
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 135.64655683516486,
    "kernel_usage": 4.238954901098902,
    "cpu_runtime": 2.9430000000000005e-05,
    "total_runtime": 2.1696090698242188e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.35238809600003,
    "kernel_usage": 5.198512128000001,
    "cpu_runtime": 7.932300000000001e-05,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 282.687802981155,
    "kernel_usage": 8.833993843161094,
    "cpu_runtime": 0.00044347900000000004,
    "total_runtime": 0.00015687942504882812
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 198.28063142524272,
    "kernel_usage": 6.196269732038835,
    "cpu_runtime": 9.7384e-05,
    "total_runtime": 4.9114227294921875e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 178.26661285803107,
    "kernel_usage": 5.570831651813471,
    "cpu_runtime": 8.2029e-05,
    "total_runtime": 4.601478576660156e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 190.3716913303704,
    "kernel_usage": 5.949115354074075,
    "cpu_runtime": 0.00012254800000000002,
    "total_runtime": 6.437301635742188e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 216.0544857824562,
    "kernel_usage": 6.751702680701756,
    "cpu_runtime": 0.00023489200000000003,
    "total_runtime": 0.0001087188720703125
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 327.3162752,
    "kernel_usage": 10.2286336,
    "cpu_runtime": 0.000399556,
    "total_runtime": 0.0001220703125
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 200.59502734883722,
    "kernel_usage": 6.268594604651163,
    "cpu_runtime": 0.000102825,
    "total_runtime": 5.125999450683594e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 156.67188569302328,
    "kernel_usage": 4.895996427906978,
    "cpu_runtime": 3.2124000000000006e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 210.7977133145228,
    "kernel_usage": 6.587428541078838,
    "cpu_runtime": 0.000121122,
    "total_runtime": 5.745887756347656e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 296.58088256443426,
    "kernel_usage": 9.26815258013857,
    "cpu_runtime": 0.00030617600000000007,
    "total_runtime": 0.00010323524475097656
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.13093740606064,
    "kernel_usage": 6.222841793939395,
    "cpu_runtime": 0.000125338,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 207.4154488846307,
    "kernel_usage": 6.48173277764471,
    "cpu_runtime": 0.00024775299999999997,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 258.3915747876057,
    "kernel_usage": 8.074736712112678,
    "cpu_runtime": 0.0004373980000000001,
    "total_runtime": 0.00016927719116210938
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 210.14428357376298,
    "kernel_usage": 6.567008861680093,
    "cpu_runtime": 0.00043538900000000006,
    "total_runtime": 0.0002071857452392578
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.04634442980935,
    "kernel_usage": 7.001448263431542,
    "cpu_runtime": 0.000308215,
    "total_runtime": 0.00013756752014160156
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.27045555744684,
    "kernel_usage": 8.102201736170214,
    "cpu_runtime": 0.000174318,
    "total_runtime": 6.723403930664062e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 169.4971413633803,
    "kernel_usage": 5.296785667605635,
    "cpu_runtime": 2.8692000000000002e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.8773974899083,
    "kernel_usage": 5.9024186715596345,
    "cpu_runtime": 0.00019633900000000005,
    "total_runtime": 0.00010395050048828125
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.4810866694387,
    "kernel_usage": 6.171283958419959,
    "cpu_runtime": 0.00045294000000000004,
    "total_runtime": 0.00022935867309570312
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 386.01285719887073,
    "kernel_usage": 12.06290178746471,
    "cpu_runtime": 0.001629898,
    "total_runtime": 0.0004222393035888672
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 173.49468565544558,
    "kernel_usage": 5.421708926732674,
    "cpu_runtime": 4.1778000000000006e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.9166776293194,
    "kernel_usage": 8.309896175916231,
    "cpu_runtime": 0.00012109300000000001,
    "total_runtime": 4.553794860839844e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.6661341151833,
    "kernel_usage": 6.333316691099478,
    "cpu_runtime": 9.229000000000001e-05,
    "total_runtime": 4.553794860839844e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 179.25156104321223,
    "kernel_usage": 5.601611282600382,
    "cpu_runtime": 0.00022351400000000002,
    "total_runtime": 0.0001246929168701172
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 184.92745410704228,
    "kernel_usage": 5.778982940845071,
    "cpu_runtime": 3.1304000000000004e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 163.49890439529412,
    "kernel_usage": 5.109340762352941,
    "cpu_runtime": 3.3134e-05,
    "total_runtime": 2.0265579223632812e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 250.78665381118336,
    "kernel_usage": 7.83708293159948,
    "cpu_runtime": 0.00045980200000000004,
    "total_runtime": 0.00018334388732910156
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.02603644267174,
    "kernel_usage": 11.407063638833492,
    "cpu_runtime": 0.21985002100000003,
    "total_runtime": 0.060228586196899414
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 205.9968183619455,
    "kernel_usage": 6.4374005738107964,
    "cpu_runtime": 0.0009189129999999999,
    "total_runtime": 0.00044608116149902344
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.33233885637586,
    "kernel_usage": 5.2603855892617455,
    "cpu_runtime": 5.979900000000001e-05,
    "total_runtime": 3.552436828613281e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 198.31331570526316,
    "kernel_usage": 6.197291115789474,
    "cpu_runtime": 7.1868e-05,
    "total_runtime": 3.62396240234375e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 203.26266697314557,
    "kernel_usage": 6.351958342910799,
    "cpu_runtime": 0.0005161160000000001,
    "total_runtime": 0.00025391578674316406
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 202.88711512832194,
    "kernel_usage": 6.3402223477600606,
    "cpu_runtime": 0.00063706,
    "total_runtime": 0.0003139972686767578
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 129.1516666980392,
    "kernel_usage": 4.035989584313725,
    "cpu_runtime": 1.5704e-05,
    "total_runtime": 1.2159347534179688e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 205.87472828056872,
    "kernel_usage": 6.433585258767772,
    "cpu_runtime": 0.000310704,
    "total_runtime": 0.00015091896057128906
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 196.46267104561403,
    "kernel_usage": 6.139458470175438,
    "cpu_runtime": 0.000133495,
    "total_runtime": 6.794929504394531e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 252.82579349757182,
    "kernel_usage": 7.9008060467991195,
    "cpu_runtime": 0.00027306100000000006,
    "total_runtime": 0.00010800361633300781
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.18144839038274,
    "kernel_usage": 11.22442026219946,
    "cpu_runtime": 0.271546842,
    "total_runtime": 0.07560157775878906
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 274.85808317175287,
    "kernel_usage": 8.589315099117277,
    "cpu_runtime": 0.0005196630000000001,
    "total_runtime": 0.00018906593322753906
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 272.07515405672194,
    "kernel_usage": 8.50234856427256,
    "cpu_runtime": 0.000352232,
    "total_runtime": 0.00012946128845214844
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.5695756363,
    "kernel_usage": 9.299049238634375,
    "cpu_runtime": 0.019450587000000002,
    "total_runtime": 0.0065364837646484375
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 178.77808695895197,
    "kernel_usage": 5.586815217467249,
    "cpu_runtime": 9.760900000000001e-05,
    "total_runtime": 5.459785461425781e-05
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.42143778533728,
    "kernel_usage": 5.82566993079179,
    "cpu_runtime": 0.00030312400000000005,
    "total_runtime": 0.00016260147094726562
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 267.53820527742647,
    "kernel_usage": 8.360568914919577,
    "cpu_runtime": 0.001150063,
    "total_runtime": 0.0004298686981201172
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 188.7327654542751,
    "kernel_usage": 5.897898920446097,
    "cpu_runtime": 0.00012104300000000001,
    "total_runtime": 6.413459777832031e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 141.2703725037037,
    "kernel_usage": 4.4146991407407405,
    "cpu_runtime": 2.7282e-05,
    "total_runtime": 1.9311904907226562e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.79006640355558,
    "kernel_usage": 5.837189575111112,
    "cpu_runtime": 0.00030060600000000003,
    "total_runtime": 0.0001609325408935547
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 211.39704714491808,
    "kernel_usage": 6.60615772327869,
    "cpu_runtime": 0.00015372300000000003,
    "total_runtime": 7.271766662597656e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 205.72484345522554,
    "kernel_usage": 6.428901357975798,
    "cpu_runtime": 0.00044585200000000005,
    "total_runtime": 0.0002167224884033203
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 365.2782815746581,
    "kernel_usage": 11.414946299208065,
    "cpu_runtime": 0.0012096680000000001,
    "total_runtime": 0.0003311634063720703
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 192.5738366899714,
    "kernel_usage": 6.017932396561606,
    "cpu_runtime": 0.00016023700000000003,
    "total_runtime": 8.320808410644531e-05
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 173.41358966580088,
    "kernel_usage": 5.419174677056278,
    "cpu_runtime": 0.000191014,
    "total_runtime": 0.00011014938354492188
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 223.805109273838,
    "kernel_usage": 6.993909664807438,
    "cpu_runtime": 0.0008035910000000001,
    "total_runtime": 0.0003590583801269531
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 201.147285504,
    "kernel_usage": 6.285852672,
    "cpu_runtime": 0.000191829,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 182.56550082335767,
    "kernel_usage": 5.705171900729927,
    "cpu_runtime": 0.000178896,
    "total_runtime": 9.799003601074219e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 301.7297911867637,
    "kernel_usage": 9.429055974586365,
    "cpu_runtime": 0.001086983,
    "total_runtime": 0.00036025047302246094
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 168.41488428201438,
    "kernel_usage": 5.2629651338129495,
    "cpu_runtime": 0.000111626,
    "total_runtime": 6.628036499023438e-05
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 295.6219840945813,
    "kernel_usage": 9.238187002955666,
    "cpu_runtime": 0.0005723120000000001,
    "total_runtime": 0.00019359588623046875
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.72037080073395,
    "kernel_usage": 6.085011587522936,
    "cpu_runtime": 0.000253016,
    "total_runtime": 0.00012993812561035156
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 191.97803546713047,
    "kernel_usage": 5.999313608347827,
    "cpu_runtime": 0.0002631840000000001,
    "total_runtime": 0.00013709068298339844
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 229.8996577084153,
    "kernel_usage": 7.184364303387978,
    "cpu_runtime": 0.0005015330000000001,
    "total_runtime": 0.0002181529998779297
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 282.03682230460714,
    "kernel_usage": 8.813650697018973,
    "cpu_runtime": 0.00024812600000000004,
    "total_runtime": 8.797645568847656e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.35671092825396,
    "kernel_usage": 9.042397216507936,
    "cpu_runtime": 0.000869249,
    "total_runtime": 0.00030040740966796875
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 268.006251922237,
    "kernel_usage": 8.375195372569907,
    "cpu_runtime": 0.0009597430000000001,
    "total_runtime": 0.0003581047058105469
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 189.07637633580248,
    "kernel_usage": 5.9086367604938275,
    "cpu_runtime": 0.000146057,
    "total_runtime": 7.724761962890625e-05
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 206.06135147136567,
    "kernel_usage": 6.439417233480177,
    "cpu_runtime": 0.00022304500000000003,
    "total_runtime": 0.00010824203491210938
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.32039093198995,
    "kernel_usage": 6.103762216624686,
    "cpu_runtime": 0.000184875,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 297.48017899682543,
    "kernel_usage": 9.296255593650795,
    "cpu_runtime": 0.001072383,
    "total_runtime": 0.0003604888916015625
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 202.12448682211624,
    "kernel_usage": 6.3163902131911325,
    "cpu_runtime": 0.0017170180000000003,
    "total_runtime": 0.0008494853973388672
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.15191863496506,
    "kernel_usage": 6.004747457342658,
    "cpu_runtime": 0.000131024,
    "total_runtime": 6.818771362304688e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.25534796039608,
    "kernel_usage": 5.7892296237623775,
    "cpu_runtime": 0.00013383,
    "total_runtime": 7.224082946777344e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 249.9664704918661,
    "kernel_usage": 7.811452202870815,
    "cpu_runtime": 0.0004982280000000001,
    "total_runtime": 0.00019931793212890625
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 156.39271169673205,
    "kernel_usage": 4.887272240522877,
    "cpu_runtime": 5.704900000000001e-05,
    "total_runtime": 3.647804260253906e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 201.23286453631283,
    "kernel_usage": 6.288527016759776,
    "cpu_runtime": 0.00025764,
    "total_runtime": 0.00012803077697753906
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 364.07917859338954,
    "kernel_usage": 11.377474331043423,
    "cpu_runtime": 0.0013393740000000002,
    "total_runtime": 0.00036787986755371094
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 224.19624016313725,
    "kernel_usage": 7.006132505098039,
    "cpu_runtime": 0.00040891200000000004,
    "total_runtime": 0.0001823902130126953
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 198.20398013478626,
    "kernel_usage": 6.193874379212071,
    "cpu_runtime": 0.002255033,
    "total_runtime": 0.0011377334594726562
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 206.11487723313132,
    "kernel_usage": 6.441089913535354,
    "cpu_runtime": 0.00024325100000000002,
    "total_runtime": 0.00011801719665527344
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 307.10533529150734,
    "kernel_usage": 9.597041727859605,
    "cpu_runtime": 0.002336438,
    "total_runtime": 0.0007607936859130859
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 221.91006415962,
    "kernel_usage": 6.934689504988125,
    "cpu_runtime": 0.000445481,
    "total_runtime": 0.00020074844360351562
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 285.3173133987629,
    "kernel_usage": 8.91616604371134,
    "cpu_runtime": 0.000659842,
    "total_runtime": 0.00023126602172851562
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 373.9728600768831,
    "kernel_usage": 11.686651877402596,
    "cpu_runtime": 0.002059644,
    "total_runtime": 0.0005507469177246094
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 316.5955103835798,
    "kernel_usage": 9.893609699486868,
    "cpu_runtime": 0.002500727,
    "total_runtime": 0.0007898807525634766
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 192.6362080291439,
    "kernel_usage": 6.0198815009107465,
    "cpu_runtime": 0.000252145,
    "total_runtime": 0.0001308917999267578
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 254.56403959322037,
    "kernel_usage": 7.955126237288137,
    "cpu_runtime": 0.000429705,
    "total_runtime": 0.00016880035400390625
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 277.9923486763949,
    "kernel_usage": 8.68726089613734,
    "cpu_runtime": 0.000308858,
    "total_runtime": 0.00011110305786132812
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 187.60492381941995,
    "kernel_usage": 5.8626538693568735,
    "cpu_runtime": 0.00035469700000000006,
    "total_runtime": 0.00018906593322753906
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 343.0225602757104,
    "kernel_usage": 10.71945500861595,
    "cpu_runtime": 0.0008922520000000002,
    "total_runtime": 0.0002601146697998047
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 169.0918312585366,
    "kernel_usage": 5.284119726829268,
    "cpu_runtime": 0.000132232,
    "total_runtime": 7.82012939453125e-05
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 180.5667230326154,
    "kernel_usage": 5.642710094769232,
    "cpu_runtime": 0.00013991400000000002,
    "total_runtime": 7.748603820800781e-05
  },
  {
    "task_id": "HumanEval_135.py",
    "status": "success",
    "cpu_usage": 179.9237065886179,
    "kernel_usage": 5.6226158308943095,
    "cpu_runtime": 0.00010552700000000001,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 175.5925816628885,
    "kernel_usage": 5.487268176965266,
    "cpu_runtime": 0.00022899900000000002,
    "total_runtime": 0.0001304149627685547
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 149.46914207244095,
    "kernel_usage": 4.6709106897637795,
    "cpu_runtime": 4.5258e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 242.78432951794872,
    "kernel_usage": 7.5870102974358975,
    "cpu_runtime": 0.000361198,
    "total_runtime": 0.000148773193359375
  },
  {
    "task_id": "HumanEval_141.py",
    "status": "success",
    "cpu_usage": 303.3964674148131,
    "kernel_usage": 9.48113960671291,
    "cpu_runtime": 0.003232667,
    "total_runtime": 0.0010654926300048828
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 193.43722878940983,
    "kernel_usage": 6.044913399669057,
    "cpu_runtime": 0.000836138,
    "total_runtime": 0.0004322528839111328
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 375.6390524511531,
    "kernel_usage": 11.738720389098534,
    "cpu_runtime": 0.0017087920000000002,
    "total_runtime": 0.00045490264892578125
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.1835089965919,
    "kernel_usage": 6.318234656143497,
    "cpu_runtime": 0.000537478,
    "total_runtime": 0.0002658367156982422
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 381.0154910587519,
    "kernel_usage": 11.906734095585996,
    "cpu_runtime": 0.001193653,
    "total_runtime": 0.0003132820129394531
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.0680506534764,
    "kernel_usage": 6.252126582921138,
    "cpu_runtime": 0.5390675200000001,
    "total_runtime": 0.269442081451416
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.2368873316456,
    "kernel_usage": 6.101152729113925,
    "cpu_runtime": 0.00018386500000000002,
    "total_runtime": 9.417533874511719e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 288.53694651889913,
    "kernel_usage": 9.016779578715598,
    "cpu_runtime": 0.0007498390000000001,
    "total_runtime": 0.0002598762512207031
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 180.3122919592018,
    "kernel_usage": 5.634759123725056,
    "cpu_runtime": 0.00019388400000000002,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 320.72796701076544,
    "kernel_usage": 10.02274896908642,
    "cpu_runtime": 0.003096934,
    "total_runtime": 0.0009655952453613281
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 236.31666420634255,
    "kernel_usage": 7.384895756448205,
    "cpu_runtime": 0.00026649900000000007,
    "total_runtime": 0.00011277198791503906
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 354.692420965908,
    "kernel_usage": 11.084138155184625,
    "cpu_runtime": 0.0066874210000000016,
    "total_runtime": 0.0018854141235351562
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 204.8499075823178,
    "kernel_usage": 6.401559611947431,
    "cpu_runtime": 0.00040879100000000004,
    "total_runtime": 0.0001995563507080078
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 202.54204418050733,
    "kernel_usage": 6.329438880640854,
    "cpu_runtime": 0.000723381,
    "total_runtime": 0.0003571510314941406
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.15485197080292,
    "kernel_usage": 5.254839124087591,
    "cpu_runtime": 0.00010985,
    "total_runtime": 6.532669067382812e-05
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 197.0915226263499,
    "kernel_usage": 6.159110082073434,
    "cpu_runtime": 0.00043513000000000004,
    "total_runtime": 0.00022077560424804688
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 254.89400920887508,
    "kernel_usage": 7.965437787777346,
    "cpu_runtime": 0.0015612190000000002,
    "total_runtime": 0.0006124973297119141
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 223.48002544197533,
    "kernel_usage": 6.983750795061729,
    "cpu_runtime": 0.000172633,
    "total_runtime": 7.724761962890625e-05
  }
]