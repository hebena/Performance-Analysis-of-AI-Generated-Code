[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 208.4878695398329,
    "kernel_usage": 6.515245923119778,
    "cpu_runtime": 0.00035689900000000004,
    "total_runtime": 0.00017118453979492188
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 226.08707744809365,
    "kernel_usage": 7.065221170252927,
    "cpu_runtime": 0.0014279000000000002,
    "total_runtime": 0.0006315708160400391
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 139.47748163678162,
    "kernel_usage": 4.358671301149426,
    "cpu_runtime": 2.8931e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.64665329849245,
    "kernel_usage": 5.207707915577889,
    "cpu_runtime": 7.9066e-05,
    "total_runtime": 4.744529724121094e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 284.29936396576863,
    "kernel_usage": 8.88435512393027,
    "cpu_runtime": 0.000427706,
    "total_runtime": 0.00015044212341308594
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 200.70373785600003,
    "kernel_usage": 6.271991808000001,
    "cpu_runtime": 9.5703e-05,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 179.90886944680855,
    "kernel_usage": 5.622152170212767,
    "cpu_runtime": 8.064000000000001e-05,
    "total_runtime": 4.482269287109375e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 190.43100687633589,
    "kernel_usage": 5.950968964885496,
    "cpu_runtime": 0.00011895400000000001,
    "total_runtime": 6.246566772460938e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.68992730606743,
    "kernel_usage": 6.709060228314607,
    "cpu_runtime": 0.00022777800000000001,
    "total_runtime": 0.00010609626770019531
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 326.10503464529063,
    "kernel_usage": 10.190782332665332,
    "cpu_runtime": 0.00038797000000000007,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 202.04853193628315,
    "kernel_usage": 6.314016623008849,
    "cpu_runtime": 0.00010886899999999999,
    "total_runtime": 5.3882598876953125e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 158.73977510697674,
    "kernel_usage": 4.960617972093023,
    "cpu_runtime": 3.2548e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 213.56947194732513,
    "kernel_usage": 6.67404599835391,
    "cpu_runtime": 0.000123733,
    "total_runtime": 5.793571472167969e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 296.89219544615383,
    "kernel_usage": 9.277881107692307,
    "cpu_runtime": 0.00029446400000000003,
    "total_runtime": 9.918212890625e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.4712388923077,
    "kernel_usage": 6.2022262153846155,
    "cpu_runtime": 0.00012303,
    "total_runtime": 6.198883056640625e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 207.00293845669293,
    "kernel_usage": 6.468841826771654,
    "cpu_runtime": 0.00025071500000000004,
    "total_runtime": 0.00012111663818359375
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 255.58464192369942,
    "kernel_usage": 7.987020060115607,
    "cpu_runtime": 0.000421678,
    "total_runtime": 0.00016498565673828125
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 209.85909218102194,
    "kernel_usage": 6.5580966306569355,
    "cpu_runtime": 0.00041128200000000006,
    "total_runtime": 0.00019598007202148438
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 222.93695972669042,
    "kernel_usage": 6.966779991459076,
    "cpu_runtime": 0.00029871600000000003,
    "total_runtime": 0.00013399124145507812
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.41063334831466,
    "kernel_usage": 8.106582292134833,
    "cpu_runtime": 0.000165135,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.25279122285718,
    "kernel_usage": 5.320399725714287,
    "cpu_runtime": 2.8414000000000003e-05,
    "total_runtime": 1.6689300537109375e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.81391954066987,
    "kernel_usage": 5.9004349856459335,
    "cpu_runtime": 0.00018817000000000004,
    "total_runtime": 9.965896606445312e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.1238807091314,
    "kernel_usage": 6.160121272160357,
    "cpu_runtime": 0.000422042,
    "total_runtime": 0.00021409988403320312
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 385.86103354399523,
    "kernel_usage": 12.058157298249851,
    "cpu_runtime": 0.0015243810000000002,
    "total_runtime": 0.00039505958557128906
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 176.02390123789473,
    "kernel_usage": 5.50074691368421,
    "cpu_runtime": 3.9869e-05,
    "total_runtime": 2.2649765014648438e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 268.4005034666667,
    "kernel_usage": 8.387515733333334,
    "cpu_runtime": 0.00010750600000000001,
    "total_runtime": 4.00543212890625e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.5403626547486,
    "kernel_usage": 6.329386332960894,
    "cpu_runtime": 8.6438e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 179.45502579281182,
    "kernel_usage": 5.6079695560253695,
    "cpu_runtime": 0.000202375,
    "total_runtime": 0.00011277198791503906
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 185.93218560000003,
    "kernel_usage": 5.810380800000001,
    "cpu_runtime": 2.8371000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 164.84748315675677,
    "kernel_usage": 5.151483848648649,
    "cpu_runtime": 2.9084e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 250.3552409312763,
    "kernel_usage": 7.823601279102385,
    "cpu_runtime": 0.000425585,
    "total_runtime": 0.00016999244689941406
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 366.03336208291114,
    "kernel_usage": 11.438542565090973,
    "cpu_runtime": 0.20241207600000002,
    "total_runtime": 0.055298805236816406
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 205.82184759215684,
    "kernel_usage": 6.431932737254901,
    "cpu_runtime": 0.000800851,
    "total_runtime": 0.00038909912109375
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.44635553185185,
    "kernel_usage": 5.26394861037037,
    "cpu_runtime": 5.4217e-05,
    "total_runtime": 3.218650817871094e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 202.1747049411765,
    "kernel_usage": 6.317959529411765,
    "cpu_runtime": 6.5555e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 203.9812637932308,
    "kernel_usage": 6.374414493538462,
    "cpu_runtime": 0.00047417100000000007,
    "total_runtime": 0.00023245811462402344
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 202.91209356091207,
    "kernel_usage": 6.341002923778502,
    "cpu_runtime": 0.000594082,
    "total_runtime": 0.00029277801513671875
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 130.05766321632652,
    "kernel_usage": 4.064301975510204,
    "cpu_runtime": 1.5194e-05,
    "total_runtime": 1.1682510375976562e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 204.69659394115703,
    "kernel_usage": 6.396768560661157,
    "cpu_runtime": 0.00029526100000000006,
    "total_runtime": 0.0001442432403564453
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 196.860434962963,
    "kernel_usage": 6.151888592592594,
    "cpu_runtime": 0.00012672500000000003,
    "total_runtime": 6.437301635742188e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 250.8704047961071,
    "kernel_usage": 7.839700149878347,
    "cpu_runtime": 0.000245828,
    "total_runtime": 9.799003601074219e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.72540720922206,
    "kernel_usage": 11.27266897528819,
    "cpu_runtime": 0.25075306999999997,
    "total_runtime": 0.06951355934143066
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 276.17061178652295,
    "kernel_usage": 8.630331618328842,
    "cpu_runtime": 0.000488564,
    "total_runtime": 0.00017690658569335938
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 274.0784080738462,
    "kernel_usage": 8.564950252307694,
    "cpu_runtime": 0.00033979600000000007,
    "total_runtime": 0.0001239776611328125
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.29913770715393,
    "kernel_usage": 9.29059805334856,
    "cpu_runtime": 0.01737876,
    "total_runtime": 0.005845546722412109
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 178.40727814243903,
    "kernel_usage": 5.5752274419512196,
    "cpu_runtime": 8.7198e-05,
    "total_runtime": 4.887580871582031e-05
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.6198866553746,
    "kernel_usage": 5.831871457980456,
    "cpu_runtime": 0.000273191,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 268.148966691432,
    "kernel_usage": 8.37965520910725,
    "cpu_runtime": 0.0010670200000000001,
    "total_runtime": 0.0003979206085205078
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 187.55179861333332,
    "kernel_usage": 5.860993706666666,
    "cpu_runtime": 0.000107318,
    "total_runtime": 5.7220458984375e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 141.53117638309863,
    "kernel_usage": 4.422849261971832,
    "cpu_runtime": 2.3958000000000003e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 187.2998981280528,
    "kernel_usage": 5.85312181650165,
    "cpu_runtime": 0.000270614,
    "total_runtime": 0.00014448165893554688
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 209.8885439291513,
    "kernel_usage": 6.559016997785978,
    "cpu_runtime": 0.00013561200000000002,
    "total_runtime": 6.461143493652344e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 205.66782374012126,
    "kernel_usage": 6.4271194918787895,
    "cpu_runtime": 0.0004045390000000001,
    "total_runtime": 0.00019669532775878906
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 366.7813585544401,
    "kernel_usage": 11.461917454826253,
    "cpu_runtime": 0.001132445,
    "total_runtime": 0.00030875205993652344
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 192.73357804556966,
    "kernel_usage": 6.022924313924052,
    "cpu_runtime": 0.00014520600000000002,
    "total_runtime": 7.534027099609375e-05
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 172.78415163076926,
    "kernel_usage": 5.399504738461539,
    "cpu_runtime": 0.00017137100000000002,
    "total_runtime": 9.918212890625e-05
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 223.5716389196581,
    "kernel_usage": 6.986613716239316,
    "cpu_runtime": 0.000748383,
    "total_runtime": 0.00033473968505859375
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 200.8836734976,
    "kernel_usage": 6.2776147968,
    "cpu_runtime": 0.000179604,
    "total_runtime": 8.940696716308594e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 182.35776782412867,
    "kernel_usage": 5.698680244504021,
    "cpu_runtime": 0.000162171,
    "total_runtime": 8.893013000488281e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 301.94456883422777,
    "kernel_usage": 9.435767776069618,
    "cpu_runtime": 0.0009927310000000002,
    "total_runtime": 0.0003287792205810547
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 168.77645350756973,
    "kernel_usage": 5.274264172111554,
    "cpu_runtime": 0.000101001,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 296.3837757908497,
    "kernel_usage": 9.261992993464053,
    "cpu_runtime": 0.0005405750000000001,
    "total_runtime": 0.0001823902130126953
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.8878154049587,
    "kernel_usage": 6.090244231404959,
    "cpu_runtime": 0.00022489000000000002,
    "total_runtime": 0.00011539459228515625
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 193.89011563209394,
    "kernel_usage": 6.059066113502936,
    "cpu_runtime": 0.00023622,
    "total_runtime": 0.00012183189392089844
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 228.926628333494,
    "kernel_usage": 7.153957135421687,
    "cpu_runtime": 0.00045301700000000006,
    "total_runtime": 0.00019788742065429688
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 281.2866083720931,
    "kernel_usage": 8.79020651162791,
    "cpu_runtime": 0.00023070000000000002,
    "total_runtime": 8.20159912109375e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.9812786154648,
    "kernel_usage": 9.061914956733276,
    "cpu_runtime": 0.000795766,
    "total_runtime": 0.00027441978454589844
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 267.9585447743041,
    "kernel_usage": 8.373704524197002,
    "cpu_runtime": 0.000895047,
    "total_runtime": 0.00033402442932128906
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 185.53039274093962,
    "kernel_usage": 5.797824773154363,
    "cpu_runtime": 0.000131817,
    "total_runtime": 7.104873657226562e-05
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 204.68405169230772,
    "kernel_usage": 6.396376615384616,
    "cpu_runtime": 0.00020301000000000002,
    "total_runtime": 9.918212890625e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.5069952,
    "kernel_usage": 6.1095936,
    "cpu_runtime": 0.000167805,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 299.89875956583523,
    "kernel_usage": 9.371836236432351,
    "cpu_runtime": 0.0009459640000000001,
    "total_runtime": 0.0003154277801513672
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 202.20936947634777,
    "kernel_usage": 6.319042796135868,
    "cpu_runtime": 0.001547074,
    "total_runtime": 0.0007650852203369141
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 193.18529754262948,
    "kernel_usage": 6.037040548207171,
    "cpu_runtime": 0.00011560800000000001,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.89032866569343,
    "kernel_usage": 5.80907277080292,
    "cpu_runtime": 0.00012143600000000001,
    "total_runtime": 6.532669067382812e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 246.17946521328028,
    "kernel_usage": 7.693108287915009,
    "cpu_runtime": 0.0004419640000000001,
    "total_runtime": 0.00017952919006347656
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 156.39102020992908,
    "kernel_usage": 4.887219381560284,
    "cpu_runtime": 5.2574e-05,
    "total_runtime": 3.361701965332031e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 201.13108748090355,
    "kernel_usage": 6.285346483778236,
    "cpu_runtime": 0.00023353300000000004,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 361.8402422381502,
    "kernel_usage": 11.307507569942194,
    "cpu_runtime": 0.0011939689999999998,
    "total_runtime": 0.0003299713134765625
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 222.71185734939763,
    "kernel_usage": 6.959745542168676,
    "cpu_runtime": 0.00035257500000000005,
    "total_runtime": 0.0001583099365234375
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 198.13780593021602,
    "kernel_usage": 6.191806435319251,
    "cpu_runtime": 0.00199021,
    "total_runtime": 0.0010044574737548828
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 206.59456208036121,
    "kernel_usage": 6.456080065011288,
    "cpu_runtime": 0.00021820400000000003,
    "total_runtime": 0.00010561943054199219
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 307.4931067314244,
    "kernel_usage": 9.609159585357013,
    "cpu_runtime": 0.00202268,
    "total_runtime": 0.0006577968597412109
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.79877823296707,
    "kernel_usage": 6.962461819780221,
    "cpu_runtime": 0.00038670900000000005,
    "total_runtime": 0.0001735687255859375
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 284.672094269275,
    "kernel_usage": 8.896002945914844,
    "cpu_runtime": 0.0005898,
    "total_runtime": 0.0002071857452392578
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 374.8343488568608,
    "kernel_usage": 11.7135734017769,
    "cpu_runtime": 0.001810585,
    "total_runtime": 0.0004830360412597656
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 315.27595430880547,
    "kernel_usage": 9.85237357215017,
    "cpu_runtime": 0.002202412,
    "total_runtime": 0.0006985664367675781
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 192.76632522625482,
    "kernel_usage": 6.023947663320463,
    "cpu_runtime": 0.000238068,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 254.16355807646133,
    "kernel_usage": 7.9426111898894165,
    "cpu_runtime": 0.000383581,
    "total_runtime": 0.00015091896057128906
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 275.8219212924574,
    "kernel_usage": 8.619435040389293,
    "cpu_runtime": 0.000270278,
    "total_runtime": 9.799003601074219e-05
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 187.24478987489482,
    "kernel_usage": 5.851399683590463,
    "cpu_runtime": 0.000318302,
    "total_runtime": 0.00016999244689941406
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 339.2556565486182,
    "kernel_usage": 10.60173926714432,
    "cpu_runtime": 0.000790245,
    "total_runtime": 0.00023293495178222656
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 170.60683391140944,
    "kernel_usage": 5.331463559731545,
    "cpu_runtime": 0.00012121400000000002,
    "total_runtime": 7.104873657226562e-05
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 179.2289301041096,
    "kernel_usage": 5.600904065753425,
    "cpu_runtime": 0.000124776,
    "total_runtime": 6.961822509765625e-05
  },
  {
    "task_id": "HumanEval_135.py",
    "status": "success",
    "cpu_usage": 178.80830378280544,
    "kernel_usage": 5.58775949321267,
    "cpu_runtime": 9.4215e-05,
    "total_runtime": 5.269050598144531e-05
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 175.47372556564417,
    "kernel_usage": 5.48355392392638,
    "cpu_runtime": 0.000204579,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 150.89292038918921,
    "kernel_usage": 4.715403762162163,
    "cpu_runtime": 3.9933000000000005e-05,
    "total_runtime": 2.6464462280273438e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 243.78251443649123,
    "kernel_usage": 7.618203576140351,
    "cpu_runtime": 0.000331297,
    "total_runtime": 0.00013589859008789062
  },
  {
    "task_id": "HumanEval_141.py",
    "status": "success",
    "cpu_usage": 302.86583007308445,
    "kernel_usage": 9.46455718978389,
    "cpu_runtime": 0.002940344,
    "total_runtime": 0.0009708404541015625
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 193.43663139862412,
    "kernel_usage": 6.044894731207004,
    "cpu_runtime": 0.0007374409999999999,
    "total_runtime": 0.00038123130798339844
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 372.93392944476915,
    "kernel_usage": 11.654185295149036,
    "cpu_runtime": 0.001521325,
    "total_runtime": 0.00040793418884277344
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.0631017561753,
    "kernel_usage": 6.314471929880479,
    "cpu_runtime": 0.00048368300000000005,
    "total_runtime": 0.00023937225341796875
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 380.03006733105804,
    "kernel_usage": 11.875939604095564,
    "cpu_runtime": 0.0010619050000000001,
    "total_runtime": 0.00027942657470703125
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.06925280512596,
    "kernel_usage": 6.252164150160186,
    "cpu_runtime": 0.5934795460000001,
    "total_runtime": 0.29663705825805664
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.84875330370372,
    "kernel_usage": 6.120273540740741,
    "cpu_runtime": 0.000201718,
    "total_runtime": 0.000102996826171875
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 288.524454356314,
    "kernel_usage": 9.016389198634812,
    "cpu_runtime": 0.000806214,
    "total_runtime": 0.00027942657470703125
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 181.1682008736196,
    "kernel_usage": 5.661506277300613,
    "cpu_runtime": 0.000211218,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 321.682946439191,
    "kernel_usage": 10.05259207622472,
    "cpu_runtime": 0.003412936,
    "total_runtime": 0.0010609626770019531
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 236.27150921712064,
    "kernel_usage": 7.38348466303502,
    "cpu_runtime": 0.00028954400000000003,
    "total_runtime": 0.00012254714965820312
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 356.5427586674627,
    "kernel_usage": 11.14196120835821,
    "cpu_runtime": 0.007404059,
    "total_runtime": 0.0020766258239746094
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 204.50991473347733,
    "kernel_usage": 6.390934835421167,
    "cpu_runtime": 0.00045150800000000004,
    "total_runtime": 0.00022077560424804688
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 202.46811584790123,
    "kernel_usage": 6.3271286202469135,
    "cpu_runtime": 0.0007820090000000001,
    "total_runtime": 0.00038623809814453125
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.87450912820515,
    "kernel_usage": 5.277328410256411,
    "cpu_runtime": 0.00012562,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 197.2652379697743,
    "kernel_usage": 6.164538686555447,
    "cpu_runtime": 0.000479253,
    "total_runtime": 0.0002429485321044922
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 255.5305660022599,
    "kernel_usage": 7.9853301875706215,
    "cpu_runtime": 0.001725346,
    "total_runtime": 0.000675201416015625
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 224.14407969265534,
    "kernel_usage": 7.004502490395479,
    "cpu_runtime": 0.000189178,
    "total_runtime": 8.440017700195312e-05
  }
]