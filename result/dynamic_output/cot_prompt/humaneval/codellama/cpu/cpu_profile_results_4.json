[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 210.6635590396818,
    "kernel_usage": 6.583236219990056,
    "cpu_runtime": 0.0010100470000000002,
    "total_runtime": 0.0004794597625732422
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.1854812768837,
    "kernel_usage": 6.880796289902616,
    "cpu_runtime": 0.0010242030000000002,
    "total_runtime": 0.00046515464782714844
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 133.10424015238095,
    "kernel_usage": 4.159507504761905,
    "cpu_runtime": 2.6657000000000002e-05,
    "total_runtime": 2.002716064453125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.59525081791045,
    "kernel_usage": 5.206101588059702,
    "cpu_runtime": 7.9836e-05,
    "total_runtime": 4.792213439941406e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 323.1574202181818,
    "kernel_usage": 10.098669381818182,
    "cpu_runtime": 0.000542409,
    "total_runtime": 0.0001678466796875
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 197.98542728170216,
    "kernel_usage": 6.187044602553192,
    "cpu_runtime": 0.00011092800000000002,
    "total_runtime": 5.602836608886719e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.5659044488688,
    "kernel_usage": 6.33018451402715,
    "cpu_runtime": 0.00010673300000000001,
    "total_runtime": 5.269050598144531e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 154.02547632676058,
    "kernel_usage": 4.813296135211268,
    "cpu_runtime": 5.2146000000000005e-05,
    "total_runtime": 3.3855438232421875e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 217.178593882353,
    "kernel_usage": 6.786831058823531,
    "cpu_runtime": 0.00024647000000000004,
    "total_runtime": 0.00011348724365234375
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.14641569567726,
    "kernel_usage": 6.6920754904899145,
    "cpu_runtime": 0.000177166,
    "total_runtime": 8.273124694824219e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.8264809411765,
    "kernel_usage": 10.088327529411766,
    "cpu_runtime": 0.000418705,
    "total_runtime": 0.00012969970703125
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 298.4000263057644,
    "kernel_usage": 9.325000822055138,
    "cpu_runtime": 0.000283865,
    "total_runtime": 9.512901306152344e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 159.7762102468085,
    "kernel_usage": 4.993006570212765,
    "cpu_runtime": 3.5808e-05,
    "total_runtime": 2.2411346435546875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.68918593015871,
    "kernel_usage": 6.61528706031746,
    "cpu_runtime": 0.000127186,
    "total_runtime": 6.008148193359375e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.76973955121952,
    "kernel_usage": 7.39905436097561,
    "cpu_runtime": 0.000185157,
    "total_runtime": 7.82012939453125e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.39467785416514,
    "kernel_usage": 6.731083682942661,
    "cpu_runtime": 0.001424049,
    "total_runtime": 0.0006611347198486328
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.20448142222224,
    "kernel_usage": 7.006390044444445,
    "cpu_runtime": 0.000307898,
    "total_runtime": 0.0001373291015625
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 260.5932890140845,
    "kernel_usage": 8.143540281690141,
    "cpu_runtime": 0.00017645,
    "total_runtime": 6.771087646484375e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 171.6773971027027,
    "kernel_usage": 5.36491865945946,
    "cpu_runtime": 3.0289e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 204.024453640678,
    "kernel_usage": 6.375764176271187,
    "cpu_runtime": 5.739900000000001e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 172.83100421224492,
    "kernel_usage": 5.400968881632654,
    "cpu_runtime": 4.0382e-05,
    "total_runtime": 2.3365020751953125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.14436036923075,
    "kernel_usage": 8.254511261538461,
    "cpu_runtime": 0.000130992,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 205.2590077502439,
    "kernel_usage": 6.414343992195122,
    "cpu_runtime": 0.000100322,
    "total_runtime": 4.887580871582031e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76549548164425,
    "kernel_usage": 6.242671733801383,
    "cpu_runtime": 0.021979756,
    "total_runtime": 0.011002779006958008
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.06021758875224,
    "kernel_usage": 5.626881799648507,
    "cpu_runtime": 0.00024427000000000004,
    "total_runtime": 0.00013566017150878906
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 181.52717887123288,
    "kernel_usage": 5.672724339726027,
    "cpu_runtime": 3.1594e-05,
    "total_runtime": 1.7404556274414062e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.11496460487805,
    "kernel_usage": 5.066092643902439,
    "cpu_runtime": 3.1694000000000005e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 206.0940264651466,
    "kernel_usage": 6.440438327035832,
    "cpu_runtime": 0.00030169900000000005,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 160.61115317073168,
    "kernel_usage": 5.019098536585365,
    "cpu_runtime": 7.85e-05,
    "total_runtime": 4.887580871582031e-05
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 170.6656218898551,
    "kernel_usage": 5.3333006840579715,
    "cpu_runtime": 5.615200000000001e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 200.43105141621623,
    "kernel_usage": 6.263470356756757,
    "cpu_runtime": 7.072400000000001e-05,
    "total_runtime": 3.528594970703125e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.9661799059581,
    "kernel_usage": 5.342693122061191,
    "cpu_runtime": 0.000253129,
    "total_runtime": 0.0001480579376220703
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 137.51670941538464,
    "kernel_usage": 4.29739716923077,
    "cpu_runtime": 1.7049000000000002e-05,
    "total_runtime": 1.239776611328125e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.34143944852613,
    "kernel_usage": 6.760669982766442,
    "cpu_runtime": 0.0004549340000000001,
    "total_runtime": 0.00021028518676757812
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 209.10087123478266,
    "kernel_usage": 6.534402226086958,
    "cpu_runtime": 0.00018346100000000002,
    "total_runtime": 8.7738037109375e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.2508732470939,
    "kernel_usage": 6.195339788971684,
    "cpu_runtime": 0.001902957,
    "total_runtime": 0.0009598731994628906
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 361.09558109048925,
    "kernel_usage": 11.284236909077789,
    "cpu_runtime": 0.276812993,
    "total_runtime": 0.0766592025756836
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 270.30180626252286,
    "kernel_usage": 8.44693144570384,
    "cpu_runtime": 0.000705028,
    "total_runtime": 0.0002608299255371094
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 157.21039583355704,
    "kernel_usage": 4.912824869798658,
    "cpu_runtime": 5.5848e-05,
    "total_runtime": 3.552436828613281e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.3329339123477,
    "kernel_usage": 9.322904184760866,
    "cpu_runtime": 0.019556675,
    "total_runtime": 0.006555318832397461
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 175.4514371764706,
    "kernel_usage": 5.482857411764706,
    "cpu_runtime": 0.00011378000000000001,
    "total_runtime": 6.4849853515625e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62041057196848,
    "kernel_usage": 6.238137830374015,
    "cpu_runtime": 0.006095263,
    "total_runtime": 0.003053426742553711
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.28221911782478,
    "kernel_usage": 5.821319347432024,
    "cpu_runtime": 0.000294015,
    "total_runtime": 0.00015783309936523438
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 197.81768048312608,
    "kernel_usage": 6.18180251509769,
    "cpu_runtime": 0.00026553,
    "total_runtime": 0.0001342296600341797
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 213.1705075809524,
    "kernel_usage": 6.661578361904763,
    "cpu_runtime": 0.00010673000000000002,
    "total_runtime": 5.0067901611328125e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 185.87788857918554,
    "kernel_usage": 5.808684018099548,
    "cpu_runtime": 0.00029382000000000003,
    "total_runtime": 0.00015807151794433594
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.70773848832812,
    "kernel_usage": 6.459616827760254,
    "cpu_runtime": 0.00015622700000000002,
    "total_runtime": 7.557868957519531e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.8939125032133,
    "kernel_usage": 6.246684765725416,
    "cpu_runtime": 0.03181438000000001,
    "total_runtime": 0.015915632247924805
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 281.459442646583,
    "kernel_usage": 8.795607582705719,
    "cpu_runtime": 0.000481144,
    "total_runtime": 0.0001709461212158203
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.696336364557,
    "kernel_usage": 11.303010511392406,
    "cpu_runtime": 0.001635018,
    "total_runtime": 0.0004520416259765625
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.6937353752381,
    "kernel_usage": 6.334179230476191,
    "cpu_runtime": 0.000202969,
    "total_runtime": 0.00010013580322265625
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.21609426622078,
    "kernel_usage": 6.100502945819399,
    "cpu_runtime": 0.00013916400000000002,
    "total_runtime": 7.128715515136719e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.22655211520004,
    "kernel_usage": 6.038329753600001,
    "cpu_runtime": 0.00028793000000000004,
    "total_runtime": 0.00014901161193847656
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.54681441669152,
    "kernel_usage": 6.04833795052161,
    "cpu_runtime": 0.00030963400000000004,
    "total_runtime": 0.00015997886657714844
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 183.6289592888889,
    "kernel_usage": 5.738404977777778,
    "cpu_runtime": 6.3044e-05,
    "total_runtime": 3.4332275390625e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.3705261176471,
    "kernel_usage": 6.105328941176472,
    "cpu_runtime": 0.00025339500000000006,
    "total_runtime": 0.00012969970703125
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 193.28629990311418,
    "kernel_usage": 6.040196871972318,
    "cpu_runtime": 0.00026636,
    "total_runtime": 0.00013780593872070312
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 278.25738306039455,
    "kernel_usage": 8.69554322063733,
    "cpu_runtime": 0.000437192,
    "total_runtime": 0.0001571178436279297
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.23611537913484,
    "kernel_usage": 6.757378605597964,
    "cpu_runtime": 0.00020260999999999999,
    "total_runtime": 9.369850158691406e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.15531776000006,
    "kernel_usage": 9.036103680000002,
    "cpu_runtime": 0.0009444780000000001,
    "total_runtime": 0.0003266334533691406
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 278.11165810930135,
    "kernel_usage": 8.690989315915667,
    "cpu_runtime": 0.001603966,
    "total_runtime": 0.0005767345428466797
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.15397135587824,
    "kernel_usage": 7.036061604871195,
    "cpu_runtime": 0.001146087,
    "total_runtime": 0.0005090236663818359
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.97542077581863,
    "kernel_usage": 6.124231899244332,
    "cpu_runtime": 0.000185495,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 283.45309704197314,
    "kernel_usage": 8.85790928256166,
    "cpu_runtime": 0.0015617849999999998,
    "total_runtime": 0.0005509853363037109
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.6592447072464,
    "kernel_usage": 6.61435139710145,
    "cpu_runtime": 0.000557117,
    "total_runtime": 0.000263214111328125
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.19087508594706,
    "kernel_usage": 6.2872148464358455,
    "cpu_runtime": 0.003768338,
    "total_runtime": 0.001873016357421875
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 190.61245886405698,
    "kernel_usage": 5.9566393395017805,
    "cpu_runtime": 0.00012770200000000002,
    "total_runtime": 6.699562072753906e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 186.44012061072556,
    "kernel_usage": 5.826253769085174,
    "cpu_runtime": 0.00014090900000000002,
    "total_runtime": 7.557868957519531e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.18538623864552,
    "kernel_usage": 6.2557933199576725,
    "cpu_runtime": 0.002255144,
    "total_runtime": 0.0011265277862548828
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 276.7772902259598,
    "kernel_usage": 8.649290319561244,
    "cpu_runtime": 0.001082877,
    "total_runtime": 0.00039124488830566406
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.6677596110211,
    "kernel_usage": 6.395867487844409,
    "cpu_runtime": 0.00030107500000000004,
    "total_runtime": 0.00014710426330566406
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.71005971253484,
    "kernel_usage": 6.897189366016714,
    "cpu_runtime": 0.0007556430000000001,
    "total_runtime": 0.00034236907958984375
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.7088747102041,
    "kernel_usage": 6.990902334693878,
    "cpu_runtime": 0.00041815700000000006,
    "total_runtime": 0.000186920166015625
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.71043565636205,
    "kernel_usage": 8.584701114261314,
    "cpu_runtime": 0.000766959,
    "total_runtime": 0.0002791881561279297
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 239.28466937611415,
    "kernel_usage": 7.477645918003567,
    "cpu_runtime": 0.0009601500000000002,
    "total_runtime": 0.0004012584686279297
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.53296429348575,
    "kernel_usage": 11.57915513417143,
    "cpu_runtime": 0.002318976,
    "total_runtime": 0.0006258487701416016
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.46653508266667,
    "kernel_usage": 7.139579221333333,
    "cpu_runtime": 0.00032682400000000003,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.11056935030012,
    "kernel_usage": 6.315955292196879,
    "cpu_runtime": 0.000401397,
    "total_runtime": 0.00019860267639160156
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.41526448495193,
    "kernel_usage": 8.200477015154748,
    "cpu_runtime": 0.000586231,
    "total_runtime": 0.00022339820861816406
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 265.56863598796696,
    "kernel_usage": 8.299019874623967,
    "cpu_runtime": 0.002609906,
    "total_runtime": 0.0009827613830566406
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 243.90882618145616,
    "kernel_usage": 7.622150818170505,
    "cpu_runtime": 0.000934509,
    "total_runtime": 0.00038313865661621094
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.4379904843956,
    "kernel_usage": 6.669937202637363,
    "cpu_runtime": 0.001389231,
    "total_runtime": 0.0006508827209472656
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.87659978867924,
    "kernel_usage": 6.308643743396226,
    "cpu_runtime": 0.0007142660000000001,
    "total_runtime": 0.00035381317138671875
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.344790242623,
    "kernel_usage": 6.6045246950819685,
    "cpu_runtime": 0.00036884400000000006,
    "total_runtime": 0.00017452239990234375
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.5721073023401,
    "kernel_usage": 6.986628353198128,
    "cpu_runtime": 0.0013667080000000001,
    "total_runtime": 0.0006113052368164062
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 143.2466877557252,
    "kernel_usage": 4.476458992366412,
    "cpu_runtime": 4.474e-05,
    "total_runtime": 3.123283386230469e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.11551068460315,
    "kernel_usage": 6.5661097088938485,
    "cpu_runtime": 0.001571494,
    "total_runtime": 0.0007479190826416016
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.46029518513012,
    "kernel_usage": 6.295634224535316,
    "cpu_runtime": 0.000516823,
    "total_runtime": 0.00025653839111328125
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.84109928392556,
    "kernel_usage": 5.745034352622674,
    "cpu_runtime": 0.000259042,
    "total_runtime": 0.00014090538024902344
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.3938521404752,
    "kernel_usage": 6.16855787938985,
    "cpu_runtime": 0.7460231460000001,
    "total_runtime": 0.37793636322021484
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 194.09861677850748,
    "kernel_usage": 6.065581774328359,
    "cpu_runtime": 0.00015502700000000002,
    "total_runtime": 7.987022399902344e-05
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.68588874545193,
    "kernel_usage": 6.240184023295373,
    "cpu_runtime": 0.013210497000000002,
    "total_runtime": 0.006615638732910156
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 253.57674571851857,
    "kernel_usage": 7.924273303703705,
    "cpu_runtime": 0.00026117600000000006,
    "total_runtime": 0.000102996826171875
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 298.55415228205976,
    "kernel_usage": 9.329817258814368,
    "cpu_runtime": 0.008224948000000001,
    "total_runtime": 0.0027549266815185547
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.6077904457143,
    "kernel_usage": 5.987743451428572,
    "cpu_runtime": 0.000239835,
    "total_runtime": 0.0001251697540283203
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.4115935154717,
    "kernel_usage": 5.262862297358491,
    "cpu_runtime": 0.000106404,
    "total_runtime": 6.318092346191406e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.61756145675474,
    "kernel_usage": 8.488048795523586,
    "cpu_runtime": 0.0008101310000000004,
    "total_runtime": 0.0002982616424560547
  }
]