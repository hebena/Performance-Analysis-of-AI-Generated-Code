[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.50756283995608,
    "kernel_usage": 6.6096113387486275,
    "cpu_runtime": 0.000918786,
    "total_runtime": 0.0004343986511230469
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.6144829295775,
    "kernel_usage": 6.894202591549297,
    "cpu_runtime": 0.0009336250000000001,
    "total_runtime": 0.00042319297790527344
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.9167562805195,
    "kernel_usage": 4.091148633766235,
    "cpu_runtime": 2.4034000000000004e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 164.94044999788363,
    "kernel_usage": 5.1543890624338635,
    "cpu_runtime": 7.432400000000002e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 325.17271290824266,
    "kernel_usage": 10.161647278382583,
    "cpu_runtime": 0.0004985,
    "total_runtime": 0.0001533031463623047
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 195.94485947031964,
    "kernel_usage": 6.123276858447489,
    "cpu_runtime": 0.00010231,
    "total_runtime": 5.221366882324219e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 201.76944237157363,
    "kernel_usage": 6.305295074111676,
    "cpu_runtime": 9.476800000000001e-05,
    "total_runtime": 4.696846008300781e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 152.99780544496127,
    "kernel_usage": 4.78118142015504,
    "cpu_runtime": 4.7056000000000005e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.191555712297,
    "kernel_usage": 6.755986116009281,
    "cpu_runtime": 0.000222155,
    "total_runtime": 0.00010275840759277344
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.43651557402598,
    "kernel_usage": 6.701141111688312,
    "cpu_runtime": 0.000157467,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.06831781494947,
    "kernel_usage": 10.06463493171717,
    "cpu_runtime": 0.000380096,
    "total_runtime": 0.00011801719665527344
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.0470093079019,
    "kernel_usage": 9.282719040871934,
    "cpu_runtime": 0.000259915,
    "total_runtime": 8.749961853027344e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 156.71577957209306,
    "kernel_usage": 4.897368111627908,
    "cpu_runtime": 3.2133000000000006e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.81779914805196,
    "kernel_usage": 6.619306223376624,
    "cpu_runtime": 0.00011665800000000001,
    "total_runtime": 5.507469177246094e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 238.59863747713314,
    "kernel_usage": 7.456207421160411,
    "cpu_runtime": 0.000166677,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.36846451286112,
    "kernel_usage": 6.73026451602691,
    "cpu_runtime": 0.0012975600000000001,
    "total_runtime": 0.0006024837493896484
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.77605058484292,
    "kernel_usage": 7.055501580776341,
    "cpu_runtime": 0.000291216,
    "total_runtime": 0.0001289844512939453
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.33655720749067,
    "kernel_usage": 8.166767412734083,
    "cpu_runtime": 0.00016636100000000002,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 167.40824244705883,
    "kernel_usage": 5.231507576470588,
    "cpu_runtime": 2.7141e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 205.22460113027523,
    "kernel_usage": 6.413268785321101,
    "cpu_runtime": 5.3333e-05,
    "total_runtime": 2.5987625122070312e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 173.31153390344826,
    "kernel_usage": 5.415985434482758,
    "cpu_runtime": 3.5949e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 263.95476672688176,
    "kernel_usage": 8.248586460215055,
    "cpu_runtime": 0.000117053,
    "total_runtime": 4.4345855712890625e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.486328515847,
    "kernel_usage": 6.3276977661202185,
    "cpu_runtime": 8.8346e-05,
    "total_runtime": 4.363059997558594e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76148280651233,
    "kernel_usage": 6.24254633770351,
    "cpu_runtime": 0.019950887000000004,
    "total_runtime": 0.009987354278564453
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.69255325422398,
    "kernel_usage": 5.615392289194499,
    "cpu_runtime": 0.000218066,
    "total_runtime": 0.00012135505676269531
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.16130855384617,
    "kernel_usage": 5.598790892307693,
    "cpu_runtime": 2.7765000000000003e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.6632647111111,
    "kernel_usage": 5.083227022222222,
    "cpu_runtime": 2.7923e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 204.68203519999997,
    "kernel_usage": 6.396313599999999,
    "cpu_runtime": 0.00025717599999999996,
    "total_runtime": 0.00012564659118652344
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 161.86984220444444,
    "kernel_usage": 5.058432568888889,
    "cpu_runtime": 6.9467e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 166.6784145723077,
    "kernel_usage": 5.208700455384616,
    "cpu_runtime": 5.1661e-05,
    "total_runtime": 3.0994415283203125e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.0794247474453,
    "kernel_usage": 6.221232023357666,
    "cpu_runtime": 6.502600000000001e-05,
    "total_runtime": 3.266334533691406e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.72598931256638,
    "kernel_usage": 5.3351871660176995,
    "cpu_runtime": 0.000229979,
    "total_runtime": 0.0001347064971923828
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.54842417021274,
    "kernel_usage": 4.173388255319148,
    "cpu_runtime": 1.4965e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.30879722886598,
    "kernel_usage": 6.759649913402062,
    "cpu_runtime": 0.000400199,
    "total_runtime": 0.0001850128173828125
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 209.62776586827795,
    "kernel_usage": 6.550867683383686,
    "cpu_runtime": 0.000165431,
    "total_runtime": 7.891654968261719e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.31970268993885,
    "kernel_usage": 6.197490709060589,
    "cpu_runtime": 0.001701246,
    "total_runtime": 0.0008578300476074219
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.54669346667174,
    "kernel_usage": 11.267084170833492,
    "cpu_runtime": 0.25233774500000006,
    "total_runtime": 0.06998753547668457
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.9783492220541,
    "kernel_usage": 8.71807341318919,
    "cpu_runtime": 0.000615251,
    "total_runtime": 0.0002205371856689453
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 156.9464071757576,
    "kernel_usage": 4.904575224242425,
    "cpu_runtime": 4.9393e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.01518751634205,
    "kernel_usage": 9.28172460988569,
    "cpu_runtime": 0.017593015000000004,
    "total_runtime": 0.005923271179199219
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.12931072,
    "kernel_usage": 5.50404096,
    "cpu_runtime": 0.000100782,
    "total_runtime": 5.7220458984375e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.63821946017043,
    "kernel_usage": 6.238694358130326,
    "cpu_runtime": 0.005529397,
    "total_runtime": 0.0027697086334228516
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.2848044671141,
    "kernel_usage": 5.821400139597316,
    "cpu_runtime": 0.000264706,
    "total_runtime": 0.00014209747314453125
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.37195584247104,
    "kernel_usage": 6.19912362007722,
    "cpu_runtime": 0.000244991,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 212.73204053333336,
    "kernel_usage": 6.6478762666666675,
    "cpu_runtime": 9.738100000000001e-05,
    "total_runtime": 4.57763671875e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.15521518535775,
    "kernel_usage": 5.81735047454243,
    "cpu_runtime": 0.000266741,
    "total_runtime": 0.00014328956604003906
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.84146066285717,
    "kernel_usage": 6.432545645714287,
    "cpu_runtime": 0.000137414,
    "total_runtime": 6.67572021484375e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89483668996024,
    "kernel_usage": 6.246713646561258,
    "cpu_runtime": 0.029478777,
    "total_runtime": 0.014747142791748047
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 280.41173783558287,
    "kernel_usage": 8.762866807361965,
    "cpu_runtime": 0.00043589700000000003,
    "total_runtime": 0.00015544891357421875
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.6504679515009,
    "kernel_usage": 11.301577123484403,
    "cpu_runtime": 0.0014649490000000001,
    "total_runtime": 0.0004050731658935547
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 203.31751750182772,
    "kernel_usage": 6.353672421932116,
    "cpu_runtime": 0.00018565800000000003,
    "total_runtime": 9.131431579589844e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.15172856606503,
    "kernel_usage": 6.098491517689532,
    "cpu_runtime": 0.00012888200000000003,
    "total_runtime": 6.604194641113281e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.76637773119432,
    "kernel_usage": 6.055199304099823,
    "cpu_runtime": 0.00025916800000000005,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 192.97430722091505,
    "kernel_usage": 6.030447100653595,
    "cpu_runtime": 0.000281573,
    "total_runtime": 0.00014591217041015625
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.03962492121212,
    "kernel_usage": 5.813738278787879,
    "cpu_runtime": 5.8549000000000005e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.696075497006,
    "kernel_usage": 6.084252359281438,
    "cpu_runtime": 0.00023256,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 191.81296974953273,
    "kernel_usage": 5.994155304672898,
    "cpu_runtime": 0.00024466500000000003,
    "total_runtime": 0.00012755393981933594
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 280.8486642526316,
    "kernel_usage": 8.776520757894737,
    "cpu_runtime": 0.00040711400000000003,
    "total_runtime": 0.00014495849609375
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.1165349498592,
    "kernel_usage": 6.7536417171831,
    "cpu_runtime": 0.000182918,
    "total_runtime": 8.463859558105469e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.582434932271,
    "kernel_usage": 9.049451091633468,
    "cpu_runtime": 0.0008664750000000001,
    "total_runtime": 0.00029921531677246094
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 278.01314918400004,
    "kernel_usage": 8.687910912000001,
    "cpu_runtime": 0.0014582370000000002,
    "total_runtime": 0.0005245208740234375
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.0687785692542,
    "kernel_usage": 7.0333993302891935,
    "cpu_runtime": 0.00105765,
    "total_runtime": 0.0004699230194091797
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.38329828189416,
    "kernel_usage": 6.105728071309192,
    "cpu_runtime": 0.000167233,
    "total_runtime": 8.559226989746094e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.8098444857001,
    "kernel_usage": 8.900307640178129,
    "cpu_runtime": 0.001372339,
    "total_runtime": 0.0004818439483642578
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.374032206346,
    "kernel_usage": 6.605438506448312,
    "cpu_runtime": 0.000492364,
    "total_runtime": 0.00023293495178222656
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.15283562524465,
    "kernel_usage": 6.286026113288895,
    "cpu_runtime": 0.003381559,
    "total_runtime": 0.0016810894012451172
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.17584827317074,
    "kernel_usage": 6.005495258536586,
    "cpu_runtime": 0.000112713,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 186.28505525527274,
    "kernel_usage": 5.821407976727273,
    "cpu_runtime": 0.00012213800000000002,
    "total_runtime": 6.556510925292969e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.03909255487463,
    "kernel_usage": 6.251221642339832,
    "cpu_runtime": 0.002054616,
    "total_runtime": 0.0010271072387695312
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 276.88072034624406,
    "kernel_usage": 8.652522510820127,
    "cpu_runtime": 0.0009578560000000002,
    "total_runtime": 0.0003459453582763672
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 203.92871118998212,
    "kernel_usage": 6.372772224686941,
    "cpu_runtime": 0.000271788,
    "total_runtime": 0.00013327598571777344
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.81923621463417,
    "kernel_usage": 6.900601131707318,
    "cpu_runtime": 0.0006907340000000001,
    "total_runtime": 0.00031280517578125
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.13224682366203,
    "kernel_usage": 6.972882713239438,
    "cpu_runtime": 0.00037771200000000005,
    "total_runtime": 0.00016927719116210938
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.5170035141014,
    "kernel_usage": 8.57865635981567,
    "cpu_runtime": 0.0007101320000000001,
    "total_runtime": 0.0002586841583251953
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 239.0517213151833,
    "kernel_usage": 7.470366291099478,
    "cpu_runtime": 0.0008708740000000002,
    "total_runtime": 0.0003643035888671875
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 371.1513915416739,
    "kernel_usage": 11.598480985677309,
    "cpu_runtime": 0.002051184,
    "total_runtime": 0.0005526542663574219
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.27768379590313,
    "kernel_usage": 7.164927618621973,
    "cpu_runtime": 0.000293546,
    "total_runtime": 0.00012803077697753906
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.27299905641033,
    "kernel_usage": 6.321031220512823,
    "cpu_runtime": 0.00035735200000000007,
    "total_runtime": 0.0001766681671142578
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 261.216812660069,
    "kernel_usage": 8.163025395627157,
    "cpu_runtime": 0.000541204,
    "total_runtime": 0.0002071857452392578
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 262.11100978232355,
    "kernel_usage": 8.190969055697611,
    "cpu_runtime": 0.0022484670000000005,
    "total_runtime": 0.0008578300476074219
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 243.82302611103103,
    "kernel_usage": 7.61946956596972,
    "cpu_runtime": 0.0008062900000000001,
    "total_runtime": 0.0003306865692138672
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.16572336112722,
    "kernel_usage": 6.661428855035226,
    "cpu_runtime": 0.0012263509999999999,
    "total_runtime": 0.0005753040313720703
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 202.07505258700476,
    "kernel_usage": 6.314845393343899,
    "cpu_runtime": 0.000608012,
    "total_runtime": 0.0003008842468261719
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.23801459780913,
    "kernel_usage": 6.601187956181535,
    "cpu_runtime": 0.00032182000000000006,
    "total_runtime": 0.00015234947204589844
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 222.2819583885356,
    "kernel_usage": 6.9463111996417375,
    "cpu_runtime": 0.0011834039999999999,
    "total_runtime": 0.0005323886871337891
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.03689325714285,
    "kernel_usage": 4.501152914285714,
    "cpu_runtime": 3.8462e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.2853117511776,
    "kernel_usage": 6.5714159922243,
    "cpu_runtime": 0.0013411360000000002,
    "total_runtime": 0.0006377696990966797
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.15232484362048,
    "kernel_usage": 6.28601015136314,
    "cpu_runtime": 0.000439779,
    "total_runtime": 0.0002186298370361328
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.76936808221345,
    "kernel_usage": 5.74279275256917,
    "cpu_runtime": 0.000221699,
    "total_runtime": 0.00012063980102539062
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.39012814902222,
    "kernel_usage": 6.168441504656944,
    "cpu_runtime": 0.7379855609999999,
    "total_runtime": 0.3738715648651123
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.71102534939763,
    "kernel_usage": 6.115969542168676,
    "cpu_runtime": 0.00015491500000000002,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.69122124053294,
    "kernel_usage": 6.240350663766654,
    "cpu_runtime": 0.013221324,
    "total_runtime": 0.006620883941650391
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 255.47373411171174,
    "kernel_usage": 7.983554190990992,
    "cpu_runtime": 0.00027043900000000003,
    "total_runtime": 0.00010585784912109375
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 298.795136374159,
    "kernel_usage": 9.337348011692468,
    "cpu_runtime": 0.008237286,
    "total_runtime": 0.002756834030151367
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.7859701353965,
    "kernel_usage": 5.9933115667311405,
    "cpu_runtime": 0.0002364,
    "total_runtime": 0.0001232624053955078
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.5623228883895,
    "kernel_usage": 5.267572590262172,
    "cpu_runtime": 0.000107303,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 272.3529751962558,
    "kernel_usage": 8.511030474882993,
    "cpu_runtime": 0.0008324539999999998,
    "total_runtime": 0.0003056526184082031
  }
]