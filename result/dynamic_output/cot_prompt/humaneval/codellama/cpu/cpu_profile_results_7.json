[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.85620049830325,
    "kernel_usage": 6.620506265571977,
    "cpu_runtime": 0.0009228260000000001,
    "total_runtime": 0.0004355907440185547
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.41019030936417,
    "kernel_usage": 6.88781844716763,
    "cpu_runtime": 0.000909113,
    "total_runtime": 0.0004124641418457031
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.11849489066668,
    "kernel_usage": 4.066202965333334,
    "cpu_runtime": 2.3267e-05,
    "total_runtime": 1.7881393432617188e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.52843286021505,
    "kernel_usage": 5.17276352688172,
    "cpu_runtime": 7.3405e-05,
    "total_runtime": 4.4345855712890625e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 323.11738368,
    "kernel_usage": 10.09741824,
    "cpu_runtime": 0.000493038,
    "total_runtime": 0.000152587890625
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 195.7608481339535,
    "kernel_usage": 6.1175265041860465,
    "cpu_runtime": 0.000100347,
    "total_runtime": 5.125999450683594e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.72045666262625,
    "kernel_usage": 6.33501427070707,
    "cpu_runtime": 9.569799999999999e-05,
    "total_runtime": 4.7206878662109375e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.31101811612905,
    "kernel_usage": 4.853469316129033,
    "cpu_runtime": 4.5916000000000006e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.30015812387708,
    "kernel_usage": 6.759379941371159,
    "cpu_runtime": 0.000218141,
    "total_runtime": 0.00010085105895996094
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.70642176000007,
    "kernel_usage": 6.709575680000002,
    "cpu_runtime": 0.00015868900000000003,
    "total_runtime": 7.390975952148438e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 321.7861640192,
    "kernel_usage": 10.0558176256,
    "cpu_runtime": 0.000383599,
    "total_runtime": 0.00011920928955078125
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.6530925764383,
    "kernel_usage": 9.301659143013698,
    "cpu_runtime": 0.000259026,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 158.19757638620692,
    "kernel_usage": 4.943674262068966,
    "cpu_runtime": 3.2814e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.46768962782608,
    "kernel_usage": 6.608365300869565,
    "cpu_runtime": 0.000115961,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 233.07747328000005,
    "kernel_usage": 7.2836710400000015,
    "cpu_runtime": 0.00017226700000000004,
    "total_runtime": 7.390975952148438e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.17891026905693,
    "kernel_usage": 6.724340945908029,
    "cpu_runtime": 0.001316426,
    "total_runtime": 0.0006117820739746094
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.96365413284934,
    "kernel_usage": 6.998864191651542,
    "cpu_runtime": 0.000294218,
    "total_runtime": 0.00013136863708496094
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 264.5658723096775,
    "kernel_usage": 8.267683509677422,
    "cpu_runtime": 0.00017598600000000005,
    "total_runtime": 6.651878356933594e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.0053434810811,
    "kernel_usage": 5.312666983783784,
    "cpu_runtime": 2.9994e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 204.47232000000005,
    "kernel_usage": 6.389760000000002,
    "cpu_runtime": 5.4600000000000006e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 174.32970625376342,
    "kernel_usage": 5.447803320430107,
    "cpu_runtime": 3.8654e-05,
    "total_runtime": 2.2172927856445312e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.0617049731959,
    "kernel_usage": 8.251928280412372,
    "cpu_runtime": 0.000122137,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.37062287253892,
    "kernel_usage": 6.449081964766841,
    "cpu_runtime": 9.496100000000003e-05,
    "total_runtime": 4.601478576660156e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76843824782208,
    "kernel_usage": 6.24276369524444,
    "cpu_runtime": 0.020020643,
    "total_runtime": 0.01002192497253418
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.22645203053435,
    "kernel_usage": 5.600826625954198,
    "cpu_runtime": 0.00022391000000000002,
    "total_runtime": 0.00012493133544921875
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 182.9240832,
    "kernel_usage": 5.7163776,
    "cpu_runtime": 2.7912000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 165.2031488,
    "kernel_usage": 5.1625984,
    "cpu_runtime": 3.151e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 206.96161325632798,
    "kernel_usage": 6.467550414260249,
    "cpu_runtime": 0.000276817,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 160.6551584507937,
    "kernel_usage": 5.020473701587303,
    "cpu_runtime": 7.239300000000001e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.7257088,
    "kernel_usage": 5.2726784,
    "cpu_runtime": 5.1491000000000006e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 200.5576362666667,
    "kernel_usage": 6.267426133333334,
    "cpu_runtime": 6.5987e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.72586406467488,
    "kernel_usage": 5.33518325202109,
    "cpu_runtime": 0.00023160700000000002,
    "total_runtime": 0.00013566017150878906
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 136.30595594893617,
    "kernel_usage": 4.259561123404255,
    "cpu_runtime": 1.5274e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 215.4744466192062,
    "kernel_usage": 6.7335764568501935,
    "cpu_runtime": 0.00040122400000000005,
    "total_runtime": 0.0001862049102783203
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 208.0387304310448,
    "kernel_usage": 6.50121032597015,
    "cpu_runtime": 0.000166161,
    "total_runtime": 7.987022399902344e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.2440002956038,
    "kernel_usage": 6.195125009237619,
    "cpu_runtime": 0.001698706,
    "total_runtime": 0.0008568763732910156
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.4254897226905,
    "kernel_usage": 11.232046553834078,
    "cpu_runtime": 0.253231782,
    "total_runtime": 0.07045459747314453
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.8616913814433,
    "kernel_usage": 8.745677855670102,
    "cpu_runtime": 0.000647225,
    "total_runtime": 0.00023126602172851562
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 156.03756963609024,
    "kernel_usage": 4.87617405112782,
    "cpu_runtime": 4.9479000000000005e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.77124428251295,
    "kernel_usage": 9.30535138382853,
    "cpu_runtime": 0.017323294,
    "total_runtime": 0.0058176517486572266
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.27342492561985,
    "kernel_usage": 5.50854452892562,
    "cpu_runtime": 0.000101705,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6059631930783,
    "kernel_usage": 6.237686349783697,
    "cpu_runtime": 0.005610358,
    "total_runtime": 0.0028107166290283203
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.09772105870647,
    "kernel_usage": 5.815553783084577,
    "cpu_runtime": 0.000267546,
    "total_runtime": 0.0001437664031982422
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 197.06933409380864,
    "kernel_usage": 6.15841669043152,
    "cpu_runtime": 0.00025043,
    "total_runtime": 0.0001270771026611328
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 217.81544960000002,
    "kernel_usage": 6.806732800000001,
    "cpu_runtime": 0.000108017,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.66005801290322,
    "kernel_usage": 5.833126812903226,
    "cpu_runtime": 0.00027592,
    "total_runtime": 0.00014781951904296875
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.98371509823326,
    "kernel_usage": 6.468241096819789,
    "cpu_runtime": 0.00013965700000000004,
    "total_runtime": 6.747245788574219e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89221398282754,
    "kernel_usage": 6.246631686963361,
    "cpu_runtime": 0.029084735,
    "total_runtime": 0.014550209045410156
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 279.93081267711216,
    "kernel_usage": 8.747837896159755,
    "cpu_runtime": 0.00043448200000000003,
    "total_runtime": 0.0001552104949951172
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 362.81622532844466,
    "kernel_usage": 11.338007041513896,
    "cpu_runtime": 0.001462751,
    "total_runtime": 0.0004031658172607422
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.03738244885497,
    "kernel_usage": 6.313668201526718,
    "cpu_runtime": 0.000189306,
    "total_runtime": 9.369850158691406e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.40862172720844,
    "kernel_usage": 6.106519428975264,
    "cpu_runtime": 0.00013184699999999999,
    "total_runtime": 6.747245788574219e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.19855049628322,
    "kernel_usage": 6.037454703008851,
    "cpu_runtime": 0.000260251,
    "total_runtime": 0.0001347064971923828
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.42463081025642,
    "kernel_usage": 6.044519712820513,
    "cpu_runtime": 0.00028776400000000003,
    "total_runtime": 0.000148773193359375
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.58691435789473,
    "kernel_usage": 5.79959107368421,
    "cpu_runtime": 5.8849e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.36966146072876,
    "kernel_usage": 6.105301920647774,
    "cpu_runtime": 0.00023010400000000002,
    "total_runtime": 0.00011777877807617188
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 191.73827246480448,
    "kernel_usage": 5.99182101452514,
    "cpu_runtime": 0.000245484,
    "total_runtime": 0.00012803077697753906
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 279.14343078145697,
    "kernel_usage": 8.72323221192053,
    "cpu_runtime": 0.00040198,
    "total_runtime": 0.00014400482177734375
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.95194768695654,
    "kernel_usage": 6.748498365217392,
    "cpu_runtime": 0.00018947200000000005,
    "total_runtime": 8.7738037109375e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.03366274670947,
    "kernel_usage": 9.03230196083467,
    "cpu_runtime": 0.000858631,
    "total_runtime": 0.0002970695495605469
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 278.7020541693694,
    "kernel_usage": 8.709439192792793,
    "cpu_runtime": 0.00147514,
    "total_runtime": 0.0005292892456054688
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.13111050286287,
    "kernel_usage": 7.035347203214465,
    "cpu_runtime": 0.001068678,
    "total_runtime": 0.00047469139099121094
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.47856650463217,
    "kernel_usage": 6.108705203269755,
    "cpu_runtime": 0.000171043,
    "total_runtime": 8.749961853027344e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.08121686278855,
    "kernel_usage": 8.877538026962142,
    "cpu_runtime": 0.001467037,
    "total_runtime": 0.0005164146423339844
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.58630912517694,
    "kernel_usage": 6.612072160161779,
    "cpu_runtime": 0.000498912,
    "total_runtime": 0.0002357959747314453
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.2204475314431,
    "kernel_usage": 6.288138985357597,
    "cpu_runtime": 0.0034009260000000003,
    "total_runtime": 0.0016901493072509766
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 190.50237271969112,
    "kernel_usage": 5.953199147490348,
    "cpu_runtime": 0.00011763600000000001,
    "total_runtime": 6.175041198730469e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 187.10583382535214,
    "kernel_usage": 5.847057307042254,
    "cpu_runtime": 0.000126691,
    "total_runtime": 6.771087646484375e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.26205317484047,
    "kernel_usage": 6.258189161713765,
    "cpu_runtime": 0.002095103,
    "total_runtime": 0.0010461807250976562
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 274.79202011672214,
    "kernel_usage": 8.587250628647567,
    "cpu_runtime": 0.0009833879999999998,
    "total_runtime": 0.0003578662872314453
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.88845644397907,
    "kernel_usage": 6.402764263874346,
    "cpu_runtime": 0.000279906,
    "total_runtime": 0.0001366138458251953
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 219.91620343159445,
    "kernel_usage": 6.872381357237327,
    "cpu_runtime": 0.0007136010000000001,
    "total_runtime": 0.00032448768615722656
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.40689630624138,
    "kernel_usage": 6.950215509570043,
    "cpu_runtime": 0.0003823170000000001,
    "total_runtime": 0.00017189979553222656
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 273.38593309257146,
    "kernel_usage": 8.543310409142858,
    "cpu_runtime": 0.000684393,
    "total_runtime": 0.0002503395080566406
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 238.7285738393862,
    "kernel_usage": 7.460267932480819,
    "cpu_runtime": 0.000890187,
    "total_runtime": 0.00037288665771484375
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 368.4338682559869,
    "kernel_usage": 11.513558382999591,
    "cpu_runtime": 0.002149481,
    "total_runtime": 0.0005834102630615234
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.2849804847584,
    "kernel_usage": 7.1651556401487,
    "cpu_runtime": 0.000294102,
    "total_runtime": 0.00012826919555664062
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.98813875744682,
    "kernel_usage": 6.343379336170213,
    "cpu_runtime": 0.000363939,
    "total_runtime": 0.000179290771484375
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.5886803906355,
    "kernel_usage": 8.205896262207359,
    "cpu_runtime": 0.000561576,
    "total_runtime": 0.00021386146545410156
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 263.47854075409657,
    "kernel_usage": 8.233704398565518,
    "cpu_runtime": 0.0022771590000000004,
    "total_runtime": 0.0008642673492431641
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.92573949860724,
    "kernel_usage": 7.653929359331476,
    "cpu_runtime": 0.0008385500000000001,
    "total_runtime": 0.00034236907958984375
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.21836166870352,
    "kernel_usage": 6.663073802146985,
    "cpu_runtime": 0.001231229,
    "total_runtime": 0.0005774497985839844
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.54997046303032,
    "kernel_usage": 6.2984365769696975,
    "cpu_runtime": 0.000634303,
    "total_runtime": 0.0003147125244140625
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.66358528,
    "kernel_usage": 6.61448704,
    "cpu_runtime": 0.000322973,
    "total_runtime": 0.000152587890625
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 222.63907435189307,
    "kernel_usage": 6.9574710734966585,
    "cpu_runtime": 0.001191675,
    "total_runtime": 0.0005352497100830078
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.70348800000002,
    "kernel_usage": 4.521984000000001,
    "cpu_runtime": 3.864e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.34001101300265,
    "kernel_usage": 6.573125344156333,
    "cpu_runtime": 0.001334464,
    "total_runtime": 0.0006344318389892578
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 200.54693958620692,
    "kernel_usage": 6.267091862068966,
    "cpu_runtime": 0.000443715,
    "total_runtime": 0.00022125244140625
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.96493712868215,
    "kernel_usage": 5.748904285271317,
    "cpu_runtime": 0.00022632099999999998,
    "total_runtime": 0.00012302398681640625
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.43748403654234,
    "kernel_usage": 6.169921376141948,
    "cpu_runtime": 0.755774886,
    "total_runtime": 0.38279199600219727
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.78509579130437,
    "kernel_usage": 6.118284243478262,
    "cpu_runtime": 0.000171778,
    "total_runtime": 8.7738037109375e-05
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.68479268257366,
    "kernel_usage": 6.240149771330427,
    "cpu_runtime": 0.014413969,
    "total_runtime": 0.007218360900878906
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 253.83119267469883,
    "kernel_usage": 7.932224771084338,
    "cpu_runtime": 0.00030138,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.0986184287003,
    "kernel_usage": 9.346831825896885,
    "cpu_runtime": 0.009004397999999999,
    "total_runtime": 0.0030105113983154297
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.06092180353357,
    "kernel_usage": 5.970653806360424,
    "cpu_runtime": 0.000257827,
    "total_runtime": 0.00013494491577148438
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.04844009283278,
    "kernel_usage": 5.251513752901024,
    "cpu_runtime": 0.000117393,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.71196580369013,
    "kernel_usage": 8.490998931365317,
    "cpu_runtime": 0.0008777850000000003,
    "total_runtime": 0.0003230571746826172
  }
]