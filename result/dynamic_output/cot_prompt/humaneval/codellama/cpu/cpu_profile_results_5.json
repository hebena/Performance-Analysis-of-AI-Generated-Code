[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 212.12703529272923,
    "kernel_usage": 6.6289698528977885,
    "cpu_runtime": 0.0009599140000000001,
    "total_runtime": 0.0004525184631347656
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.02388857897762,
    "kernel_usage": 6.875746518093051,
    "cpu_runtime": 0.0009132900000000001,
    "total_runtime": 0.0004150867462158203
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 133.17439488000002,
    "kernel_usage": 4.161699840000001,
    "cpu_runtime": 2.5401000000000003e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.50322001702128,
    "kernel_usage": 5.171975625531915,
    "cpu_runtime": 7.4183e-05,
    "total_runtime": 4.482269287109375e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 321.63823616,
    "kernel_usage": 10.05119488,
    "cpu_runtime": 0.000490781,
    "total_runtime": 0.000152587890625
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 197.03442090666667,
    "kernel_usage": 6.157325653333333,
    "cpu_runtime": 9.8651e-05,
    "total_runtime": 5.0067901611328125e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 200.4939913552239,
    "kernel_usage": 6.265437229850747,
    "cpu_runtime": 9.608100000000002e-05,
    "total_runtime": 4.792213439941406e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 156.4213248,
    "kernel_usage": 4.8881664,
    "cpu_runtime": 4.7736e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.92452976783218,
    "kernel_usage": 6.747641555244756,
    "cpu_runtime": 0.00022085100000000002,
    "total_runtime": 0.00010228157043457031
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 215.54555142564104,
    "kernel_usage": 6.735798482051282,
    "cpu_runtime": 0.000160337,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 321.77427764630744,
    "kernel_usage": 10.055446176447107,
    "cpu_runtime": 0.000384352,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.0841744265194,
    "kernel_usage": 9.28388045082873,
    "cpu_runtime": 0.00025640600000000004,
    "total_runtime": 8.630752563476562e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.77732421818186,
    "kernel_usage": 4.930541381818183,
    "cpu_runtime": 3.3103000000000005e-05,
    "total_runtime": 2.09808349609375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 213.0132851965812,
    "kernel_usage": 6.656665162393162,
    "cpu_runtime": 0.00011884,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.3490304,
    "kernel_usage": 7.3859072,
    "cpu_runtime": 0.000163415,
    "total_runtime": 6.914138793945312e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.2612625175719,
    "kernel_usage": 6.726914453674122,
    "cpu_runtime": 0.0012851100000000001,
    "total_runtime": 0.0005970001220703125
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.40496424650286,
    "kernel_usage": 6.981405132703214,
    "cpu_runtime": 0.000281766,
    "total_runtime": 0.00012612342834472656
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 260.61894463754794,
    "kernel_usage": 8.144342019923373,
    "cpu_runtime": 0.00016217600000000001,
    "total_runtime": 6.222724914550781e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 168.99961072941176,
    "kernel_usage": 5.281237835294117,
    "cpu_runtime": 2.7399e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 205.38508044190476,
    "kernel_usage": 6.418283763809524,
    "cpu_runtime": 5.1416e-05,
    "total_runtime": 2.5033950805664062e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 175.5388539586207,
    "kernel_usage": 5.485589186206897,
    "cpu_runtime": 3.6411e-05,
    "total_runtime": 2.0742416381835938e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.7551387379679,
    "kernel_usage": 8.304848085561497,
    "cpu_runtime": 0.000118485,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.63181976216217,
    "kernel_usage": 6.457244367567568,
    "cpu_runtime": 9.114e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.75428873582885,
    "kernel_usage": 6.242321522994652,
    "cpu_runtime": 0.019682039,
    "total_runtime": 0.009853124618530273
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.78665473976835,
    "kernel_usage": 5.618332960617761,
    "cpu_runtime": 0.00022203800000000003,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 180.9372664358209,
    "kernel_usage": 5.654289576119403,
    "cpu_runtime": 2.8903e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 159.66128294054053,
    "kernel_usage": 4.989415091891892,
    "cpu_runtime": 2.8169e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 206.2847245280859,
    "kernel_usage": 6.446397641502684,
    "cpu_runtime": 0.000274928,
    "total_runtime": 0.00013327598571777344
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 161.9230540939891,
    "kernel_usage": 5.060095440437159,
    "cpu_runtime": 7.0648e-05,
    "total_runtime": 4.363059997558594e-05
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 169.5357492409449,
    "kernel_usage": 5.297992163779528,
    "cpu_runtime": 5.133400000000001e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 202.63080623649637,
    "kernel_usage": 6.3322126948905115,
    "cpu_runtime": 6.6186e-05,
    "total_runtime": 3.266334533691406e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.7275082439716,
    "kernel_usage": 5.335234632624113,
    "cpu_runtime": 0.000229574,
    "total_runtime": 0.00013446807861328125
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 136.18101923404257,
    "kernel_usage": 4.25565685106383,
    "cpu_runtime": 1.526e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 215.35426807847134,
    "kernel_usage": 6.729820877452229,
    "cpu_runtime": 0.00040305399999999997,
    "total_runtime": 0.00018715858459472656
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 209.0232020700297,
    "kernel_usage": 6.531975064688428,
    "cpu_runtime": 0.00016794400000000003,
    "total_runtime": 8.034706115722656e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.30844074666666,
    "kernel_usage": 6.197138773333333,
    "cpu_runtime": 0.001702095,
    "total_runtime": 0.000858306884765625
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.40125670371896,
    "kernel_usage": 11.262539271991217,
    "cpu_runtime": 0.25274979700000005,
    "total_runtime": 0.0701301097869873
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.64783318215456,
    "kernel_usage": 8.70774478694233,
    "cpu_runtime": 0.0006105360000000001,
    "total_runtime": 0.00021910667419433594
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 156.84804792781952,
    "kernel_usage": 4.90150149774436,
    "cpu_runtime": 4.973599999999999e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.0194379777424,
    "kernel_usage": 9.31310743680445,
    "cpu_runtime": 0.017378944000000004,
    "total_runtime": 0.005831480026245117
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.6706979053942,
    "kernel_usage": 5.520959309543569,
    "cpu_runtime": 0.000101513,
    "total_runtime": 5.745887756347656e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62586533235367,
    "kernel_usage": 6.238308291636052,
    "cpu_runtime": 0.005570937999999999,
    "total_runtime": 0.002790689468383789
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.63819494569537,
    "kernel_usage": 5.8324435920529805,
    "cpu_runtime": 0.000268768,
    "total_runtime": 0.00014400482177734375
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 197.18720393472492,
    "kernel_usage": 6.162100122960154,
    "cpu_runtime": 0.00024775900000000007,
    "total_runtime": 0.00012564659118652344
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 213.39710706804124,
    "kernel_usage": 6.668659595876289,
    "cpu_runtime": 9.870300000000001e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.70905615008377,
    "kernel_usage": 5.834658004690118,
    "cpu_runtime": 0.00026575400000000004,
    "total_runtime": 0.0001423358917236328
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.08163986810038,
    "kernel_usage": 6.440051245878137,
    "cpu_runtime": 0.000137083,
    "total_runtime": 6.651878356933594e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.8971772261197,
    "kernel_usage": 6.246786788316241,
    "cpu_runtime": 0.029369506,
    "total_runtime": 0.014692306518554688
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 279.3097206562212,
    "kernel_usage": 8.728428770506913,
    "cpu_runtime": 0.00043351800000000003,
    "total_runtime": 0.0001552104949951172
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 363.07965997730844,
    "kernel_usage": 11.346239374290889,
    "cpu_runtime": 0.0014343810000000002,
    "total_runtime": 0.00039505958557128906
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 203.51977148631576,
    "kernel_usage": 6.3599928589473675,
    "cpu_runtime": 0.000184387,
    "total_runtime": 9.059906005859375e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 194.15539209241882,
    "kernel_usage": 6.067356002888088,
    "cpu_runtime": 0.00012822400000000002,
    "total_runtime": 6.604194641113281e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.5269713702128,
    "kernel_usage": 6.04771785531915,
    "cpu_runtime": 0.00026023200000000005,
    "total_runtime": 0.00013446807861328125
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.4774510535774,
    "kernel_usage": 6.046170345424294,
    "cpu_runtime": 0.00027723300000000005,
    "total_runtime": 0.00014328956604003906
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 182.85588633984963,
    "kernel_usage": 5.714246448120301,
    "cpu_runtime": 5.7983000000000004e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.8326523586207,
    "kernel_usage": 6.088520386206897,
    "cpu_runtime": 0.000229007,
    "total_runtime": 0.00011754035949707031
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 192.1123765769517,
    "kernel_usage": 6.003511768029741,
    "cpu_runtime": 0.00024642100000000003,
    "total_runtime": 0.00012826919555664062
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 278.84641757866666,
    "kernel_usage": 8.713950549333333,
    "cpu_runtime": 0.000398893,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.64748179830983,
    "kernel_usage": 6.738983806197182,
    "cpu_runtime": 0.000182521,
    "total_runtime": 8.463859558105469e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 289.8352293695793,
    "kernel_usage": 9.057350917799353,
    "cpu_runtime": 0.000854102,
    "total_runtime": 0.00029468536376953125
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.8548384827962,
    "kernel_usage": 8.682963702587381,
    "cpu_runtime": 0.0014593940000000001,
    "total_runtime": 0.0005252361297607422
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 224.95609407019282,
    "kernel_usage": 7.029877939693526,
    "cpu_runtime": 0.0010850100000000002,
    "total_runtime": 0.00048232078552246094
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 195.76651045793872,
    "kernel_usage": 6.117703451810585,
    "cpu_runtime": 0.000167561,
    "total_runtime": 8.559226989746094e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.15292894733756,
    "kernel_usage": 8.879779029604299,
    "cpu_runtime": 0.001386788,
    "total_runtime": 0.00048804283142089844
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 210.85808324599586,
    "kernel_usage": 6.5893151014373705,
    "cpu_runtime": 0.000489654,
    "total_runtime": 0.00023221969604492188
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.2143661910045,
    "kernel_usage": 6.287948943468891,
    "cpu_runtime": 0.0033384580000000007,
    "total_runtime": 0.0016591548919677734
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 189.61721811653544,
    "kernel_usage": 5.9255380661417325,
    "cpu_runtime": 0.00011482900000000001,
    "total_runtime": 6.0558319091796875e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.73045849741698,
    "kernel_usage": 5.7728268280442805,
    "cpu_runtime": 0.000119357,
    "total_runtime": 6.461143493652344e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.13899352938972,
    "kernel_usage": 6.254343547793429,
    "cpu_runtime": 0.0020327380000000005,
    "total_runtime": 0.0010156631469726562
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 276.1145756416503,
    "kernel_usage": 8.628580488801571,
    "cpu_runtime": 0.001005237,
    "total_runtime": 0.00036406517028808594
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.6820352,
    "kernel_usage": 6.3963136,
    "cpu_runtime": 0.00027523200000000004,
    "total_runtime": 0.00013446807861328125
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.79860751937747,
    "kernel_usage": 6.899956484980546,
    "cpu_runtime": 0.0006764560000000001,
    "total_runtime": 0.0003063678741455078
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.3572700253879,
    "kernel_usage": 6.948664688293372,
    "cpu_runtime": 0.00037587,
    "total_runtime": 0.0001690387725830078
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.1570167910781,
    "kernel_usage": 8.56740677472119,
    "cpu_runtime": 0.0007033180000000001,
    "total_runtime": 0.00025653839111328125
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 238.20338994802844,
    "kernel_usage": 7.443855935875889,
    "cpu_runtime": 0.000878574,
    "total_runtime": 0.0003688335418701172
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.15932243503136,
    "kernel_usage": 11.56747882609473,
    "cpu_runtime": 0.0019750990000000006,
    "total_runtime": 0.0005335807800292969
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.00780402671904,
    "kernel_usage": 7.12524387583497,
    "cpu_runtime": 0.000276699,
    "total_runtime": 0.00012135505676269531
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.2253714285714,
    "kernel_usage": 6.3195428571428565,
    "cpu_runtime": 0.000351,
    "total_runtime": 0.0001735687255859375
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.4516862413879,
    "kernel_usage": 8.201615195043372,
    "cpu_runtime": 0.000504967,
    "total_runtime": 0.00019240379333496094
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 264.61849506055046,
    "kernel_usage": 8.269327970642202,
    "cpu_runtime": 0.002200578,
    "total_runtime": 0.00083160400390625
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.10605247767276,
    "kernel_usage": 7.628314139927274,
    "cpu_runtime": 0.000800242,
    "total_runtime": 0.00032782554626464844
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.4937003220061,
    "kernel_usage": 6.671678135062691,
    "cpu_runtime": 0.0011773370000000003,
    "total_runtime": 0.0005514621734619141
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 202.1894774529833,
    "kernel_usage": 6.3184211704057285,
    "cpu_runtime": 0.0006059460000000001,
    "total_runtime": 0.00029969215393066406
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.5285163524288,
    "kernel_usage": 6.6102661360134,
    "cpu_runtime": 0.00030108099999999997,
    "total_runtime": 0.0001423358917236328
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.57628326542755,
    "kernel_usage": 6.986758852044611,
    "cpu_runtime": 0.0011471180000000001,
    "total_runtime": 0.0005130767822265625
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.0484401046729,
    "kernel_usage": 4.532763753271028,
    "cpu_runtime": 3.7003e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.03831195615595,
    "kernel_usage": 6.5636972486298735,
    "cpu_runtime": 0.0012974960000000002,
    "total_runtime": 0.0006177425384521484
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.45269827665197,
    "kernel_usage": 6.295396821145374,
    "cpu_runtime": 0.000436113,
    "total_runtime": 0.00021648406982421875
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.87442086733466,
    "kernel_usage": 5.746075652104208,
    "cpu_runtime": 0.000218757,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.35877811427122,
    "kernel_usage": 6.1674618160709755,
    "cpu_runtime": 0.740825696,
    "total_runtime": 0.3753700256347656
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.50046151975687,
    "kernel_usage": 6.109389422492402,
    "cpu_runtime": 0.00015335000000000001,
    "total_runtime": 7.843971252441406e-05
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6844771553512,
    "kernel_usage": 6.240139911104725,
    "cpu_runtime": 0.013251823000000001,
    "total_runtime": 0.006636381149291992
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 253.96463592988766,
    "kernel_usage": 7.9363948728089895,
    "cpu_runtime": 0.000269447,
    "total_runtime": 0.00010609626770019531
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 298.64451084199885,
    "kernel_usage": 9.332640963812464,
    "cpu_runtime": 0.008307184,
    "total_runtime": 0.0027816295623779297
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.17685750210327,
    "kernel_usage": 5.974276796940727,
    "cpu_runtime": 0.000238384,
    "total_runtime": 0.0001246929168701172
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 167.49098628740742,
    "kernel_usage": 5.234093321481482,
    "cpu_runtime": 0.000107819,
    "total_runtime": 6.437301635742188e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.35706344281147,
    "kernel_usage": 8.479908232587858,
    "cpu_runtime": 0.0008100009999999999,
    "total_runtime": 0.00029850006103515625
  }
]