[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.69964162819386,
    "kernel_usage": 6.615613800881058,
    "cpu_runtime": 0.0009165920000000001,
    "total_runtime": 0.0004329681396484375
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.24177210222743,
    "kernel_usage": 6.882555378194607,
    "cpu_runtime": 0.000895816,
    "total_runtime": 0.0004067420959472656
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 131.36560128,
    "kernel_usage": 4.10517504,
    "cpu_runtime": 2.3489999999999997e-05,
    "total_runtime": 1.7881393432617188e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.90358647195768,
    "kernel_usage": 5.1844870772486775,
    "cpu_runtime": 7.4758e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 322.62886894454834,
    "kernel_usage": 10.082152154517136,
    "cpu_runtime": 0.000493831,
    "total_runtime": 0.00015306472778320312
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 195.4327003601896,
    "kernel_usage": 6.107271886255925,
    "cpu_runtime": 9.831500000000001e-05,
    "total_runtime": 5.030632019042969e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.987536384,
    "kernel_usage": 6.343360512,
    "cpu_runtime": 9.679199999999999e-05,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.8334930944,
    "kernel_usage": 4.8697966592,
    "cpu_runtime": 4.6442e-05,
    "total_runtime": 2.9802322387695312e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.60770578373203,
    "kernel_usage": 6.768990805741626,
    "cpu_runtime": 0.000215869,
    "total_runtime": 9.965896606445312e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.67799983157897,
    "kernel_usage": 6.708687494736843,
    "cpu_runtime": 0.00015559700000000002,
    "total_runtime": 7.2479248046875e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.9788496601981,
    "kernel_usage": 10.09308905188119,
    "cpu_runtime": 0.00038887100000000005,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.91675278222226,
    "kernel_usage": 9.309898524444446,
    "cpu_runtime": 0.00025570400000000004,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 146.75440357795276,
    "kernel_usage": 4.586075111811024,
    "cpu_runtime": 4.4436e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.45857157565214,
    "kernel_usage": 6.6080803617391295,
    "cpu_runtime": 0.000115956,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 238.34315158745642,
    "kernel_usage": 7.448223487108013,
    "cpu_runtime": 0.000163089,
    "total_runtime": 6.842613220214844e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.12768438252655,
    "kernel_usage": 6.722740136953955,
    "cpu_runtime": 0.00130329,
    "total_runtime": 0.0006058216094970703
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.76979761403507,
    "kernel_usage": 6.992806175438596,
    "cpu_runtime": 0.00027369,
    "total_runtime": 0.00012230873107910156
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.2893711398496,
    "kernel_usage": 8.1652928481203,
    "cpu_runtime": 0.000165708,
    "total_runtime": 6.341934204101562e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 173.17313299692307,
    "kernel_usage": 5.411660406153846,
    "cpu_runtime": 2.6837e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 207.33565921584162,
    "kernel_usage": 6.4792393504950505,
    "cpu_runtime": 4.9927000000000005e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 175.25362783255812,
    "kernel_usage": 5.476675869767441,
    "cpu_runtime": 3.5934e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.9675398435754,
    "kernel_usage": 8.280235620111732,
    "cpu_runtime": 0.00011308000000000001,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.68831061333336,
    "kernel_usage": 6.459009706666667,
    "cpu_runtime": 8.8701e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76825720464225,
    "kernel_usage": 6.24275803764507,
    "cpu_runtime": 0.020273532000000004,
    "total_runtime": 0.01014852523803711
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.4908413780347,
    "kernel_usage": 5.640338793063584,
    "cpu_runtime": 0.00022333800000000004,
    "total_runtime": 0.00012373924255371094
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.47239011343288,
    "kernel_usage": 5.6085121910447775,
    "cpu_runtime": 2.8669000000000006e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 158.90497115897438,
    "kernel_usage": 4.965780348717949,
    "cpu_runtime": 2.9551000000000002e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 205.3263775536232,
    "kernel_usage": 6.416449298550725,
    "cpu_runtime": 0.000270224,
    "total_runtime": 0.0001316070556640625
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 154.86660923076923,
    "kernel_usage": 4.839581538461538,
    "cpu_runtime": 7.68e-05,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 167.92584442137408,
    "kernel_usage": 5.24768263816794,
    "cpu_runtime": 5.244800000000001e-05,
    "total_runtime": 3.123283386230469e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 202.20927388656716,
    "kernel_usage": 6.319039808955224,
    "cpu_runtime": 6.4602e-05,
    "total_runtime": 3.1948089599609375e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.45894604057972,
    "kernel_usage": 5.326842063768116,
    "cpu_runtime": 0.000224336,
    "total_runtime": 0.0001316070556640625
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 131.17266329600002,
    "kernel_usage": 4.099145728000001,
    "cpu_runtime": 1.5637000000000003e-05,
    "total_runtime": 1.1920928955078125e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.0852992,
    "kernel_usage": 6.7526656,
    "cpu_runtime": 0.00040390700000000006,
    "total_runtime": 0.000186920166015625
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 208.81857333652695,
    "kernel_usage": 6.525580416766467,
    "cpu_runtime": 0.00016628600000000003,
    "total_runtime": 7.963180541992188e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.23939183571818,
    "kernel_usage": 6.194980994866193,
    "cpu_runtime": 0.001730806,
    "total_runtime": 0.0008730888366699219
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.60044842041424,
    "kernel_usage": 11.268764013137945,
    "cpu_runtime": 0.252805236,
    "total_runtime": 0.07010674476623535
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.25988080875277,
    "kernel_usage": 8.726871275273524,
    "cpu_runtime": 0.000608548,
    "total_runtime": 0.00021791458129882812
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 157.56810698507465,
    "kernel_usage": 4.924003343283583,
    "cpu_runtime": 5.034e-05,
    "total_runtime": 3.1948089599609375e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.8238580952303,
    "kernel_usage": 9.306995565475948,
    "cpu_runtime": 0.017432865,
    "total_runtime": 0.005853414535522461
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 175.9502037506073,
    "kernel_usage": 5.498443867206478,
    "cpu_runtime": 0.000103616,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62022097747533,
    "kernel_usage": 6.238131905546104,
    "cpu_runtime": 0.005595053,
    "total_runtime": 0.0028028488159179688
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 185.99108148382834,
    "kernel_usage": 5.812221296369636,
    "cpu_runtime": 0.00026872299999999995,
    "total_runtime": 0.00014448165893554688
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 196.56285297777782,
    "kernel_usage": 6.142589155555557,
    "cpu_runtime": 0.00026993800000000006,
    "total_runtime": 0.0001373291015625
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 213.82859864365483,
    "kernel_usage": 6.682143707614213,
    "cpu_runtime": 0.000100432,
    "total_runtime": 4.696846008300781e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 187.15273710344832,
    "kernel_usage": 5.84852303448276,
    "cpu_runtime": 0.00028468000000000005,
    "total_runtime": 0.00015211105346679688
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.93435586049824,
    "kernel_usage": 6.43544862064057,
    "cpu_runtime": 0.00013796700000000002,
    "total_runtime": 6.699562072753906e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89574224359123,
    "kernel_usage": 6.246741945112226,
    "cpu_runtime": 0.028983735000000004,
    "total_runtime": 0.014499425888061523
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 281.3905386366197,
    "kernel_usage": 8.793454332394365,
    "cpu_runtime": 0.00042869699999999996,
    "total_runtime": 0.00015234947204589844
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.0544973594273,
    "kernel_usage": 11.282953042482102,
    "cpu_runtime": 0.0014427360000000002,
    "total_runtime": 0.00039958953857421875
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 203.39347582680412,
    "kernel_usage": 6.356046119587629,
    "cpu_runtime": 0.000188152,
    "total_runtime": 9.250640869140625e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.01871701637012,
    "kernel_usage": 6.094334906761566,
    "cpu_runtime": 0.000130654,
    "total_runtime": 6.699562072753906e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.69716805734768,
    "kernel_usage": 6.053036501792115,
    "cpu_runtime": 0.00025769000000000003,
    "total_runtime": 0.00013303756713867188
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.46797266029654,
    "kernel_usage": 6.045874145634267,
    "cpu_runtime": 0.000279987,
    "total_runtime": 0.00014472007751464844
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 183.42336669538463,
    "kernel_usage": 5.73198020923077,
    "cpu_runtime": 5.6851e-05,
    "total_runtime": 3.0994415283203125e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.2819093076305,
    "kernel_usage": 6.1025596658634536,
    "cpu_runtime": 0.00023186299999999999,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.19872800935673,
    "kernel_usage": 6.068710250292398,
    "cpu_runtime": 0.00023752200000000002,
    "total_runtime": 0.00012230873107910156
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 278.8306812762226,
    "kernel_usage": 8.713458789881956,
    "cpu_runtime": 0.000394217,
    "total_runtime": 0.00014138221740722656
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 214.32073324692743,
    "kernel_usage": 6.697522913966482,
    "cpu_runtime": 0.00018293100000000003,
    "total_runtime": 8.535385131835938e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 288.3812238940064,
    "kernel_usage": 9.0119132466877,
    "cpu_runtime": 0.0008718190000000001,
    "total_runtime": 0.00030231475830078125
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.21574630423044,
    "kernel_usage": 8.662992072007201,
    "cpu_runtime": 0.001468595,
    "total_runtime": 0.0005297660827636719
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.70211157422736,
    "kernel_usage": 7.053190986694605,
    "cpu_runtime": 0.001027263,
    "total_runtime": 0.0004551410675048828
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.4745183197772,
    "kernel_usage": 6.139828697493037,
    "cpu_runtime": 0.00016816700000000002,
    "total_runtime": 8.559226989746094e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.1765210940953,
    "kernel_usage": 8.911766284190477,
    "cpu_runtime": 0.001427819,
    "total_runtime": 0.0005006790161132812
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.38313637327678,
    "kernel_usage": 6.6057230116648995,
    "cpu_runtime": 0.00047525000000000003,
    "total_runtime": 0.00022482872009277344
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.12253659829702,
    "kernel_usage": 6.285079268696782,
    "cpu_runtime": 0.003322549,
    "total_runtime": 0.0016520023345947266
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 191.87172117590364,
    "kernel_usage": 5.995991286746989,
    "cpu_runtime": 0.000113907,
    "total_runtime": 5.936622619628906e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 186.09126782633453,
    "kernel_usage": 5.815352119572954,
    "cpu_runtime": 0.000124673,
    "total_runtime": 6.699562072753906e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.10006691725107,
    "kernel_usage": 6.253127091164096,
    "cpu_runtime": 0.0020409300000000003,
    "total_runtime": 0.0010199546813964844
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.3231225840475,
    "kernel_usage": 8.666347580751484,
    "cpu_runtime": 0.0010030250000000003,
    "total_runtime": 0.0003616809844970703
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.6896335768116,
    "kernel_usage": 6.396551049275362,
    "cpu_runtime": 0.000269386,
    "total_runtime": 0.0001316070556640625
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 221.06199757977015,
    "kernel_usage": 6.908187424367817,
    "cpu_runtime": 0.0006878040000000001,
    "total_runtime": 0.00031113624572753906
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.79564726436786,
    "kernel_usage": 6.993613977011496,
    "cpu_runtime": 0.000371365,
    "total_runtime": 0.0001659393310546875
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.50923293164556,
    "kernel_usage": 8.578413529113924,
    "cpu_runtime": 0.000672152,
    "total_runtime": 0.0002448558807373047
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 240.6285312,
    "kernel_usage": 7.5196416,
    "cpu_runtime": 0.0008812080000000001,
    "total_runtime": 0.0003662109375
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.71583976233427,
    "kernel_usage": 11.584869992572946,
    "cpu_runtime": 0.0019992810000000003,
    "total_runtime": 0.0005393028259277344
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.06600835728156,
    "kernel_usage": 7.158312761165049,
    "cpu_runtime": 0.00028126000000000003,
    "total_runtime": 0.0001227855682373047
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 203.25386297206705,
    "kernel_usage": 6.3516832178770954,
    "cpu_runtime": 0.00034697,
    "total_runtime": 0.00017070770263671875
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.72772798863906,
    "kernel_usage": 8.21024149964497,
    "cpu_runtime": 0.0005293009999999999,
    "total_runtime": 0.0002014636993408203
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 264.1785004807297,
    "kernel_usage": 8.255578140022804,
    "cpu_runtime": 0.002209516,
    "total_runtime": 0.0008363723754882812
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.4634413733808,
    "kernel_usage": 7.63948254291815,
    "cpu_runtime": 0.000818899,
    "total_runtime": 0.0003349781036376953
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.0253874382391,
    "kernel_usage": 6.657043357444972,
    "cpu_runtime": 0.001176786,
    "total_runtime": 0.0005524158477783203
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 201.78246526661306,
    "kernel_usage": 6.305702039581658,
    "cpu_runtime": 0.0005979910000000001,
    "total_runtime": 0.0002963542938232422
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 211.7025011809524,
    "kernel_usage": 6.615703161904762,
    "cpu_runtime": 0.000296786,
    "total_runtime": 0.00014019012451171875
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.18164701469772,
    "kernel_usage": 6.974426469209304,
    "cpu_runtime": 0.0011440290000000002,
    "total_runtime": 0.0005125999450683594
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.9156033761468,
    "kernel_usage": 4.559862605504588,
    "cpu_runtime": 3.792e-05,
    "total_runtime": 2.5987625122070312e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.3007477511381,
    "kernel_usage": 6.571898367223065,
    "cpu_runtime": 0.00132168,
    "total_runtime": 0.0006284713745117188
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.6982427675676,
    "kernel_usage": 6.334320086486487,
    "cpu_runtime": 0.00044702500000000004,
    "total_runtime": 0.0002205371856689453
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.43450831650102,
    "kernel_usage": 5.732328384890657,
    "cpu_runtime": 0.000219983,
    "total_runtime": 0.00011992454528808594
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.33781390787627,
    "kernel_usage": 6.166806684621133,
    "cpu_runtime": 0.744169347,
    "total_runtime": 0.3771042823791504
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.22211099759033,
    "kernel_usage": 6.100690968674698,
    "cpu_runtime": 0.000154528,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.68489527779306,
    "kernel_usage": 6.240152977431033,
    "cpu_runtime": 0.013547024000000003,
    "total_runtime": 0.006784200668334961
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 254.75068371841493,
    "kernel_usage": 7.960958866200467,
    "cpu_runtime": 0.000260563,
    "total_runtime": 0.00010228157043457031
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.2992839660107,
    "kernel_usage": 9.353102623937835,
    "cpu_runtime": 0.008448134000000001,
    "total_runtime": 0.0028226375579833984
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 189.73434956417913,
    "kernel_usage": 5.929198423880598,
    "cpu_runtime": 0.00024246600000000002,
    "total_runtime": 0.0001277923583984375
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.08862553646213,
    "kernel_usage": 5.252769548014442,
    "cpu_runtime": 0.00011100900000000002,
    "total_runtime": 6.604194641113281e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.77289935287456,
    "kernel_usage": 8.49290310477733,
    "cpu_runtime": 0.0008002270000000001,
    "total_runtime": 0.0002944469451904297
  }
]