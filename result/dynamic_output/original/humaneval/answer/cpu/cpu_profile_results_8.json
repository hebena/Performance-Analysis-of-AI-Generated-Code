[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.63233700670273,
    "kernel_usage": 6.61351053145946,
    "cpu_runtime": 0.000933456,
    "total_runtime": 0.0004410743713378906
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.35073988100282,
    "kernel_usage": 6.885960621281338,
    "cpu_runtime": 0.0009430160000000001,
    "total_runtime": 0.0004279613494873047
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.71024128000002,
    "kernel_usage": 4.084695040000001,
    "cpu_runtime": 2.4931000000000002e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.24247265882354,
    "kernel_usage": 5.195077270588236,
    "cpu_runtime": 7.411800000000001e-05,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 282.0443177223833,
    "kernel_usage": 8.813884928824478,
    "cpu_runtime": 0.00041758900000000006,
    "total_runtime": 0.0001480579376220703
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 197.15043643076925,
    "kernel_usage": 6.160951138461539,
    "cpu_runtime": 9.776900000000002e-05,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_6.py",
    "status": "success",
    "cpu_usage": 369.7419069149798,
    "kernel_usage": 11.554434591093118,
    "cpu_runtime": 0.0008709550000000001,
    "total_runtime": 0.00023555755615234375
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 205.31219391690826,
    "kernel_usage": 6.416006059903383,
    "cpu_runtime": 0.00010132700000000001,
    "total_runtime": 4.935264587402344e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.5414414656489,
    "kernel_usage": 4.860670045801528,
    "cpu_runtime": 4.8580000000000006e-05,
    "total_runtime": 3.123283386230469e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.1972789696145,
    "kernel_usage": 6.724914967800453,
    "cpu_runtime": 0.000226264,
    "total_runtime": 0.00010514259338378906
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.14704548867314,
    "kernel_usage": 6.692095171521036,
    "cpu_runtime": 0.000157765,
    "total_runtime": 7.367134094238281e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 324.00689346021056,
    "kernel_usage": 10.12521542063158,
    "cpu_runtime": 0.000366934,
    "total_runtime": 0.00011324882507324219
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 295.8412650551351,
    "kernel_usage": 9.245039532972973,
    "cpu_runtime": 0.000260976,
    "total_runtime": 8.821487426757812e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 158.0714876717949,
    "kernel_usage": 4.939733989743591,
    "cpu_runtime": 2.9396000000000005e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 198.59076189090914,
    "kernel_usage": 6.2059613090909105,
    "cpu_runtime": 0.00012499800000000003,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.04096600275867,
    "kernel_usage": 7.376280187586208,
    "cpu_runtime": 0.00016320200000000001,
    "total_runtime": 6.914138793945312e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.64223743999997,
    "kernel_usage": 6.207569919999999,
    "cpu_runtime": 0.00012076799999999999,
    "total_runtime": 6.079673767089844e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 222.9128116598575,
    "kernel_usage": 6.966025364370547,
    "cpu_runtime": 0.000223747,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 207.64880622933336,
    "kernel_usage": 6.4890251946666675,
    "cpu_runtime": 0.00022278300000000003,
    "total_runtime": 0.00010728836059570312
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 254.20155532659342,
    "kernel_usage": 7.943798603956044,
    "cpu_runtime": 0.000551518,
    "total_runtime": 0.00021696090698242188
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.11135556594746,
    "kernel_usage": 6.722229861435858,
    "cpu_runtime": 0.001307294,
    "total_runtime": 0.0006077289581298828
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 223.72401797523455,
    "kernel_usage": 6.9913755617260795,
    "cpu_runtime": 0.000284302,
    "total_runtime": 0.0001270771026611328
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 261.7823172637681,
    "kernel_usage": 8.180697414492753,
    "cpu_runtime": 0.00017226199999999998,
    "total_runtime": 6.580352783203125e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 169.11200711111113,
    "kernel_usage": 5.284750222222223,
    "cpu_runtime": 2.903e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.11506109403342,
    "kernel_usage": 5.909845659188544,
    "cpu_runtime": 0.00018892100000000002,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 215.46972251239126,
    "kernel_usage": 6.733428828512227,
    "cpu_runtime": 0.001239606,
    "total_runtime": 0.0005753040313720703
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 342.6122099497674,
    "kernel_usage": 10.706631560930232,
    "cpu_runtime": 0.000526869,
    "total_runtime": 0.0001537799835205078
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 203.53983634285711,
    "kernel_usage": 6.360619885714285,
    "cpu_runtime": 5.4350999999999995e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 174.81191796363638,
    "kernel_usage": 5.462872436363637,
    "cpu_runtime": 3.6677e-05,
    "total_runtime": 2.09808349609375e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 262.6178756923077,
    "kernel_usage": 8.206808615384615,
    "cpu_runtime": 0.000130235,
    "total_runtime": 4.9591064453125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 205.69036282828282,
    "kernel_usage": 6.427823838383838,
    "cpu_runtime": 9.709999999999999e-05,
    "total_runtime": 4.7206878662109375e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76916789011702,
    "kernel_usage": 6.242786496566157,
    "cpu_runtime": 0.020028813000000003,
    "total_runtime": 0.010025978088378906
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.425036354439,
    "kernel_usage": 11.419532386076218,
    "cpu_runtime": 1.034918646,
    "total_runtime": 0.28320956230163574
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.15894933754942,
    "kernel_usage": 5.598717166798419,
    "cpu_runtime": 0.000216137,
    "total_runtime": 0.00012063980102539062
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 176.63653979701493,
    "kernel_usage": 5.519891868656717,
    "cpu_runtime": 2.8216000000000002e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 161.50904389189188,
    "kernel_usage": 5.047157621621621,
    "cpu_runtime": 2.8495e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_36.py",
    "status": "success",
    "cpu_usage": 204.7714567642915,
    "kernel_usage": 6.399108023884109,
    "cpu_runtime": 0.486281338,
    "total_runtime": 0.23747515678405762
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 204.53175799786098,
    "kernel_usage": 6.391617437433156,
    "cpu_runtime": 0.00027356700000000006,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 383.1734831121166,
    "kernel_usage": 11.974171347253645,
    "cpu_runtime": 0.236941912,
    "total_runtime": 0.06183671951293945
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 297.990834025249,
    "kernel_usage": 9.312213563289031,
    "cpu_runtime": 0.06991833200000001,
    "total_runtime": 0.02346324920654297
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 206.69592417663742,
    "kernel_usage": 6.459247630519919,
    "cpu_runtime": 0.000729839,
    "total_runtime": 0.00035309791564941406
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.8093561054264,
    "kernel_usage": 5.275292378294575,
    "cpu_runtime": 5.191900000000001e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 203.76415128115943,
    "kernel_usage": 6.367629727536232,
    "cpu_runtime": 6.7042e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 198.19602935537193,
    "kernel_usage": 6.193625917355373,
    "cpu_runtime": 0.0004574150000000001,
    "total_runtime": 0.0002307891845703125
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.9760113138577,
    "kernel_usage": 5.343000353558053,
    "cpu_runtime": 0.00021767900000000003,
    "total_runtime": 0.00012731552124023438
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 133.93810773333337,
    "kernel_usage": 4.185565866666668,
    "cpu_runtime": 1.5328000000000003e-05,
    "total_runtime": 1.1444091796875e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.039086185567,
    "kernel_usage": 6.751221443298968,
    "cpu_runtime": 0.0003997,
    "total_runtime": 0.0001850128173828125
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.69339477844312,
    "kernel_usage": 6.4904185868263475,
    "cpu_runtime": 0.00016539000000000001,
    "total_runtime": 7.963180541992188e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 201.6769636416465,
    "kernel_usage": 6.302405113801453,
    "cpu_runtime": 0.000198585,
    "total_runtime": 9.846687316894531e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.3583686077622,
    "kernel_usage": 6.198699018992569,
    "cpu_runtime": 0.0017181300000000002,
    "total_runtime": 0.0008661746978759766
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.96153846366315,
    "kernel_usage": 11.248798076989473,
    "cpu_runtime": 0.243200161,
    "total_runtime": 0.06756281852722168
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 278.703112192,
    "kernel_usage": 8.709472256,
    "cpu_runtime": 0.000614644,
    "total_runtime": 0.0002205371856689453
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 158.27460344242425,
    "kernel_usage": 4.946081357575758,
    "cpu_runtime": 4.9811e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 296.6446958190942,
    "kernel_usage": 9.270146744346693,
    "cpu_runtime": 0.017364551,
    "total_runtime": 0.0058536529541015625
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 178.438144,
    "kernel_usage": 5.576192,
    "cpu_runtime": 0.00010891,
    "total_runtime": 6.103515625e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.57802280626413,
    "kernel_usage": 6.236813212695754,
    "cpu_runtime": 0.005681899,
    "total_runtime": 0.002846956253051758
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 185.68772855769882,
    "kernel_usage": 5.802741517428088,
    "cpu_runtime": 0.000261644,
    "total_runtime": 0.00014090538024902344
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 209.50665639329614,
    "kernel_usage": 6.547083012290504,
    "cpu_runtime": 0.00017882200000000003,
    "total_runtime": 8.535385131835938e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.2364364998066,
    "kernel_usage": 6.194888640618956,
    "cpu_runtime": 0.000244351,
    "total_runtime": 0.0001232624053955078
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 202.27924145840186,
    "kernel_usage": 6.321226295575058,
    "cpu_runtime": 0.020882347000000002,
    "total_runtime": 0.010323524475097656
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 211.0799456162437,
    "kernel_usage": 6.596248300507615,
    "cpu_runtime": 9.9141e-05,
    "total_runtime": 4.696846008300781e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.66515402105267,
    "kernel_usage": 5.833286063157896,
    "cpu_runtime": 0.00027058700000000003,
    "total_runtime": 0.00014495849609375
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 204.0640052466431,
    "kernel_usage": 6.377000163957597,
    "cpu_runtime": 0.000137687,
    "total_runtime": 6.747245788574219e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.87844304786836,
    "kernel_usage": 6.246201345245886,
    "cpu_runtime": 0.028984086000000003,
    "total_runtime": 0.014500856399536133
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 278.5196881170732,
    "kernel_usage": 8.703740253658538,
    "cpu_runtime": 0.00043561200000000004,
    "total_runtime": 0.000156402587890625
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 192.6238357246964,
    "kernel_usage": 6.019494866396762,
    "cpu_runtime": 0.00011343500000000001,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 361.3693870552162,
    "kernel_usage": 11.292793345475506,
    "cpu_runtime": 0.001494827,
    "total_runtime": 0.00041365623474121094
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.27133172820962,
    "kernel_usage": 6.9147291165065505,
    "cpu_runtime": 0.000604047,
    "total_runtime": 0.00027298927307128906
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 221.477083493357,
    "kernel_usage": 6.921158859167406,
    "cpu_runtime": 0.0005961600000000001,
    "total_runtime": 0.00026917457580566406
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.86779139971793,
    "kernel_usage": 6.402118481241185,
    "cpu_runtime": 0.0017315300000000002,
    "total_runtime": 0.0008451938629150391
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 232.99973172178343,
    "kernel_usage": 7.281241616305732,
    "cpu_runtime": 0.001308237,
    "total_runtime": 0.0005614757537841797
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 199.74072455092355,
    "kernel_usage": 6.241897642216361,
    "cpu_runtime": 0.00018048700000000004,
    "total_runtime": 9.036064147949219e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.6517722722807,
    "kernel_usage": 6.114117883508772,
    "cpu_runtime": 0.000132944,
    "total_runtime": 6.794929504394531e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 195.05236106776184,
    "kernel_usage": 6.095386283367557,
    "cpu_runtime": 0.00022647500000000002,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 192.73383646017697,
    "kernel_usage": 6.02293238938053,
    "cpu_runtime": 0.000259625,
    "total_runtime": 0.0001347064971923828
  },
  {
    "task_id": "HumanEval_75.py",
    "status": "success",
    "cpu_usage": 283.6660908013738,
    "kernel_usage": 8.864565337542931,
    "cpu_runtime": 10.713726570999999,
    "total_runtime": 3.7768795490264893
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 164.407007762963,
    "kernel_usage": 5.1377189925925935,
    "cpu_runtime": 8.466700000000002e-05,
    "total_runtime": 5.14984130859375e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.42460173087935,
    "kernel_usage": 6.3570188040899795,
    "cpu_runtime": 0.000237166,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.1544185740304,
    "kernel_usage": 6.03607558043845,
    "cpu_runtime": 0.000273086,
    "total_runtime": 0.00014138221740722656
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 183.18547282877697,
    "kernel_usage": 5.72454602589928,
    "cpu_runtime": 6.0708e-05,
    "total_runtime": 3.314018249511719e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.06591181551363,
    "kernel_usage": 6.095809744234801,
    "cpu_runtime": 0.00022184,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 191.84392274548946,
    "kernel_usage": 5.995122585796546,
    "cpu_runtime": 0.00023830100000000003,
    "total_runtime": 0.00012421607971191406
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 186.57730162330097,
    "kernel_usage": 5.830540675728155,
    "cpu_runtime": 0.00022909,
    "total_runtime": 0.0001227855682373047
  },
  {
    "task_id": "HumanEval_83.py",
    "status": "success",
    "cpu_usage": 164.53510441290325,
    "kernel_usage": 5.141722012903227,
    "cpu_runtime": 4.864300000000001e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 282.2458959685152,
    "kernel_usage": 8.8201842490161,
    "cpu_runtime": 0.000376166,
    "total_runtime": 0.00013327598571777344
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.3076053333333,
    "kernel_usage": 6.728362666666666,
    "cpu_runtime": 0.00016939999999999997,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 288.96228671695724,
    "kernel_usage": 9.030071459904914,
    "cpu_runtime": 0.000869442,
    "total_runtime": 0.0003008842468261719
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 276.33586520108406,
    "kernel_usage": 8.635495787533877,
    "cpu_runtime": 0.0014586630000000002,
    "total_runtime": 0.0005278587341308594
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 196.97255971068498,
    "kernel_usage": 6.1553924909589055,
    "cpu_runtime": 0.00017141100000000003,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.35243152695656,
    "kernel_usage": 7.042263485217393,
    "cpu_runtime": 0.0009885990000000002,
    "total_runtime": 0.000438690185546875
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.24991008836105,
    "kernel_usage": 6.414059690261283,
    "cpu_runtime": 0.000206018,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_91.py",
    "status": "success",
    "cpu_usage": 308.3012978725024,
    "kernel_usage": 9.6344155585157,
    "cpu_runtime": 0.0007725350000000001,
    "total_runtime": 0.0002505779266357422
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.5306921179625,
    "kernel_usage": 6.141584128686328,
    "cpu_runtime": 0.00017477500000000003,
    "total_runtime": 8.893013000488281e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.53114976796024,
    "kernel_usage": 8.891598430248758,
    "cpu_runtime": 0.0013635340000000002,
    "total_runtime": 0.0004792213439941406
  },
  {
    "task_id": "HumanEval_94.py",
    "status": "success",
    "cpu_usage": 261.40695469374435,
    "kernel_usage": 8.168967334179511,
    "cpu_runtime": 0.0027497470000000003,
    "total_runtime": 0.0010519027709960938
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.77213856989687,
    "kernel_usage": 6.617879330309277,
    "cpu_runtime": 0.000489757,
    "total_runtime": 0.00023126602172851562
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.2707901251771,
    "kernel_usage": 6.289712191411784,
    "cpu_runtime": 0.0031848770000000005,
    "total_runtime": 0.0015823841094970703
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 191.9169801179283,
    "kernel_usage": 5.997405628685259,
    "cpu_runtime": 0.000114849,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.38823680000004,
    "kernel_usage": 5.793382400000001,
    "cpu_runtime": 0.00011978200000000003,
    "total_runtime": 6.461143493652344e-05
  },
  {
    "task_id": "HumanEval_99.py",
    "status": "success",
    "cpu_usage": 206.4077308653595,
    "kernel_usage": 6.450241589542484,
    "cpu_runtime": 0.00030117400000000003,
    "total_runtime": 0.00014591217041015625
  },
  {
    "task_id": "HumanEval_100.py",
    "status": "success",
    "cpu_usage": 214.90025155614617,
    "kernel_usage": 6.715632861129568,
    "cpu_runtime": 0.000154221,
    "total_runtime": 7.176399230957031e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 220.9944573038751,
    "kernel_usage": 6.906076790746097,
    "cpu_runtime": 0.000910996,
    "total_runtime": 0.00041222572326660156
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.77058769836066,
    "kernel_usage": 4.6490808655737705,
    "cpu_runtime": 4.3273000000000004e-05,
    "total_runtime": 2.9087066650390625e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.11715987623907,
    "kernel_usage": 6.253661246132471,
    "cpu_runtime": 0.0020601890000000005,
    "total_runtime": 0.0010294914245605469
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 275.67237453838993,
    "kernel_usage": 8.614761704324685,
    "cpu_runtime": 0.0009878530000000001,
    "total_runtime": 0.00035834312438964844
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 203.4133326070922,
    "kernel_usage": 6.356666643971631,
    "cpu_runtime": 0.000273526,
    "total_runtime": 0.00013446807861328125
  },
  {
    "task_id": "HumanEval_106.py",
    "status": "success",
    "cpu_usage": 186.43076779423507,
    "kernel_usage": 5.825961493569846,
    "cpu_runtime": 0.00020046300000000004,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 255.56863735150137,
    "kernel_usage": 7.986519917234418,
    "cpu_runtime": 0.004829495,
    "total_runtime": 0.0018897056579589844
  },
  {
    "task_id": "HumanEval_108.py",
    "status": "success",
    "cpu_usage": 349.1016067483758,
    "kernel_usage": 10.909425210886743,
    "cpu_runtime": 0.002844048,
    "total_runtime": 0.0008146762847900391
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.1718063951662,
    "kernel_usage": 6.692868949848943,
    "cpu_runtime": 0.000338034,
    "total_runtime": 0.00015783309936523438
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 173.46524382608695,
    "kernel_usage": 5.420788869565217,
    "cpu_runtime": 0.000152195,
    "total_runtime": 8.7738037109375e-05
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.39536752116788,
    "kernel_usage": 6.887355235036496,
    "cpu_runtime": 0.000719885,
    "total_runtime": 0.0003266334533691406
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.51699355973514,
    "kernel_usage": 6.953656048741723,
    "cpu_runtime": 0.0004005440000000001,
    "total_runtime": 0.0001800060272216797
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.7636025046041,
    "kernel_usage": 8.586362578268877,
    "cpu_runtime": 0.0007114250000000001,
    "total_runtime": 0.0002589225769042969
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 239.3073650544021,
    "kernel_usage": 7.478355157950066,
    "cpu_runtime": 0.000868382,
    "total_runtime": 0.0003628730773925781
  },
  {
    "task_id": "HumanEval_115.py",
    "status": "success",
    "cpu_usage": 265.19797760000006,
    "kernel_usage": 8.287436800000002,
    "cpu_runtime": 0.0004653590000000001,
    "total_runtime": 0.00017547607421875
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 368.349896196777,
    "kernel_usage": 11.510934256149282,
    "cpu_runtime": 0.0020708300000000005,
    "total_runtime": 0.0005621910095214844
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 215.77908524874792,
    "kernel_usage": 6.7430964140233725,
    "cpu_runtime": 0.0012326400000000001,
    "total_runtime": 0.0005712509155273438
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 190.42865239148935,
    "kernel_usage": 5.950895387234042,
    "cpu_runtime": 0.000341421,
    "total_runtime": 0.000179290771484375
  },
  {
    "task_id": "HumanEval_119.py",
    "status": "success",
    "cpu_usage": 244.52163698251454,
    "kernel_usage": 7.641301155703579,
    "cpu_runtime": 0.000700165,
    "total_runtime": 0.00028634071350097656
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 181.24751641938326,
    "kernel_usage": 5.663984888105727,
    "cpu_runtime": 0.000196186,
    "total_runtime": 0.00010824203491210938
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.6090221001855,
    "kernel_usage": 7.144031940630797,
    "cpu_runtime": 0.00029378,
    "total_runtime": 0.0001285076141357422
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 318.1850242540458,
    "kernel_usage": 9.943282007938931,
    "cpu_runtime": 0.0004968910000000001,
    "total_runtime": 0.00015616416931152344
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.35247391707952,
    "kernel_usage": 6.323514809908735,
    "cpu_runtime": 0.000370036,
    "total_runtime": 0.00018286705017089844
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 202.206245282793,
    "kernel_usage": 6.318945165087281,
    "cpu_runtime": 0.000579963,
    "total_runtime": 0.0002868175506591797
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 261.4431421518214,
    "kernel_usage": 8.170098192244419,
    "cpu_runtime": 0.0005304530000000001,
    "total_runtime": 0.0002028942108154297
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 262.79777209266734,
    "kernel_usage": 8.212430377895855,
    "cpu_runtime": 0.0023583669999999997,
    "total_runtime": 0.0008974075317382812
  },
  {
    "task_id": "HumanEval_127.py",
    "status": "success",
    "cpu_usage": 217.302695936,
    "kernel_usage": 6.790709248,
    "cpu_runtime": 0.000310854,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 243.4237888472166,
    "kernel_usage": 7.606993401475519,
    "cpu_runtime": 0.000865328,
    "total_runtime": 0.0003554821014404297
  },
  {
    "task_id": "HumanEval_129.py",
    "status": "success",
    "cpu_usage": 206.70531916984172,
    "kernel_usage": 6.459541224057554,
    "cpu_runtime": 0.001712563,
    "total_runtime": 0.0008285045623779297
  },
  {
    "task_id": "HumanEval_130.py",
    "status": "success",
    "cpu_usage": 199.18854315827664,
    "kernel_usage": 6.224641973696145,
    "cpu_runtime": 0.000628296,
    "total_runtime": 0.0003154277801513672
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 186.1796837286957,
    "kernel_usage": 5.81811511652174,
    "cpu_runtime": 0.00020418800000000003,
    "total_runtime": 0.00010967254638671875
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.53601284169378,
    "kernel_usage": 6.6730004013029305,
    "cpu_runtime": 0.001250373,
    "total_runtime": 0.0005855560302734375
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 202.21241356564414,
    "kernel_usage": 6.319137923926379,
    "cpu_runtime": 0.000628674,
    "total_runtime": 0.0003108978271484375
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 208.81276699651568,
    "kernel_usage": 6.525398968641115,
    "cpu_runtime": 0.000285765,
    "total_runtime": 0.00013685226440429688
  },
  {
    "task_id": "HumanEval_135.py",
    "status": "success",
    "cpu_usage": 204.62197819122406,
    "kernel_usage": 6.394436818475752,
    "cpu_runtime": 0.00021124200000000002,
    "total_runtime": 0.00010323524475097656
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.4769964737864,
    "kernel_usage": 6.983656139805825,
    "cpu_runtime": 0.001207349,
    "total_runtime": 0.0005402565002441406
  },
  {
    "task_id": "HumanEval_137.py",
    "status": "success",
    "cpu_usage": 202.7605804263815,
    "kernel_usage": 6.336268138324422,
    "cpu_runtime": 0.00027119800000000006,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.62103587008548,
    "kernel_usage": 4.519407370940171,
    "cpu_runtime": 4.0342e-05,
    "total_runtime": 2.7894973754882812e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 174.4830464,
    "kernel_usage": 5.4525952,
    "cpu_runtime": 6.5312e-05,
    "total_runtime": 3.743171691894531e-05
  },
  {
    "task_id": "HumanEval_140.py",
    "status": "success",
    "cpu_usage": 209.77444538555378,
    "kernel_usage": 6.5554514182985555,
    "cpu_runtime": 0.000934764,
    "total_runtime": 0.0004456043243408203
  },
  {
    "task_id": "HumanEval_141.py",
    "status": "success",
    "cpu_usage": 243.19014098628725,
    "kernel_usage": 7.5996919058214765,
    "cpu_runtime": 0.0017927740000000002,
    "total_runtime": 0.0007371902465820312
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.3918830833819,
    "kernel_usage": 6.574746346355685,
    "cpu_runtime": 0.001376427,
    "total_runtime": 0.0006542205810546875
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 219.67044179013092,
    "kernel_usage": 6.864701305941591,
    "cpu_runtime": 0.001040138,
    "total_runtime": 0.0004734992980957031
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 200.84044328225025,
    "kernel_usage": 6.27626385257032,
    "cpu_runtime": 0.000493685,
    "total_runtime": 0.00024580955505371094
  },
  {
    "task_id": "HumanEval_145.py",
    "status": "success",
    "cpu_usage": 399.85613702289317,
    "kernel_usage": 12.495504281965411,
    "cpu_runtime": 0.0034729859999999995,
    "total_runtime": 0.0008685588836669922
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.14123444165173,
    "kernel_usage": 5.723163576301617,
    "cpu_runtime": 0.00024321000000000005,
    "total_runtime": 0.0001327991485595703
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.86495147276153,
    "kernel_usage": 6.183279733523798,
    "cpu_runtime": 0.7106865630000001,
    "total_runtime": 0.3591775894165039
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.9804577272171,
    "kernel_usage": 6.124389303975534,
    "cpu_runtime": 0.00015279199999999998,
    "total_runtime": 7.796287536621094e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.9340334682353,
    "kernel_usage": 6.841688545882353,
    "cpu_runtime": 0.000532419,
    "total_runtime": 0.00024318695068359375
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.68833989573858,
    "kernel_usage": 6.240260621741831,
    "cpu_runtime": 0.013037837000000002,
    "total_runtime": 0.006529092788696289
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 245.6275465636136,
    "kernel_usage": 7.675860830112925,
    "cpu_runtime": 0.0018669620000000004,
    "total_runtime": 0.0007600784301757812
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 256.47720637719715,
    "kernel_usage": 8.014912699287411,
    "cpu_runtime": 0.000257437,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.1794153068044,
    "kernel_usage": 9.349356728337638,
    "cpu_runtime": 0.008281404999999999,
    "total_runtime": 0.0027680397033691406
  },
  {
    "task_id": "HumanEval_154.py",
    "status": "success",
    "cpu_usage": 197.01274020483092,
    "kernel_usage": 6.156648131400966,
    "cpu_runtime": 0.000388924,
    "total_runtime": 0.00019741058349609375
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.95275536810507,
    "kernel_usage": 5.9985236052532835,
    "cpu_runtime": 0.00024392800000000003,
    "total_runtime": 0.0001270771026611328
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 192.34661150574567,
    "kernel_usage": 6.010831609554552,
    "cpu_runtime": 0.0007103560000000001,
    "total_runtime": 0.0003693103790283203
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.59119318109092,
    "kernel_usage": 5.268474786909091,
    "cpu_runtime": 0.00011053700000000002,
    "total_runtime": 6.556510925292969e-05
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 324.72752077879005,
    "kernel_usage": 10.147735024337189,
    "cpu_runtime": 0.0011388640000000003,
    "total_runtime": 0.00035071372985839844
  },
  {
    "task_id": "HumanEval_159.py",
    "status": "success",
    "cpu_usage": 141.00454576551724,
    "kernel_usage": 4.406392055172414,
    "cpu_runtime": 3.8997e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 272.8586798886447,
    "kernel_usage": 8.526833746520147,
    "cpu_runtime": 0.000887995,
    "total_runtime": 0.0003254413604736328
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 211.9642387561462,
    "kernel_usage": 6.623882461129568,
    "cpu_runtime": 0.0006084560000000001,
    "total_runtime": 0.00028705596923828125
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 226.69089645714288,
    "kernel_usage": 7.084090514285715,
    "cpu_runtime": 0.000181599,
    "total_runtime": 8.0108642578125e-05
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 232.3343167646409,
    "kernel_usage": 7.260447398895028,
    "cpu_runtime": 0.00030078300000000005,
    "total_runtime": 0.00012946128845214844
  }
]