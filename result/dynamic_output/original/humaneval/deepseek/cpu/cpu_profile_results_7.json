[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.02073001679855,
    "kernel_usage": 6.875647813024955,
    "cpu_runtime": 0.000861869,
    "total_runtime": 0.0003917217254638672
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 132.5400064,
    "kernel_usage": 4.1418752,
    "cpu_runtime": 2.1804000000000003e-05,
    "total_runtime": 1.6450881958007812e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 167.19122479080463,
    "kernel_usage": 5.2247257747126445,
    "cpu_runtime": 6.935900000000001e-05,
    "total_runtime": 4.1484832763671875e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.27024260502515,
    "kernel_usage": 6.133445081407036,
    "cpu_runtime": 9.3121e-05,
    "total_runtime": 4.744529724121094e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 206.49596357938145,
    "kernel_usage": 6.45299886185567,
    "cpu_runtime": 9.5511e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.92390754957984,
    "kernel_usage": 4.81012211092437,
    "cpu_runtime": 4.3671e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.35701192180454,
    "kernel_usage": 6.729906622556392,
    "cpu_runtime": 0.00020486700000000002,
    "total_runtime": 9.512901306152344e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.3669315790941,
    "kernel_usage": 6.698966611846691,
    "cpu_runtime": 0.00014668300000000002,
    "total_runtime": 6.842613220214844e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 320.32918395798686,
    "kernel_usage": 10.01028699868709,
    "cpu_runtime": 0.000349022,
    "total_runtime": 0.00010895729064941406
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 299.4454280507553,
    "kernel_usage": 9.357669626586103,
    "cpu_runtime": 0.00023631200000000002,
    "total_runtime": 7.891654968261719e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 159.0294873766234,
    "kernel_usage": 4.969671480519481,
    "cpu_runtime": 2.9195e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 212.3160515214612,
    "kernel_usage": 6.634876610045662,
    "cpu_runtime": 0.000110858,
    "total_runtime": 5.221366882324219e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 238.37728679277976,
    "kernel_usage": 7.449290212274367,
    "cpu_runtime": 0.000157429,
    "total_runtime": 6.604194641113281e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.92124983652175,
    "kernel_usage": 6.216289057391305,
    "cpu_runtime": 0.00010908100000000001,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 225.73969738484107,
    "kernel_usage": 7.054365543276283,
    "cpu_runtime": 0.000220126,
    "total_runtime": 9.751319885253906e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 218.66966875634026,
    "kernel_usage": 6.833427148635633,
    "cpu_runtime": 0.000649601,
    "total_runtime": 0.0002970695495605469
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.60871669861388,
    "kernel_usage": 7.019022396831684,
    "cpu_runtime": 0.00027043200000000003,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.08814994285717,
    "kernel_usage": 8.096504685714287,
    "cpu_runtime": 0.00015134000000000002,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 169.91591537777774,
    "kernel_usage": 5.309872355555554,
    "cpu_runtime": 2.5521999999999997e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.01088892323762,
    "kernel_usage": 5.9065902788511755,
    "cpu_runtime": 0.000172594,
    "total_runtime": 9.131431579589844e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.5393822117647,
    "kernel_usage": 6.1731056941176465,
    "cpu_runtime": 0.000368299,
    "total_runtime": 0.00018644332885742188
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 271.81982543448277,
    "kernel_usage": 8.494369544827586,
    "cpu_runtime": 0.00018794,
    "total_runtime": 6.914138793945312e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 206.3854362122449,
    "kernel_usage": 6.4495448816326535,
    "cpu_runtime": 4.8222e-05,
    "total_runtime": 2.3365020751953125e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 154.1320535671233,
    "kernel_usage": 4.816626673972603,
    "cpu_runtime": 2.6826e-05,
    "total_runtime": 1.7404556274414062e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 261.8195786961326,
    "kernel_usage": 8.181861834254144,
    "cpu_runtime": 0.00011298500000000002,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 208.43593728,
    "kernel_usage": 6.51362304,
    "cpu_runtime": 8.9451e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76321083821836,
    "kernel_usage": 6.242600338694324,
    "cpu_runtime": 0.01901185,
    "total_runtime": 0.009517192840576172
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.9176461228353,
    "kernel_usage": 11.434926441338604,
    "cpu_runtime": 1.0242430210000002,
    "total_runtime": 0.2799108028411865
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.56257033742074,
    "kernel_usage": 5.642580323044398,
    "cpu_runtime": 0.00020362400000000001,
    "total_runtime": 0.00011277198791503906
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 178.36105862295085,
    "kernel_usage": 5.573783081967214,
    "cpu_runtime": 2.5940000000000002e-05,
    "total_runtime": 1.4543533325195312e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.2023710117647,
    "kernel_usage": 5.068824094117647,
    "cpu_runtime": 2.6297000000000003e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.69514855492594,
    "kernel_usage": 11.427973392341435,
    "cpu_runtime": 0.18843531200000002,
    "total_runtime": 0.051527976989746094
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 202.6285039616,
    "kernel_usage": 6.3321407488,
    "cpu_runtime": 6.0388e-05,
    "total_runtime": 2.9802322387695312e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.4387694276923,
    "kernel_usage": 5.326211544615385,
    "cpu_runtime": 0.000211306,
    "total_runtime": 0.0001239776611328125
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 135.64926219130436,
    "kernel_usage": 4.239039443478261,
    "cpu_runtime": 1.4877000000000002e-05,
    "total_runtime": 1.0967254638671875e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 203.66081335652177,
    "kernel_usage": 6.364400417391305,
    "cpu_runtime": 0.00014518400000000002,
    "total_runtime": 7.128715515136719e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.29145645948716,
    "kernel_usage": 6.165358014358974,
    "cpu_runtime": 0.00018344799999999998,
    "total_runtime": 9.298324584960938e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.1724935506017,
    "kernel_usage": 11.255390423456303,
    "cpu_runtime": 0.235470819,
    "total_runtime": 0.06537723541259766
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 208.37438773017755,
    "kernel_usage": 6.511699616568048,
    "cpu_runtime": 0.00033583900000000005,
    "total_runtime": 0.00016117095947265625
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.4700064477612,
    "kernel_usage": 8.452187701492537,
    "cpu_runtime": 0.000302435,
    "total_runtime": 0.00011181831359863281
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.85837971806035,
    "kernel_usage": 9.308074366189386,
    "cpu_runtime": 0.016416531,
    "total_runtime": 0.00551152229309082
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62262566736095,
    "kernel_usage": 6.23820705210503,
    "cpu_runtime": 0.005347157000000001,
    "total_runtime": 0.0026786327362060547
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 209.6609966867692,
    "kernel_usage": 6.551906146461538,
    "cpu_runtime": 0.00016245799999999998,
    "total_runtime": 7.748603820800781e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.18441401973095,
    "kernel_usage": 5.943262938116592,
    "cpu_runtime": 0.00010111600000000001,
    "total_runtime": 5.316734313964844e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.25291507729182,
    "kernel_usage": 6.164153596165369,
    "cpu_runtime": 0.0007849100000000001,
    "total_runtime": 0.0003979206085205078
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.09567099259257,
    "kernel_usage": 6.440489718518518,
    "cpu_runtime": 0.00013267,
    "total_runtime": 6.437301635742188e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89942707075363,
    "kernel_usage": 6.246857095961051,
    "cpu_runtime": 0.027800878,
    "total_runtime": 0.013907432556152344
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 279.0400546133334,
    "kernel_usage": 8.720001706666668,
    "cpu_runtime": 0.00039917,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 193.4008037517242,
    "kernel_usage": 6.043775117241381,
    "cpu_runtime": 0.00010697600000000003,
    "total_runtime": 5.53131103515625e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 219.00578171487535,
    "kernel_usage": 6.843930678589855,
    "cpu_runtime": 0.0006072610000000001,
    "total_runtime": 0.0002772808074951172
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 213.15151697736147,
    "kernel_usage": 6.660984905542546,
    "cpu_runtime": 0.000650995,
    "total_runtime": 0.00030541419982910156
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 201.17035718051582,
    "kernel_usage": 6.286573661891119,
    "cpu_runtime": 0.00016739000000000004,
    "total_runtime": 8.320808410644531e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.95419652063492,
    "kernel_usage": 6.154818641269841,
    "cpu_runtime": 0.00011833300000000001,
    "total_runtime": 6.008148193359375e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.2901789062802,
    "kernel_usage": 5.665318090821256,
    "cpu_runtime": 0.000178943,
    "total_runtime": 9.870529174804688e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.64184780800002,
    "kernel_usage": 6.363807744000001,
    "cpu_runtime": 0.00021848400000000002,
    "total_runtime": 0.00010728836059570312
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.99861259770117,
    "kernel_usage": 6.0624566436781615,
    "cpu_runtime": 0.00028168000000000003,
    "total_runtime": 0.00014519691467285156
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.8340781788618,
    "kernel_usage": 5.838564943089431,
    "cpu_runtime": 5.479e-05,
    "total_runtime": 2.9325485229492188e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.3631355547826,
    "kernel_usage": 6.073847986086956,
    "cpu_runtime": 0.000213163,
    "total_runtime": 0.00010967254638671875
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.71549177737003,
    "kernel_usage": 6.7411091180428135,
    "cpu_runtime": 0.000168178,
    "total_runtime": 7.796287536621094e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.4179847013699,
    "kernel_usage": 7.0443120219178095,
    "cpu_runtime": 0.000980825,
    "total_runtime": 0.00043511390686035156
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.79493839526626,
    "kernel_usage": 6.1810918248520705,
    "cpu_runtime": 0.00015939399999999999,
    "total_runtime": 8.058547973632812e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.3932962716357,
    "kernel_usage": 8.918540508488615,
    "cpu_runtime": 0.0013145920000000003,
    "total_runtime": 0.00046062469482421875
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 212.45045173213484,
    "kernel_usage": 6.639076616629214,
    "cpu_runtime": 0.000450804,
    "total_runtime": 0.00021219253540039062
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.0545989818182,
    "kernel_usage": 5.782956218181819,
    "cpu_runtime": 0.000116478,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.1457099034483,
    "kernel_usage": 4.62955343448276,
    "cpu_runtime": 4.097200000000001e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.1029489445136,
    "kernel_usage": 6.25321715451605,
    "cpu_runtime": 0.0019173950000000001,
    "total_runtime": 0.0009582042694091797
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.21831054014604,
    "kernel_usage": 6.725572204379564,
    "cpu_runtime": 0.00028119000000000006,
    "total_runtime": 0.00013065338134765625
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.6260225617694,
    "kernel_usage": 6.894563205055293,
    "cpu_runtime": 0.0006659330000000001,
    "total_runtime": 0.0003018379211425781
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.59155777109825,
    "kernel_usage": 6.98723618034682,
    "cpu_runtime": 0.000368894,
    "total_runtime": 0.00016498565673828125
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.19521778707883,
    "kernel_usage": 12.756100555846213,
    "cpu_runtime": 0.002455417,
    "total_runtime": 0.0006015300750732422
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.0284140340568,
    "kernel_usage": 5.750887938564275,
    "cpu_runtime": 0.000262816,
    "total_runtime": 0.00014281272888183594
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.75979707447704,
    "kernel_usage": 7.148743658577407,
    "cpu_runtime": 0.00026070400000000006,
    "total_runtime": 0.00011396408081054688
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.58550182890858,
    "kernel_usage": 6.330796932153393,
    "cpu_runtime": 0.00032747500000000003,
    "total_runtime": 0.00016164779663085938
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 202.6998063478099,
    "kernel_usage": 6.334368948369059,
    "cpu_runtime": 0.000518553,
    "total_runtime": 0.00025582313537597656
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 245.0262532237773,
    "kernel_usage": 7.657070413243041,
    "cpu_runtime": 0.000776386,
    "total_runtime": 0.00031685829162597656
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 184.90644504556357,
    "kernel_usage": 5.778326407673862,
    "cpu_runtime": 0.00018383500000000003,
    "total_runtime": 9.942054748535156e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.30036972307693,
    "kernel_usage": 4.540636553846154,
    "cpu_runtime": 3.6028e-05,
    "total_runtime": 2.47955322265625e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.25033533793106,
    "kernel_usage": 6.570322979310346,
    "cpu_runtime": 0.0012937930000000001,
    "total_runtime": 0.0006153583526611328
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.86284361879197,
    "kernel_usage": 6.308213863087249,
    "cpu_runtime": 0.00043026300000000006,
    "total_runtime": 0.00021314620971679688
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.98535378343948,
    "kernel_usage": 6.155792305732484,
    "cpu_runtime": 0.00014747,
    "total_runtime": 7.486343383789062e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.68519281943634,
    "kernel_usage": 6.802662275607386,
    "cpu_runtime": 0.0005340529999999999,
    "total_runtime": 0.0002453327178955078
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6872295746103,
    "kernel_usage": 6.240225924206572,
    "cpu_runtime": 0.012675935,
    "total_runtime": 0.0063478946685791016
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 192.19678682744282,
    "kernel_usage": 6.006149588357588,
    "cpu_runtime": 0.00022041,
    "total_runtime": 0.00011467933654785156
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.49469440000001,
    "kernel_usage": 5.2654592000000005,
    "cpu_runtime": 0.00010284100000000001,
    "total_runtime": 6.103515625e-05
  }
]