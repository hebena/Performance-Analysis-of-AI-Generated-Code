[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 219.9917607045511,
    "kernel_usage": 6.874742522017222,
    "cpu_runtime": 0.0008528390000000001,
    "total_runtime": 0.0003876686096191406
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.99601623188406,
    "kernel_usage": 4.093625507246377,
    "cpu_runtime": 2.155e-05,
    "total_runtime": 1.6450881958007812e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 167.78400831638422,
    "kernel_usage": 5.243250259887007,
    "cpu_runtime": 7.080500000000001e-05,
    "total_runtime": 4.220008850097656e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.58636271746033,
    "kernel_usage": 6.143323834920635,
    "cpu_runtime": 8.8584e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.06884619130437,
    "kernel_usage": 6.377151443478262,
    "cpu_runtime": 8.952300000000002e-05,
    "total_runtime": 4.38690185546875e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.11875549579835,
    "kernel_usage": 4.8474611092436986,
    "cpu_runtime": 4.401000000000001e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.25380497822786,
    "kernel_usage": 6.726681405569621,
    "cpu_runtime": 0.000202716,
    "total_runtime": 9.417533874511719e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 212.9675508794613,
    "kernel_usage": 6.655235964983166,
    "cpu_runtime": 0.000150803,
    "total_runtime": 7.081031799316406e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 320.9536129113044,
    "kernel_usage": 10.029800403478262,
    "cpu_runtime": 0.000351998,
    "total_runtime": 0.00010967254638671875
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 299.66241294797703,
    "kernel_usage": 9.364450404624282,
    "cpu_runtime": 0.0002472000000000001,
    "total_runtime": 8.249282836914062e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 164.40749854945057,
    "kernel_usage": 5.13773432967033,
    "cpu_runtime": 3.567e-05,
    "total_runtime": 2.1696090698242188e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 214.4674962285715,
    "kernel_usage": 6.702109257142859,
    "cpu_runtime": 0.00011453800000000002,
    "total_runtime": 5.340576171875e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 237.11594510948905,
    "kernel_usage": 7.409873284671533,
    "cpu_runtime": 0.0001549,
    "total_runtime": 6.532669067382812e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.19717612307693,
    "kernel_usage": 6.224911753846154,
    "cpu_runtime": 0.000111132,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 226.0157432377171,
    "kernel_usage": 7.062991976178659,
    "cpu_runtime": 0.000217162,
    "total_runtime": 9.608268737792969e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 219.69008297201717,
    "kernel_usage": 6.865315092875536,
    "cpu_runtime": 0.000610206,
    "total_runtime": 0.0002777576446533203
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.23082219842516,
    "kernel_usage": 7.038463193700786,
    "cpu_runtime": 0.00027279199999999995,
    "total_runtime": 0.00012111663818359375
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 258.8507537034221,
    "kernel_usage": 8.08908605323194,
    "cpu_runtime": 0.00016231,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 168.86401056507938,
    "kernel_usage": 5.277000330158731,
    "cpu_runtime": 2.5364000000000003e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.82747133433585,
    "kernel_usage": 5.932108479197995,
    "cpu_runtime": 0.00018058100000000002,
    "total_runtime": 9.512901306152344e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.2601441070632,
    "kernel_usage": 6.164379503345725,
    "cpu_runtime": 0.00037953600000000003,
    "total_runtime": 0.00019240379333496094
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 273.7839167558621,
    "kernel_usage": 8.55574739862069,
    "cpu_runtime": 0.00018929800000000002,
    "total_runtime": 6.914138793945312e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 210.50497851914898,
    "kernel_usage": 6.5782805787234055,
    "cpu_runtime": 4.7177000000000006e-05,
    "total_runtime": 2.2411346435546875e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 152.8823808,
    "kernel_usage": 4.7775744,
    "cpu_runtime": 2.6973e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.9163620407186,
    "kernel_usage": 8.309886313772456,
    "cpu_runtime": 0.00010587700000000002,
    "total_runtime": 3.981590270996094e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 203.9609092491228,
    "kernel_usage": 6.373778414035088,
    "cpu_runtime": 8.3154e-05,
    "total_runtime": 4.076957702636719e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76415349093477,
    "kernel_usage": 6.242629796591712,
    "cpu_runtime": 0.018892871000000002,
    "total_runtime": 0.009457588195800781
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.70324556433894,
    "kernel_usage": 11.428226423885592,
    "cpu_runtime": 1.0178891930000002,
    "total_runtime": 0.2783374786376953
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.06550707949793,
    "kernel_usage": 5.62704709623431,
    "cpu_runtime": 0.00020521000000000002,
    "total_runtime": 0.00011396408081054688
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.62106880000002,
    "kernel_usage": 5.6131584000000005,
    "cpu_runtime": 2.5695000000000004e-05,
    "total_runtime": 1.430511474609375e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 169.32505112380954,
    "kernel_usage": 5.291407847619048,
    "cpu_runtime": 3.3911e-05,
    "total_runtime": 2.002716064453125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.68506657859194,
    "kernel_usage": 11.427658330580998,
    "cpu_runtime": 0.18790874400000002,
    "total_runtime": 0.05138540267944336
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.32446720000002,
    "kernel_usage": 6.2288896000000005,
    "cpu_runtime": 6.0829e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.46439427005876,
    "kernel_usage": 5.327012320939336,
    "cpu_runtime": 0.00020768000000000004,
    "total_runtime": 0.00012183189392089844
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 132.93992840930233,
    "kernel_usage": 4.154372762790698,
    "cpu_runtime": 1.3629000000000001e-05,
    "total_runtime": 1.0251998901367188e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 204.94945726711413,
    "kernel_usage": 6.4046705395973165,
    "cpu_runtime": 0.00014561400000000002,
    "total_runtime": 7.104873657226562e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.27755946666667,
    "kernel_usage": 6.1649237333333335,
    "cpu_runtime": 0.00018061300000000001,
    "total_runtime": 9.1552734375e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.37086456017414,
    "kernel_usage": 11.261589517505442,
    "cpu_runtime": 0.23803975200000002,
    "total_runtime": 0.06605410575866699
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 207.6229608011713,
    "kernel_usage": 6.488217525036603,
    "cpu_runtime": 0.000338093,
    "total_runtime": 0.0001628398895263672
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 269.8489909194805,
    "kernel_usage": 8.432780966233766,
    "cpu_runtime": 0.000297237,
    "total_runtime": 0.00011014938354492188
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.3623045404669,
    "kernel_usage": 9.32382201688959,
    "cpu_runtime": 0.016274292000000003,
    "total_runtime": 0.005454540252685547
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.62152113688728,
    "kernel_usage": 6.2381725355277275,
    "cpu_runtime": 0.005320951,
    "total_runtime": 0.0026655197143554688
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 210.14631731517025,
    "kernel_usage": 6.56707241609907,
    "cpu_runtime": 0.000161832,
    "total_runtime": 7.700920104980469e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.32698436709958,
    "kernel_usage": 5.947718261471862,
    "cpu_runtime": 0.00010482200000000001,
    "total_runtime": 5.507469177246094e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.07825392767188,
    "kernel_usage": 6.158695435239746,
    "cpu_runtime": 0.0008133470000000001,
    "total_runtime": 0.0004127025604248047
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 207.4198556131868,
    "kernel_usage": 6.481870487912087,
    "cpu_runtime": 0.000135006,
    "total_runtime": 6.508827209472656e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.9007945117134,
    "kernel_usage": 6.246899828491044,
    "cpu_runtime": 0.028119914000000003,
    "total_runtime": 0.014066934585571289
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 280.82500347661016,
    "kernel_usage": 8.775781358644068,
    "cpu_runtime": 0.000395028,
    "total_runtime": 0.00014066696166992188
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 193.46182196738198,
    "kernel_usage": 6.045681936480687,
    "cpu_runtime": 0.000107471,
    "total_runtime": 5.555152893066406e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.3629169965974,
    "kernel_usage": 6.9175911561436685,
    "cpu_runtime": 0.000558381,
    "total_runtime": 0.0002522468566894531
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 211.83189891437598,
    "kernel_usage": 6.6197468410742495,
    "cpu_runtime": 0.000639389,
    "total_runtime": 0.0003018379211425781
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 200.5872570576271,
    "kernel_usage": 6.268351783050847,
    "cpu_runtime": 0.000169296,
    "total_runtime": 8.440017700195312e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 195.61713632248063,
    "kernel_usage": 6.11303551007752,
    "cpu_runtime": 0.000120328,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.75214531764706,
    "kernel_usage": 5.679754541176471,
    "cpu_runtime": 0.000176799,
    "total_runtime": 9.72747802734375e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.68258167927928,
    "kernel_usage": 6.3650806774774775,
    "cpu_runtime": 0.000215614,
    "total_runtime": 0.00010585784912109375
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.73864798598947,
    "kernel_usage": 6.054332749562171,
    "cpu_runtime": 0.00026375,
    "total_runtime": 0.0001361370086669922
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.1588975349594,
    "kernel_usage": 5.8174655479674815,
    "cpu_runtime": 5.4592000000000015e-05,
    "total_runtime": 2.9325485229492188e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.3905568138528,
    "kernel_usage": 6.0747049004329,
    "cpu_runtime": 0.00021412000000000002,
    "total_runtime": 0.00011014938354492188
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.98213545353846,
    "kernel_usage": 6.749441732923077,
    "cpu_runtime": 0.000167356,
    "total_runtime": 7.748603820800781e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.9549409223269,
    "kernel_usage": 7.061091903822716,
    "cpu_runtime": 0.0009723870000000001,
    "total_runtime": 0.0004303455352783203
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 198.26662812656718,
    "kernel_usage": 6.1958321289552245,
    "cpu_runtime": 0.000158356,
    "total_runtime": 7.987022399902344e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.1395944029212,
    "kernel_usage": 8.910612325091288,
    "cpu_runtime": 0.001303226,
    "total_runtime": 0.0004570484161376953
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.81839031140646,
    "kernel_usage": 6.619324697231452,
    "cpu_runtime": 0.00045602800000000003,
    "total_runtime": 0.00021529197692871094
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.4598062730159,
    "kernel_usage": 5.795618946031746,
    "cpu_runtime": 0.000111427,
    "total_runtime": 6.008148193359375e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.34718171428574,
    "kernel_usage": 4.667099428571429,
    "cpu_runtime": 3.9880000000000004e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.14601542452314,
    "kernel_usage": 6.254562982016348,
    "cpu_runtime": 0.001926397,
    "total_runtime": 0.0009624958038330078
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.4437960819788,
    "kernel_usage": 6.701368627561838,
    "cpu_runtime": 0.000289381,
    "total_runtime": 0.00013494491577148438
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.67761660653593,
    "kernel_usage": 6.896175518954248,
    "cpu_runtime": 0.000643991,
    "total_runtime": 0.0002918243408203125
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.10548403123124,
    "kernel_usage": 6.972046375975976,
    "cpu_runtime": 0.00035426200000000004,
    "total_runtime": 0.00015878677368164062
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.00379799301754,
    "kernel_usage": 12.750118687281798,
    "cpu_runtime": 0.002340453,
    "total_runtime": 0.0005736351013183594
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.26975573333334,
    "kernel_usage": 5.758429866666667,
    "cpu_runtime": 0.000266236,
    "total_runtime": 0.00014448165893554688
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.93073989769394,
    "kernel_usage": 7.154085621802936,
    "cpu_runtime": 0.000260353,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.07419074575262,
    "kernel_usage": 6.314818460804769,
    "cpu_runtime": 0.000323276,
    "total_runtime": 0.00015997886657714844
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 203.14175407005655,
    "kernel_usage": 6.348179814689267,
    "cpu_runtime": 0.0005143560000000001,
    "total_runtime": 0.0002532005310058594
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.19645844620058,
    "kernel_usage": 7.631139326443768,
    "cpu_runtime": 0.000766188,
    "total_runtime": 0.00031375885009765625
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 184.8529935283582,
    "kernel_usage": 5.776656047761194,
    "cpu_runtime": 0.000177171,
    "total_runtime": 9.584426879882812e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.26272853333336,
    "kernel_usage": 4.5394602666666675,
    "cpu_runtime": 3.3248000000000004e-05,
    "total_runtime": 2.288818359375e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 209.8448831576159,
    "kernel_usage": 6.557652598675497,
    "cpu_runtime": 0.001208747,
    "total_runtime": 0.000576019287109375
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.2361070150179,
    "kernel_usage": 6.288628344219309,
    "cpu_runtime": 0.00040253900000000004,
    "total_runtime": 0.00020003318786621094
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 197.0935050520548,
    "kernel_usage": 6.159172032876713,
    "cpu_runtime": 0.00013721300000000002,
    "total_runtime": 6.961822509765625e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.5293171014493,
    "kernel_usage": 6.82904115942029,
    "cpu_runtime": 0.0005033,
    "total_runtime": 0.00023031234741210938
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.67941540569342,
    "kernel_usage": 6.239981731427919,
    "cpu_runtime": 0.012492627000000001,
    "total_runtime": 0.0062563419342041016
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 192.353715726749,
    "kernel_usage": 6.011053616460906,
    "cpu_runtime": 0.00022288300000000003,
    "total_runtime": 0.00011587142944335938
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 169.04579621463418,
    "kernel_usage": 5.282681131707318,
    "cpu_runtime": 9.914700000000002e-05,
    "total_runtime": 5.8650970458984375e-05
  }
]