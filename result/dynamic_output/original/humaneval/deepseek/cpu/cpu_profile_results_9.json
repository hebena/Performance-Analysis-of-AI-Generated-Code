[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.64000579399536,
    "kernel_usage": 6.895000181062355,
    "cpu_runtime": 0.000911113,
    "total_runtime": 0.00041294097900390625
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.25014313513518,
    "kernel_usage": 4.070316972972974,
    "cpu_runtime": 2.2980000000000004e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 167.59758626594598,
    "kernel_usage": 5.237424570810812,
    "cpu_runtime": 7.392300000000002e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 199.03108867783254,
    "kernel_usage": 6.219721521182267,
    "cpu_runtime": 9.632900000000002e-05,
    "total_runtime": 4.839897155761719e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 201.70108342857142,
    "kernel_usage": 6.303158857142857,
    "cpu_runtime": 9.4255e-05,
    "total_runtime": 4.673004150390625e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 154.6217833411765,
    "kernel_usage": 4.8319307294117655,
    "cpu_runtime": 4.3869e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.26967173776723,
    "kernel_usage": 6.758427241805226,
    "cpu_runtime": 0.000217079,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.12130938471762,
    "kernel_usage": 6.691290918272426,
    "cpu_runtime": 0.00015366200000000002,
    "total_runtime": 7.176399230957031e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 318.6167582761711,
    "kernel_usage": 9.956773696130346,
    "cpu_runtime": 0.00037298400000000003,
    "total_runtime": 0.00011706352233886719
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.05177824815866,
    "kernel_usage": 9.282868070254958,
    "cpu_runtime": 0.000250004,
    "total_runtime": 8.416175842285156e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 159.63418723902439,
    "kernel_usage": 4.988568351219512,
    "cpu_runtime": 3.1209e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 209.90934682270742,
    "kernel_usage": 6.559667088209607,
    "cpu_runtime": 0.000114606,
    "total_runtime": 5.459785461425781e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 239.75012588843546,
    "kernel_usage": 7.492191434013608,
    "cpu_runtime": 0.00016805300000000004,
    "total_runtime": 7.009506225585938e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.91053424132232,
    "kernel_usage": 6.215954195041323,
    "cpu_runtime": 0.000114766,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 223.89750026288417,
    "kernel_usage": 6.99679688321513,
    "cpu_runtime": 0.000225803,
    "total_runtime": 0.00010085105895996094
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 219.51134651733338,
    "kernel_usage": 6.859729578666668,
    "cpu_runtime": 0.0006280270000000001,
    "total_runtime": 0.000286102294921875
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.98640978597197,
    "kernel_usage": 7.062075305811624,
    "cpu_runtime": 0.000268858,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.3654744766284,
    "kernel_usage": 8.105171077394637,
    "cpu_runtime": 0.000161396,
    "total_runtime": 6.222724914550781e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 173.19093016774195,
    "kernel_usage": 5.412216567741936,
    "cpu_runtime": 2.5601e-05,
    "total_runtime": 1.4781951904296875e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.95446517551025,
    "kernel_usage": 5.904827036734695,
    "cpu_runtime": 0.00017659700000000004,
    "total_runtime": 9.34600830078125e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.94477590906897,
    "kernel_usage": 6.185774247158405,
    "cpu_runtime": 0.0003902920000000001,
    "total_runtime": 0.0001971721649169922
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 271.46881100887373,
    "kernel_usage": 8.483400344027304,
    "cpu_runtime": 0.00018963900000000002,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 208.20694522828288,
    "kernel_usage": 6.50646703838384,
    "cpu_runtime": 4.914400000000001e-05,
    "total_runtime": 2.3603439331054688e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 154.42903040000002,
    "kernel_usage": 4.8259072000000005,
    "cpu_runtime": 2.9455000000000005e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 266.42558431445093,
    "kernel_usage": 8.325799509826592,
    "cpu_runtime": 0.00010989100000000002,
    "total_runtime": 4.124641418457031e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.32460900111735,
    "kernel_usage": 6.447644031284917,
    "cpu_runtime": 8.805300000000002e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.77138973617994,
    "kernel_usage": 6.242855929255623,
    "cpu_runtime": 0.019163613,
    "total_runtime": 0.009592771530151367
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 366.2409992721367,
    "kernel_usage": 11.445031227254272,
    "cpu_runtime": 1.020747261,
    "total_runtime": 0.27870917320251465
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.8626971826087,
    "kernel_usage": 5.620709286956522,
    "cpu_runtime": 0.000207123,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 182.63290171076923,
    "kernel_usage": 5.7072781784615385,
    "cpu_runtime": 2.8303e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.96777541818182,
    "kernel_usage": 5.092742981818182,
    "cpu_runtime": 2.5644e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.948693061559,
    "kernel_usage": 11.43589665817372,
    "cpu_runtime": 0.18525835000000002,
    "total_runtime": 0.05062413215637207
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 203.66153131338586,
    "kernel_usage": 6.364422853543308,
    "cpu_runtime": 6.166700000000002e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.94462459920322,
    "kernel_usage": 5.342019518725101,
    "cpu_runtime": 0.00020459700000000002,
    "total_runtime": 0.00011968612670898438
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 134.44278821463416,
    "kernel_usage": 4.201337131707318,
    "cpu_runtime": 1.3142e-05,
    "total_runtime": 9.775161743164062e-06
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 205.04174537748347,
    "kernel_usage": 6.407554543046358,
    "cpu_runtime": 0.000147635,
    "total_runtime": 7.200241088867188e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 196.39071775670104,
    "kernel_usage": 6.137209929896907,
    "cpu_runtime": 0.000181674,
    "total_runtime": 9.250640869140625e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.7713423561915,
    "kernel_usage": 11.274104448630984,
    "cpu_runtime": 0.23608166700000002,
    "total_runtime": 0.06543803215026855
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 207.9964674275556,
    "kernel_usage": 6.499889607111112,
    "cpu_runtime": 0.00033473400000000005,
    "total_runtime": 0.0001609325408935547
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 272.44949416851074,
    "kernel_usage": 8.51404669276596,
    "cpu_runtime": 0.00030529800000000007,
    "total_runtime": 0.00011205673217773438
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.205060755935,
    "kernel_usage": 9.318908148622969,
    "cpu_runtime": 0.016237987,
    "total_runtime": 0.005445241928100586
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.63996695692336,
    "kernel_usage": 6.238748967403855,
    "cpu_runtime": 0.005359045000000001,
    "total_runtime": 0.002684354782104492
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 212.283893449697,
    "kernel_usage": 6.633871670303031,
    "cpu_runtime": 0.000167021,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 188.72461498181818,
    "kernel_usage": 5.897644218181818,
    "cpu_runtime": 0.00010888900000000001,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.26873529188217,
    "kernel_usage": 6.164647977871318,
    "cpu_runtime": 0.000782151,
    "total_runtime": 0.00039649009704589844
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 207.6994758798535,
    "kernel_usage": 6.490608621245422,
    "cpu_runtime": 0.00013518800000000003,
    "total_runtime": 6.508827209472656e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.89862243627454,
    "kernel_usage": 6.246831951133579,
    "cpu_runtime": 0.027433311,
    "total_runtime": 0.013723611831665039
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 279.69051609326766,
    "kernel_usage": 8.740328627914614,
    "cpu_runtime": 0.00040610200000000004,
    "total_runtime": 0.00014519691467285156
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 192.3544286608696,
    "kernel_usage": 6.011075895652175,
    "cpu_runtime": 0.00010548000000000001,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.41610312363304,
    "kernel_usage": 6.919253222613532,
    "cpu_runtime": 0.0005696010000000001,
    "total_runtime": 0.00025725364685058594
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 212.85311041555914,
    "kernel_usage": 6.651659700486223,
    "cpu_runtime": 0.000626232,
    "total_runtime": 0.0002942085266113281
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 200.6701427590028,
    "kernel_usage": 6.2709419612188375,
    "cpu_runtime": 0.00017271500000000002,
    "total_runtime": 8.606910705566406e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.06133132648225,
    "kernel_usage": 6.12691660395257,
    "cpu_runtime": 0.00011826400000000002,
    "total_runtime": 6.031990051269531e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.89673447024393,
    "kernel_usage": 5.684272952195123,
    "cpu_runtime": 0.00017780700000000001,
    "total_runtime": 9.775161743164062e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.4944240674058,
    "kernel_usage": 6.359200752106431,
    "cpu_runtime": 0.00021881100000000002,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.8404170034843,
    "kernel_usage": 6.0575130313588845,
    "cpu_runtime": 0.000265275,
    "total_runtime": 0.00013685226440429688
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.87792981333337,
    "kernel_usage": 5.777435306666668,
    "cpu_runtime": 5.2894000000000006e-05,
    "total_runtime": 2.86102294921875e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 193.73043600835075,
    "kernel_usage": 6.054076125260961,
    "cpu_runtime": 0.00022124500000000001,
    "total_runtime": 0.00011420249938964844
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 217.59850015905045,
    "kernel_usage": 6.799953129970326,
    "cpu_runtime": 0.000174834,
    "total_runtime": 8.034706115722656e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.76125862212942,
    "kernel_usage": 7.055039331941544,
    "cpu_runtime": 0.0010313,
    "total_runtime": 0.00045680999755859375
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 198.01523665454545,
    "kernel_usage": 6.187976145454545,
    "cpu_runtime": 0.000166181,
    "total_runtime": 8.392333984375e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.5269292806419,
    "kernel_usage": 8.92271654002006,
    "cpu_runtime": 0.0013574140000000001,
    "total_runtime": 0.0004754066467285156
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 212.03666762531648,
    "kernel_usage": 6.62614586329114,
    "cpu_runtime": 0.00047924700000000003,
    "total_runtime": 0.00022602081298828125
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.5237941536122,
    "kernel_usage": 5.797618567300381,
    "cpu_runtime": 0.00011633100000000002,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.05097527652177,
    "kernel_usage": 4.657842977391305,
    "cpu_runtime": 4.086700000000001e-05,
    "total_runtime": 2.7418136596679688e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.20093843797855,
    "kernel_usage": 6.25627932618683,
    "cpu_runtime": 0.001870125,
    "total_runtime": 0.0009341239929199219
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.11583703554763,
    "kernel_usage": 6.722369907360863,
    "cpu_runtime": 0.00028567200000000005,
    "total_runtime": 0.0001327991485595703
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 222.62448335721078,
    "kernel_usage": 6.957015104912837,
    "cpu_runtime": 0.000669842,
    "total_runtime": 0.0003008842468261719
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.21431903568217,
    "kernel_usage": 6.975447469865068,
    "cpu_runtime": 0.00035496700000000003,
    "total_runtime": 0.0001590251922607422
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.3094925962671,
    "kernel_usage": 12.759671643633347,
    "cpu_runtime": 0.0023470739999999998,
    "total_runtime": 0.0005748271942138672
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.27138957462438,
    "kernel_usage": 5.758480924207012,
    "cpu_runtime": 0.000263163,
    "total_runtime": 0.00014281272888183594
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.93178108786617,
    "kernel_usage": 7.154118158995818,
    "cpu_runtime": 0.00026090000000000005,
    "total_runtime": 0.00011396408081054688
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.09880861107874,
    "kernel_usage": 6.315587769096211,
    "cpu_runtime": 0.00033054300000000004,
    "total_runtime": 0.00016355514526367188
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 203.17492935593222,
    "kernel_usage": 6.349216542372882,
    "cpu_runtime": 0.00051444,
    "total_runtime": 0.0002532005310058594
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.94893994795763,
    "kernel_usage": 7.654654373373676,
    "cpu_runtime": 0.000772053,
    "total_runtime": 0.0003151893615722656
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.19712942350122,
    "kernel_usage": 5.787410294484413,
    "cpu_runtime": 0.00018412400000000003,
    "total_runtime": 9.942054748535156e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 146.34126384761902,
    "kernel_usage": 4.573164495238094,
    "cpu_runtime": 3.6635e-05,
    "total_runtime": 2.5033950805664062e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.0202561651957,
    "kernel_usage": 6.563133005162365,
    "cpu_runtime": 0.001202747,
    "total_runtime": 0.0005726814270019531
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.32148265957917,
    "kernel_usage": 6.291296333111849,
    "cpu_runtime": 0.00043342900000000004,
    "total_runtime": 0.00021529197692871094
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.26441000251572,
    "kernel_usage": 6.133262812578616,
    "cpu_runtime": 0.000148802,
    "total_runtime": 7.581710815429688e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.56526466031752,
    "kernel_usage": 6.830164520634923,
    "cpu_runtime": 0.0005252690000000001,
    "total_runtime": 0.000240325927734375
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.70602244427732,
    "kernel_usage": 6.240813201383666,
    "cpu_runtime": 0.012663319999999999,
    "total_runtime": 0.006340980529785156
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.71155917535938,
    "kernel_usage": 5.990986224229981,
    "cpu_runtime": 0.00022259600000000004,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.61102079999998,
    "kernel_usage": 5.269094399999999,
    "cpu_runtime": 0.00010170599999999999,
    "total_runtime": 6.031990051269531e-05
  }
]