[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.1021133452229,
    "kernel_usage": 6.878191042038216,
    "cpu_runtime": 0.001071044,
    "total_runtime": 0.00048661231994628906
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 132.24781893033708,
    "kernel_usage": 4.132744341573034,
    "cpu_runtime": 2.8062e-05,
    "total_runtime": 2.1219253540039062e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.69579058738736,
    "kernel_usage": 5.177993455855855,
    "cpu_runtime": 8.770099999999999e-05,
    "total_runtime": 5.2928924560546875e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.98556709961977,
    "kernel_usage": 6.155798971863118,
    "cpu_runtime": 0.000123518,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.08187462764232,
    "kernel_usage": 6.3775585821138225,
    "cpu_runtime": 0.00011969600000000001,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.20359015696204,
    "kernel_usage": 4.787612192405064,
    "cpu_runtime": 5.7712000000000006e-05,
    "total_runtime": 3.7670135498046875e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 217.2209619895131,
    "kernel_usage": 6.788155062172285,
    "cpu_runtime": 0.000276556,
    "total_runtime": 0.00012731552124023438
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.5643693886792,
    "kernel_usage": 6.705136543396225,
    "cpu_runtime": 0.000216902,
    "total_runtime": 0.0001010894775390625
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 321.32500342447764,
    "kernel_usage": 10.041406357014926,
    "cpu_runtime": 0.0005132860000000001,
    "total_runtime": 0.00015974044799804688
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 298.1303515970371,
    "kernel_usage": 9.316573487407409,
    "cpu_runtime": 0.00038383100000000006,
    "total_runtime": 0.00012874603271484375
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 158.66265600000003,
    "kernel_usage": 4.958208000000001,
    "cpu_runtime": 4.842000000000001e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 212.6684328164223,
    "kernel_usage": 6.645888525513197,
    "cpu_runtime": 0.000172901,
    "total_runtime": 8.130073547363281e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 238.07330205583526,
    "kernel_usage": 7.439790689244852,
    "cpu_runtime": 0.00024804600000000003,
    "total_runtime": 0.00010418891906738281
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.3066573121339,
    "kernel_usage": 6.228333041004184,
    "cpu_runtime": 0.00011356900000000001,
    "total_runtime": 5.698204040527344e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 226.47321316240965,
    "kernel_usage": 7.0772879113253016,
    "cpu_runtime": 0.00022408100000000003,
    "total_runtime": 9.894371032714844e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 219.32814867858346,
    "kernel_usage": 6.854004646205733,
    "cpu_runtime": 0.0006201819999999999,
    "total_runtime": 0.0002827644348144531
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.39789091273488,
    "kernel_usage": 7.012434091022965,
    "cpu_runtime": 0.00025626800000000003,
    "total_runtime": 0.00011420249938964844
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.5347933866667,
    "kernel_usage": 8.110462293333335,
    "cpu_runtime": 0.000148507,
    "total_runtime": 5.7220458984375e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 168.67190585806452,
    "kernel_usage": 5.270997058064516,
    "cpu_runtime": 2.4933000000000003e-05,
    "total_runtime": 1.4781951904296875e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.85150272493573,
    "kernel_usage": 5.9016094601542415,
    "cpu_runtime": 0.00017515,
    "total_runtime": 9.274482727050781e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.56908823386115,
    "kernel_usage": 6.174034007308161,
    "cpu_runtime": 0.000386725,
    "total_runtime": 0.0001957416534423828
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 278.28849164232076,
    "kernel_usage": 8.696515363822524,
    "cpu_runtime": 0.00019440299999999997,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 208.82549915151517,
    "kernel_usage": 6.525796848484849,
    "cpu_runtime": 4.9290000000000004e-05,
    "total_runtime": 2.3603439331054688e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 152.76703744,
    "kernel_usage": 4.77396992,
    "cpu_runtime": 2.9138e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 268.12885483040935,
    "kernel_usage": 8.379026713450292,
    "cpu_runtime": 0.00010931499999999999,
    "total_runtime": 4.076957702636719e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 205.99130689060777,
    "kernel_usage": 6.437228340331493,
    "cpu_runtime": 8.8893e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76201427340737,
    "kernel_usage": 6.24256294604398,
    "cpu_runtime": 0.019774244000000003,
    "total_runtime": 0.009898900985717773
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.9692557629741,
    "kernel_usage": 11.436539242592941,
    "cpu_runtime": 1.0324375239999997,
    "total_runtime": 0.28211045265197754
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.3214831178645,
    "kernel_usage": 5.635046347433265,
    "cpu_runtime": 0.00020937100000000003,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.97108642253522,
    "kernel_usage": 5.624096450704226,
    "cpu_runtime": 3.0465000000000004e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 163.6251157633803,
    "kernel_usage": 5.113284867605635,
    "cpu_runtime": 2.7698000000000005e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 364.60709855257744,
    "kernel_usage": 11.393971829768045,
    "cpu_runtime": 0.188131972,
    "total_runtime": 0.051598548889160156
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.27203840000004,
    "kernel_usage": 6.227251200000001,
    "cpu_runtime": 6.081300000000001e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.91451908112452,
    "kernel_usage": 5.341078721285141,
    "cpu_runtime": 0.00020293100000000003,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 134.56089832727272,
    "kernel_usage": 4.205028072727273,
    "cpu_runtime": 1.4116000000000002e-05,
    "total_runtime": 1.049041748046875e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 204.8067307243243,
    "kernel_usage": 6.400210335135134,
    "cpu_runtime": 0.00014453599999999999,
    "total_runtime": 7.05718994140625e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.50762443487181,
    "kernel_usage": 6.172113263589744,
    "cpu_runtime": 0.00018364900000000003,
    "total_runtime": 9.298324584960938e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.649700752136,
    "kernel_usage": 11.27030314850425,
    "cpu_runtime": 0.23638470300000003,
    "total_runtime": 0.06554412841796875
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 206.91080761841002,
    "kernel_usage": 6.465962738075313,
    "cpu_runtime": 0.00035370599999999996,
    "total_runtime": 0.0001709461212158203
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 272.2916212651547,
    "kernel_usage": 8.509113164536084,
    "cpu_runtime": 0.000314859,
    "total_runtime": 0.00011563301086425781
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.94335341876206,
    "kernel_usage": 9.310729794336314,
    "cpu_runtime": 0.017007255000000002,
    "total_runtime": 0.005708217620849609
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.60474927265147,
    "kernel_usage": 6.237648414770359,
    "cpu_runtime": 0.0057093099999999996,
    "total_runtime": 0.0028603076934814453
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 210.14196737492713,
    "kernel_usage": 6.566936480466473,
    "cpu_runtime": 0.00017184900000000001,
    "total_runtime": 8.177757263183594e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.46295114049587,
    "kernel_usage": 5.920717223140496,
    "cpu_runtime": 0.000109315,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.3677996027335,
    "kernel_usage": 6.167743737585422,
    "cpu_runtime": 0.0008263060000000001,
    "total_runtime": 0.00041866302490234375
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.96268799999999,
    "kernel_usage": 6.4675839999999996,
    "cpu_runtime": 0.00014211,
    "total_runtime": 6.866455078125e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.88760924621835,
    "kernel_usage": 6.246487788944323,
    "cpu_runtime": 0.028657059000000002,
    "total_runtime": 0.014336585998535156
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 280.3474120911393,
    "kernel_usage": 8.760856627848103,
    "cpu_runtime": 0.00042242900000000004,
    "total_runtime": 0.0001506805419921875
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 193.12225258577408,
    "kernel_usage": 6.03507039330544,
    "cpu_runtime": 0.00011004500000000001,
    "total_runtime": 5.698204040527344e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 222.54708894977168,
    "kernel_usage": 6.954596529680365,
    "cpu_runtime": 0.000581,
    "total_runtime": 0.00026106834411621094
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 213.19425123806602,
    "kernel_usage": 6.662320351189563,
    "cpu_runtime": 0.000662308,
    "total_runtime": 0.00031065940856933594
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 201.29106647431695,
    "kernel_usage": 6.290345827322405,
    "cpu_runtime": 0.000175649,
    "total_runtime": 8.726119995117188e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.6630401961686,
    "kernel_usage": 6.145720006130269,
    "cpu_runtime": 0.000122378,
    "total_runtime": 6.222724914550781e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 180.7072352603774,
    "kernel_usage": 5.647101101886793,
    "cpu_runtime": 0.00018267600000000002,
    "total_runtime": 0.0001010894775390625
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.17622606008587,
    "kernel_usage": 6.349257064377683,
    "cpu_runtime": 0.00022573500000000002,
    "total_runtime": 0.00011110305786132812
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 194.01514187454845,
    "kernel_usage": 6.062973183579639,
    "cpu_runtime": 0.000281704,
    "total_runtime": 0.00014519691467285156
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.26984918709678,
    "kernel_usage": 5.789682787096774,
    "cpu_runtime": 5.4773e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.48638122666665,
    "kernel_usage": 6.077699413333333,
    "cpu_runtime": 0.00022257199999999998,
    "total_runtime": 0.00011444091796875
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.22688789144541,
    "kernel_usage": 6.757090246607669,
    "cpu_runtime": 0.000174763,
    "total_runtime": 8.082389831542969e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.67732145561385,
    "kernel_usage": 7.052416295487933,
    "cpu_runtime": 0.001025536,
    "total_runtime": 0.0004544258117675781
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.5672528592593,
    "kernel_usage": 6.173976651851853,
    "cpu_runtime": 0.00016533400000000003,
    "total_runtime": 8.368492126464844e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.99067003064596,
    "kernel_usage": 8.905958438457686,
    "cpu_runtime": 0.0013569029999999998,
    "total_runtime": 0.0004761219024658203
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 212.61808809391675,
    "kernel_usage": 6.6443152529348986,
    "cpu_runtime": 0.000474985,
    "total_runtime": 0.00022339820861816406
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.72096116363636,
    "kernel_usage": 5.772530036363636,
    "cpu_runtime": 0.000116268,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 149.3714590896552,
    "kernel_usage": 4.667858096551725,
    "cpu_runtime": 4.1311000000000005e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.20654153369955,
    "kernel_usage": 6.256454422928111,
    "cpu_runtime": 0.001998579,
    "total_runtime": 0.0009982585906982422
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.42724945160205,
    "kernel_usage": 6.700851545362564,
    "cpu_runtime": 0.00030316200000000005,
    "total_runtime": 0.00014138221740722656
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 219.46171392000005,
    "kernel_usage": 6.858178560000002,
    "cpu_runtime": 0.0006697440000000001,
    "total_runtime": 0.00030517578125
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.6519468011461,
    "kernel_usage": 6.9891233375358155,
    "cpu_runtime": 0.000372193,
    "total_runtime": 0.00016641616821289062
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.5837817425361,
    "kernel_usage": 12.768243179454252,
    "cpu_runtime": 0.002427556,
    "total_runtime": 0.0005941390991210938
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.23759283881066,
    "kernel_usage": 5.757424776212833,
    "cpu_runtime": 0.00028068500000000003,
    "total_runtime": 0.00015234947204589844
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.26048920790512,
    "kernel_usage": 7.133140287747035,
    "cpu_runtime": 0.000275373,
    "total_runtime": 0.00012063980102539062
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.27589105658268,
    "kernel_usage": 6.321121595518209,
    "cpu_runtime": 0.00034433600000000005,
    "total_runtime": 0.00017023086547851562
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 203.06668659804097,
    "kernel_usage": 6.34583395618878,
    "cpu_runtime": 0.000543699,
    "total_runtime": 0.0002677440643310547
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.7139558514116,
    "kernel_usage": 7.647311120356613,
    "cpu_runtime": 0.0007853150000000001,
    "total_runtime": 0.0003209114074707031
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.56076845390072,
    "kernel_usage": 5.7987740141843975,
    "cpu_runtime": 0.00018714000000000003,
    "total_runtime": 0.00010085105895996094
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.17430011214955,
    "kernel_usage": 4.5054468785046735,
    "cpu_runtime": 3.6780000000000004e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 209.54879554782613,
    "kernel_usage": 6.548399860869567,
    "cpu_runtime": 0.0012869780000000003,
    "total_runtime": 0.000614166259765625
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.6977358302483,
    "kernel_usage": 6.303054244695259,
    "cpu_runtime": 0.000426064,
    "total_runtime": 0.00021123886108398438
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.98557604102564,
    "kernel_usage": 6.124549251282051,
    "cpu_runtime": 0.000145787,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.50430434857708,
    "kernel_usage": 6.828259510893034,
    "cpu_runtime": 0.0005308530000000001,
    "total_runtime": 0.0002429485321044922
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.70225108546464,
    "kernel_usage": 6.24069534642077,
    "cpu_runtime": 0.013295854000000001,
    "total_runtime": 0.006657838821411133
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.64853030040163,
    "kernel_usage": 5.989016571887551,
    "cpu_runtime": 0.00022754900000000004,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.55360827376427,
    "kernel_usage": 5.267300258555133,
    "cpu_runtime": 0.00010569,
    "total_runtime": 6.270408630371094e-05
  }
]