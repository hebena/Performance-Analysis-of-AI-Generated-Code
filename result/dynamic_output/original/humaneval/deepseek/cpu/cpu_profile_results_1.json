[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.30509110392612,
    "kernel_usage": 6.884534096997691,
    "cpu_runtime": 0.0009097300000000001,
    "total_runtime": 0.00041294097900390625
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 131.804641412987,
    "kernel_usage": 4.118895044155844,
    "cpu_runtime": 2.4197e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.88287587322407,
    "kernel_usage": 5.215089871038252,
    "cpu_runtime": 7.281200000000001e-05,
    "total_runtime": 4.363059997558594e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 197.09527943529412,
    "kernel_usage": 6.159227482352941,
    "cpu_runtime": 9.5862e-05,
    "total_runtime": 4.863739013671875e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 205.91503411457288,
    "kernel_usage": 6.434844816080402,
    "cpu_runtime": 9.769700000000001e-05,
    "total_runtime": 4.744529724121094e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 152.78767070967743,
    "kernel_usage": 4.77461470967742,
    "cpu_runtime": 4.517e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.82914878439027,
    "kernel_usage": 6.775910899512196,
    "cpu_runtime": 0.000211954,
    "total_runtime": 9.775161743164062e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 215.25738227572816,
    "kernel_usage": 6.726793196116505,
    "cpu_runtime": 0.000158583,
    "total_runtime": 7.367134094238281e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 323.2986999466667,
    "kernel_usage": 10.103084373333335,
    "cpu_runtime": 0.00036998600000000005,
    "total_runtime": 0.00011444091796875
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 297.1560678681319,
    "kernel_usage": 9.286127120879122,
    "cpu_runtime": 0.000257885,
    "total_runtime": 8.678436279296875e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 160.5419788190476,
    "kernel_usage": 5.016936838095238,
    "cpu_runtime": 3.2152e-05,
    "total_runtime": 2.002716064453125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 213.3621755408072,
    "kernel_usage": 6.667567985650225,
    "cpu_runtime": 0.00011343900000000001,
    "total_runtime": 5.316734313964844e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 232.0907804537705,
    "kernel_usage": 7.252836889180328,
    "cpu_runtime": 0.00016877100000000001,
    "total_runtime": 7.271766662597656e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.13892095999998,
    "kernel_usage": 6.191841279999999,
    "cpu_runtime": 0.000115738,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 223.827389111639,
    "kernel_usage": 6.994605909738719,
    "cpu_runtime": 0.00022466500000000003,
    "total_runtime": 0.00010037422180175781
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 219.85172715648537,
    "kernel_usage": 6.870366473640168,
    "cpu_runtime": 0.0006263800000000001,
    "total_runtime": 0.0002849102020263672
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.49659174019803,
    "kernel_usage": 7.015518491881188,
    "cpu_runtime": 0.000270297,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.9602988698413,
    "kernel_usage": 8.123759339682541,
    "cpu_runtime": 0.00015618800000000003,
    "total_runtime": 6.008148193359375e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 171.46452270163937,
    "kernel_usage": 5.35826633442623,
    "cpu_runtime": 2.4937000000000002e-05,
    "total_runtime": 1.4543533325195312e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.77792103696203,
    "kernel_usage": 5.930560032405063,
    "cpu_runtime": 0.000178724,
    "total_runtime": 9.417533874511719e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.38575673093527,
    "kernel_usage": 6.168304897841727,
    "cpu_runtime": 0.000392484,
    "total_runtime": 0.00019884109497070312
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 276.331306606993,
    "kernel_usage": 8.635353331468531,
    "cpu_runtime": 0.000188424,
    "total_runtime": 6.818771362304688e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 205.58800486400006,
    "kernel_usage": 6.424625152000002,
    "cpu_runtime": 4.901600000000001e-05,
    "total_runtime": 2.384185791015625e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 155.08990922105264,
    "kernel_usage": 4.846559663157895,
    "cpu_runtime": 2.8102e-05,
    "total_runtime": 1.811981201171875e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.3532417462857,
    "kernel_usage": 8.292288804571427,
    "cpu_runtime": 0.000110714,
    "total_runtime": 4.172325134277344e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.2796408808989,
    "kernel_usage": 6.446238777528091,
    "cpu_runtime": 8.754200000000001e-05,
    "total_runtime": 4.2438507080078125e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.7583775189525,
    "kernel_usage": 6.242449297467266,
    "cpu_runtime": 0.01938716,
    "total_runtime": 0.009705305099487305
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 366.29526048012286,
    "kernel_usage": 11.44672689000384,
    "cpu_runtime": 1.0219185250000002,
    "total_runtime": 0.2789876461029053
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.62290105060242,
    "kernel_usage": 5.644465657831326,
    "cpu_runtime": 0.00021445800000000003,
    "total_runtime": 0.00011873245239257812
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 176.5801984,
    "kernel_usage": 5.5181312,
    "cpu_runtime": 2.6523e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 166.16434346666668,
    "kernel_usage": 5.192635733333334,
    "cpu_runtime": 2.6147000000000002e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 365.8384593643386,
    "kernel_usage": 11.43245185513558,
    "cpu_runtime": 0.186178567,
    "total_runtime": 0.05089092254638672
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.53569076825394,
    "kernel_usage": 6.235490336507936,
    "cpu_runtime": 5.9941999999999996e-05,
    "total_runtime": 3.0040740966796875e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.2936672187867,
    "kernel_usage": 5.321677100587085,
    "cpu_runtime": 0.00020747200000000002,
    "total_runtime": 0.00012183189392089844
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 132.56736055652175,
    "kernel_usage": 4.142730017391305,
    "cpu_runtime": 1.4539000000000001e-05,
    "total_runtime": 1.0967254638671875e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 204.11847064192443,
    "kernel_usage": 6.3787022075601385,
    "cpu_runtime": 0.00014161700000000002,
    "total_runtime": 6.937980651855469e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.04602982005144,
    "kernel_usage": 6.157688431876608,
    "cpu_runtime": 0.00018275000000000002,
    "total_runtime": 9.274482727050781e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.4778678409434,
    "kernel_usage": 11.264933370029482,
    "cpu_runtime": 0.23672930200000003,
    "total_runtime": 0.06567096710205078
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 206.86557734208955,
    "kernel_usage": 6.4645492919402985,
    "cpu_runtime": 0.000330448,
    "total_runtime": 0.00015974044799804688
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.5154330482759,
    "kernel_usage": 8.453607282758622,
    "cpu_runtime": 0.00029926100000000005,
    "total_runtime": 0.000110626220703125
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.0007458937359,
    "kernel_usage": 9.343773309179246,
    "cpu_runtime": 0.016433156,
    "total_runtime": 0.005496025085449219
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.64049271940948,
    "kernel_usage": 6.238765397481546,
    "cpu_runtime": 0.00548091,
    "total_runtime": 0.002745389938354492
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 211.46619558554218,
    "kernel_usage": 6.608318612048193,
    "cpu_runtime": 0.000167386,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.76098268070177,
    "kernel_usage": 5.93003070877193,
    "cpu_runtime": 0.000103153,
    "total_runtime": 5.435943603515625e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.2517919644005,
    "kernel_usage": 6.1641184988875155,
    "cpu_runtime": 0.000760921,
    "total_runtime": 0.0003857612609863281
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.2785584355556,
    "kernel_usage": 6.414954951111112,
    "cpu_runtime": 0.00013214400000000003,
    "total_runtime": 6.437301635742188e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90083618452474,
    "kernel_usage": 6.246901130766398,
    "cpu_runtime": 0.027169578000000003,
    "total_runtime": 0.013591527938842773
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 281.80045311133676,
    "kernel_usage": 8.806264159729274,
    "cpu_runtime": 0.00039707200000000005,
    "total_runtime": 0.00014090538024902344
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 192.4815993797357,
    "kernel_usage": 6.015049980616741,
    "cpu_runtime": 0.00010417300000000001,
    "total_runtime": 5.412101745605469e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.04965734784244,
    "kernel_usage": 6.907801792120076,
    "cpu_runtime": 0.0005618070000000001,
    "total_runtime": 0.0002541542053222656
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 213.35529182173576,
    "kernel_usage": 6.6673528694292425,
    "cpu_runtime": 0.0006506000000000001,
    "total_runtime": 0.00030493736267089844
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.440333740113,
    "kernel_usage": 6.326260429378531,
    "cpu_runtime": 0.00017086000000000003,
    "total_runtime": 8.440017700195312e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 197.6090624,
    "kernel_usage": 6.1752832,
    "cpu_runtime": 0.000120611,
    "total_runtime": 6.103515625e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.73814374400004,
    "kernel_usage": 5.679316992000001,
    "cpu_runtime": 0.00017331900000000004,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 203.09731368869177,
    "kernel_usage": 6.346791052771618,
    "cpu_runtime": 0.000218384,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.82165260105083,
    "kernel_usage": 6.056926643782838,
    "cpu_runtime": 0.00026386300000000003,
    "total_runtime": 0.0001361370086669922
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 183.25475618267717,
    "kernel_usage": 5.726711130708662,
    "cpu_runtime": 5.5488e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.86103281509432,
    "kernel_usage": 6.0894072754716975,
    "cpu_runtime": 0.000221607,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.79096660346823,
    "kernel_usage": 6.774717706358382,
    "cpu_runtime": 0.00017883700000000002,
    "total_runtime": 8.249282836914062e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.97889536808844,
    "kernel_usage": 7.061840480252764,
    "cpu_runtime": 0.0010231349999999999,
    "total_runtime": 0.0004527568817138672
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 196.8866216228572,
    "kernel_usage": 6.152706925714288,
    "cpu_runtime": 0.00016429500000000004,
    "total_runtime": 8.344650268554688e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.6045813057654,
    "kernel_usage": 8.893893165805169,
    "cpu_runtime": 0.001365243,
    "total_runtime": 0.00047969818115234375
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 212.21894737136614,
    "kernel_usage": 6.631842105355192,
    "cpu_runtime": 0.000462962,
    "total_runtime": 0.0002181529998779297
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.55569000152096,
    "kernel_usage": 5.79861531254753,
    "cpu_runtime": 0.00011635100000000002,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 151.87027700869567,
    "kernel_usage": 4.74594615652174,
    "cpu_runtime": 4.164e-05,
    "total_runtime": 2.7418136596679688e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.1950195550957,
    "kernel_usage": 6.256094361096741,
    "cpu_runtime": 0.00184525,
    "total_runtime": 0.0009217262268066406
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.17413952537817,
    "kernel_usage": 6.724191860168068,
    "cpu_runtime": 0.00030524400000000003,
    "total_runtime": 0.0001418590545654297
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 221.62563407949528,
    "kernel_usage": 6.925801064984228,
    "cpu_runtime": 0.000670007,
    "total_runtime": 0.00030231475830078125
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 224.7460050736232,
    "kernel_usage": 7.023312658550725,
    "cpu_runtime": 0.000369727,
    "total_runtime": 0.00016450881958007812
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.7449590200957,
    "kernel_usage": 12.77327996937799,
    "cpu_runtime": 0.002444106,
    "total_runtime": 0.0005979537963867188
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 183.6673775797468,
    "kernel_usage": 5.739605549367088,
    "cpu_runtime": 0.000276751,
    "total_runtime": 0.0001506805419921875
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.24472478759697,
    "kernel_usage": 7.163897649612405,
    "cpu_runtime": 0.00028202600000000005,
    "total_runtime": 0.00012302398681640625
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.8129115583099,
    "kernel_usage": 6.337903486197185,
    "cpu_runtime": 0.00034331600000000003,
    "total_runtime": 0.00016927719116210938
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 202.57190347939874,
    "kernel_usage": 6.330371983731211,
    "cpu_runtime": 0.0005462379999999999,
    "total_runtime": 0.0002696514129638672
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.17809126549707,
    "kernel_usage": 7.6305653520467835,
    "cpu_runtime": 0.000796403,
    "total_runtime": 0.0003261566162109375
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.34619365727926,
    "kernel_usage": 5.792068551789977,
    "cpu_runtime": 0.00018515600000000004,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.45514049900993,
    "kernel_usage": 4.54547314059406,
    "cpu_runtime": 3.5026000000000007e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.2780891963622,
    "kernel_usage": 6.571190287386319,
    "cpu_runtime": 0.001267894,
    "total_runtime": 0.0006029605865478516
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.0338482275395,
    "kernel_usage": 6.313557757110609,
    "cpu_runtime": 0.000426774,
    "total_runtime": 0.00021123886108398438
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.237680121519,
    "kernel_usage": 6.1324275037974685,
    "cpu_runtime": 0.000147846,
    "total_runtime": 7.534027099609375e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.42284061879332,
    "kernel_usage": 6.825713769337291,
    "cpu_runtime": 0.0005264890000000001,
    "total_runtime": 0.0002410411834716797
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6996753844479,
    "kernel_usage": 6.240614855763996,
    "cpu_runtime": 0.012943829,
    "total_runtime": 0.006481647491455078
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 192.10481314728682,
    "kernel_usage": 6.003275410852713,
    "cpu_runtime": 0.000236335,
    "total_runtime": 0.00012302398681640625
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.67457086060605,
    "kernel_usage": 5.271080339393939,
    "cpu_runtime": 0.000106168,
    "total_runtime": 6.29425048828125e-05
  }
]