[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.45999178812787,
    "kernel_usage": 6.889374743378996,
    "cpu_runtime": 0.0009208819999999999,
    "total_runtime": 0.0004177093505859375
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 129.40531604210526,
    "kernel_usage": 4.043916126315789,
    "cpu_runtime": 2.3448e-05,
    "total_runtime": 1.811981201171875e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 165.7226190183784,
    "kernel_usage": 5.178831844324325,
    "cpu_runtime": 7.3096e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.0631516862745,
    "kernel_usage": 6.126973490196078,
    "cpu_runtime": 9.536e-05,
    "total_runtime": 4.863739013671875e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.507461465946,
    "kernel_usage": 6.390858170810812,
    "cpu_runtime": 9.020300000000002e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 156.60832085333334,
    "kernel_usage": 4.894010026666667,
    "cpu_runtime": 4.4806000000000004e-05,
    "total_runtime": 2.86102294921875e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 215.8298960457143,
    "kernel_usage": 6.744684251428572,
    "cpu_runtime": 0.000216123,
    "total_runtime": 0.00010013580322265625
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.4574964815534,
    "kernel_usage": 6.6705467650485435,
    "cpu_runtime": 0.000157257,
    "total_runtime": 7.367134094238281e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.7773998245162,
    "kernel_usage": 10.08679374451613,
    "cpu_runtime": 0.00035784600000000004,
    "total_runtime": 0.00011086463928222656
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 299.26106371084336,
    "kernel_usage": 9.351908240963855,
    "cpu_runtime": 0.00023688,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.13033287441863,
    "kernel_usage": 4.910322902325582,
    "cpu_runtime": 3.2218e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 212.533772288,
    "kernel_usage": 6.641680384,
    "cpu_runtime": 0.000114012,
    "total_runtime": 5.364418029785156e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.12809298193977,
    "kernel_usage": 7.379002905685618,
    "cpu_runtime": 0.000168329,
    "total_runtime": 7.128715515136719e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 196.39870932469634,
    "kernel_usage": 6.137459666396761,
    "cpu_runtime": 0.000115658,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 223.95381350400007,
    "kernel_usage": 6.998556672000002,
    "cpu_runtime": 0.00021357900000000004,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 218.77482827318664,
    "kernel_usage": 6.836713383537083,
    "cpu_runtime": 0.000640003,
    "total_runtime": 0.0002925395965576172
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.5953129683367,
    "kernel_usage": 7.018603530260522,
    "cpu_runtime": 0.00026720300000000004,
    "total_runtime": 0.00011897087097167969
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.1580550095238,
    "kernel_usage": 8.09868921904762,
    "cpu_runtime": 0.000155706,
    "total_runtime": 6.008148193359375e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 167.084032,
    "kernel_usage": 5.221376,
    "cpu_runtime": 2.5495000000000002e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.58467530585244,
    "kernel_usage": 5.924521103307889,
    "cpu_runtime": 0.00017763800000000004,
    "total_runtime": 9.369850158691406e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.53145606183574,
    "kernel_usage": 6.172858001932367,
    "cpu_runtime": 0.000389948,
    "total_runtime": 0.00019741058349609375
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 271.9802254222222,
    "kernel_usage": 8.499382044444443,
    "cpu_runtime": 0.000186754,
    "total_runtime": 6.866455078125e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 209.46440656494843,
    "kernel_usage": 6.5457627051546385,
    "cpu_runtime": 4.8441999999999995e-05,
    "total_runtime": 2.3126602172851562e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 153.76209521038965,
    "kernel_usage": 4.805065475324676,
    "cpu_runtime": 2.8228000000000005e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 268.07354748342857,
    "kernel_usage": 8.377298358857143,
    "cpu_runtime": 0.000111849,
    "total_runtime": 4.172325134277344e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 206.23033256228575,
    "kernel_usage": 6.44469789257143,
    "cpu_runtime": 8.604600000000001e-05,
    "total_runtime": 4.172325134277344e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.75887451310481,
    "kernel_usage": 6.2424648285345254,
    "cpu_runtime": 0.019174319,
    "total_runtime": 0.009598731994628906
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 366.4680099948059,
    "kernel_usage": 11.452125312337685,
    "cpu_runtime": 1.0352853389999999,
    "total_runtime": 0.282503604888916
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 181.08185118997912,
    "kernel_usage": 5.6588078496868475,
    "cpu_runtime": 0.0002068,
    "total_runtime": 0.00011420249938964844
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 183.92345678769232,
    "kernel_usage": 5.747608024615385,
    "cpu_runtime": 2.8503e-05,
    "total_runtime": 1.5497207641601562e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 166.18079171764705,
    "kernel_usage": 5.19314974117647,
    "cpu_runtime": 2.6942e-05,
    "total_runtime": 1.621246337890625e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 366.4099274389835,
    "kernel_usage": 11.450310232468235,
    "cpu_runtime": 0.187287072,
    "total_runtime": 0.05111408233642578
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 201.26156403100777,
    "kernel_usage": 6.289423875968993,
    "cpu_runtime": 6.19e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 171.01796990732677,
    "kernel_usage": 5.344311559603962,
    "cpu_runtime": 0.00020590800000000004,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 132.88317672727274,
    "kernel_usage": 4.152599272727273,
    "cpu_runtime": 1.3940000000000002e-05,
    "total_runtime": 1.049041748046875e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 204.26402179459458,
    "kernel_usage": 6.383250681081081,
    "cpu_runtime": 0.000144153,
    "total_runtime": 7.05718994140625e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.13435926123458,
    "kernel_usage": 6.160448726913581,
    "cpu_runtime": 0.000190352,
    "total_runtime": 9.655952453613281e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.34252044677504,
    "kernel_usage": 11.26070376396172,
    "cpu_runtime": 0.235297608,
    "total_runtime": 0.06529831886291504
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 207.05797028023954,
    "kernel_usage": 6.470561571257486,
    "cpu_runtime": 0.00032976800000000003,
    "total_runtime": 0.00015926361083984375
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 273.33364211835857,
    "kernel_usage": 8.541676316198705,
    "cpu_runtime": 0.00030172700000000006,
    "total_runtime": 0.00011038780212402344
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.1176733249901,
    "kernel_usage": 9.31617729140594,
    "cpu_runtime": 0.016152201,
    "total_runtime": 0.005418062210083008
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6327958399431,
    "kernel_usage": 6.238524869998222,
    "cpu_runtime": 0.005352665,
    "total_runtime": 0.002681255340576172
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 210.8906407506173,
    "kernel_usage": 6.590332523456791,
    "cpu_runtime": 0.00016290800000000002,
    "total_runtime": 7.724761962890625e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 189.6494327172414,
    "kernel_usage": 5.926544772413794,
    "cpu_runtime": 0.00010490100000000002,
    "total_runtime": 5.53131103515625e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 196.69446815903905,
    "kernel_usage": 6.14670212996997,
    "cpu_runtime": 0.0007808120000000001,
    "total_runtime": 0.00039696693420410156
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 206.72773291301115,
    "kernel_usage": 6.4602416535315985,
    "cpu_runtime": 0.000132584,
    "total_runtime": 6.413459777832031e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.8948538233161,
    "kernel_usage": 6.2467141819786285,
    "cpu_runtime": 0.027651547000000002,
    "total_runtime": 0.013833045959472656
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 280.3895796660988,
    "kernel_usage": 8.762174364565588,
    "cpu_runtime": 0.00039241000000000005,
    "total_runtime": 0.0001399517059326172
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 190.24506963591838,
    "kernel_usage": 5.9451584261224495,
    "cpu_runtime": 0.00011112700000000001,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.6249715838194,
    "kernel_usage": 6.925780361994356,
    "cpu_runtime": 0.000561684,
    "total_runtime": 0.00025343894958496094
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 212.59105545179287,
    "kernel_usage": 6.643470482868527,
    "cpu_runtime": 0.0006361050000000001,
    "total_runtime": 0.00029921531677246094
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.82783856138332,
    "kernel_usage": 6.338369955043229,
    "cpu_runtime": 0.00016780200000000002,
    "total_runtime": 8.273124694824219e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 194.68561066666666,
    "kernel_usage": 6.083925333333333,
    "cpu_runtime": 0.000119755,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 181.62037039045344,
    "kernel_usage": 5.67563657470167,
    "cpu_runtime": 0.00018143399999999998,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.8966721699115,
    "kernel_usage": 6.340521005309735,
    "cpu_runtime": 0.00021865200000000003,
    "total_runtime": 0.00010776519775390625
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.98583434186853,
    "kernel_usage": 6.062057323183391,
    "cpu_runtime": 0.00026732400000000004,
    "total_runtime": 0.00013780593872070312
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.62164653559324,
    "kernel_usage": 5.831926454237289,
    "cpu_runtime": 5.2503e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.07689345132746,
    "kernel_usage": 6.096152920353983,
    "cpu_runtime": 0.00021022500000000003,
    "total_runtime": 0.00010776519775390625
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.24989933542324,
    "kernel_usage": 6.757809354231976,
    "cpu_runtime": 0.00016447000000000003,
    "total_runtime": 7.605552673339844e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 226.1744905314223,
    "kernel_usage": 7.067952829106947,
    "cpu_runtime": 0.0009781850000000001,
    "total_runtime": 0.0004324913024902344
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.77813658053097,
    "kernel_usage": 6.180566768141593,
    "cpu_runtime": 0.000159852,
    "total_runtime": 8.082389831542969e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.19766080673685,
    "kernel_usage": 8.912426900210527,
    "cpu_runtime": 0.001291932,
    "total_runtime": 0.00045299530029296875
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 213.22478501548528,
    "kernel_usage": 6.663274531733915,
    "cpu_runtime": 0.000466173,
    "total_runtime": 0.0002186298370361328
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 184.5644754944,
    "kernel_usage": 5.7676398592,
    "cpu_runtime": 0.000110009,
    "total_runtime": 5.9604644775390625e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 150.24624113644862,
    "kernel_usage": 4.695195035514019,
    "cpu_runtime": 3.8329000000000005e-05,
    "total_runtime": 2.5510787963867188e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.2263921989104,
    "kernel_usage": 6.25707475621595,
    "cpu_runtime": 0.0019276480000000001,
    "total_runtime": 0.0009627342224121094
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 214.80699485591396,
    "kernel_usage": 6.712718589247311,
    "cpu_runtime": 0.000285774,
    "total_runtime": 0.00013303756713867188
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 221.4381742954774,
    "kernel_usage": 6.919942946733669,
    "cpu_runtime": 0.000630372,
    "total_runtime": 0.0002846717834472656
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.69847829867453,
    "kernel_usage": 6.990577446833579,
    "cpu_runtime": 0.000362137,
    "total_runtime": 0.00016188621520996094
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 408.7347579621321,
    "kernel_usage": 12.772961186316628,
    "cpu_runtime": 0.0024498920000000004,
    "total_runtime": 0.0005993843078613281
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.94626372377857,
    "kernel_usage": 5.77957074136808,
    "cpu_runtime": 0.00027074100000000007,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.2488348503093,
    "kernel_usage": 7.132776089072165,
    "cpu_runtime": 0.000263931,
    "total_runtime": 0.00011563301086425781
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.6904823671853,
    "kernel_usage": 6.3340775739745405,
    "cpu_runtime": 0.000341659,
    "total_runtime": 0.0001685619354248047
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 202.8936089219331,
    "kernel_usage": 6.340425278810409,
    "cpu_runtime": 0.0005205,
    "total_runtime": 0.00025653839111328125
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 245.15338396455314,
    "kernel_usage": 7.661043248892286,
    "cpu_runtime": 0.0007650990000000001,
    "total_runtime": 0.0003120899200439453
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.09030387103275,
    "kernel_usage": 5.784071995969773,
    "cpu_runtime": 0.000175192,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.92144935384619,
    "kernel_usage": 4.560045292307693,
    "cpu_runtime": 3.618200000000001e-05,
    "total_runtime": 2.47955322265625e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.6705220176733,
    "kernel_usage": 6.583453813052291,
    "cpu_runtime": 0.0012391190000000001,
    "total_runtime": 0.0005881786346435547
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.4415578239257,
    "kernel_usage": 6.295048681997678,
    "cpu_runtime": 0.00041351600000000006,
    "total_runtime": 0.0002052783966064453
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.97533568859063,
    "kernel_usage": 6.124229240268457,
    "cpu_runtime": 0.00013923800000000002,
    "total_runtime": 7.104873657226562e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 219.1228496405269,
    "kernel_usage": 6.847589051266466,
    "cpu_runtime": 0.0005156380000000001,
    "total_runtime": 0.0002353191375732422
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.69331159518146,
    "kernel_usage": 6.2404159873494205,
    "cpu_runtime": 0.012765829000000001,
    "total_runtime": 0.006392717361450195
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.51243527852762,
    "kernel_usage": 5.984763602453988,
    "cpu_runtime": 0.000223278,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.38667430697677,
    "kernel_usage": 5.262083572093024,
    "cpu_runtime": 0.00010357800000000002,
    "total_runtime": 6.151199340820312e-05
  }
]