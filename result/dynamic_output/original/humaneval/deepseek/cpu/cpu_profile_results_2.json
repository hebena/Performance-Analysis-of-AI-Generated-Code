[
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.18334295788264,
    "kernel_usage": 6.880729467433833,
    "cpu_runtime": 0.000912377,
    "total_runtime": 0.0004143714904785156
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 127.34400391529412,
    "kernel_usage": 3.9795001223529414,
    "cpu_runtime": 2.5807000000000002e-05,
    "total_runtime": 2.0265579223632812e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 167.18029710222223,
    "kernel_usage": 5.224384284444445,
    "cpu_runtime": 7.1746e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 195.9845928756219,
    "kernel_usage": 6.124518527363184,
    "cpu_runtime": 9.392000000000001e-05,
    "total_runtime": 4.792213439941406e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.09410639175255,
    "kernel_usage": 6.315440824742267,
    "cpu_runtime": 9.3475e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.36025641967217,
    "kernel_usage": 4.792508013114755,
    "cpu_runtime": 4.460800000000001e-05,
    "total_runtime": 2.9087066650390625e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.0857938113208,
    "kernel_usage": 6.752681056603775,
    "cpu_runtime": 0.00021844000000000003,
    "total_runtime": 0.0001010894775390625
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.16988864429533,
    "kernel_usage": 6.692809020134229,
    "cpu_runtime": 0.000152165,
    "total_runtime": 7.104873657226562e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.2128593358179,
    "kernel_usage": 10.069151854244309,
    "cpu_runtime": 0.00037104800000000007,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.65263616000004,
    "kernel_usage": 9.270394880000001,
    "cpu_runtime": 0.00025461900000000004,
    "total_runtime": 8.58306884765625e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 156.1070604047059,
    "kernel_usage": 4.878345637647059,
    "cpu_runtime": 3.1636e-05,
    "total_runtime": 2.0265579223632812e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 211.47462882077926,
    "kernel_usage": 6.608582150649352,
    "cpu_runtime": 0.00011646900000000001,
    "total_runtime": 5.507469177246094e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 237.70238281522492,
    "kernel_usage": 7.428199462975779,
    "cpu_runtime": 0.00016378400000000002,
    "total_runtime": 6.890296936035156e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.32803120956177,
    "kernel_usage": 6.229000975298805,
    "cpu_runtime": 0.00011928400000000002,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 224.20406780334133,
    "kernel_usage": 7.006377118854417,
    "cpu_runtime": 0.00022397400000000002,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 219.1384259628595,
    "kernel_usage": 6.848075811339359,
    "cpu_runtime": 0.000635842,
    "total_runtime": 0.00029015541076660156
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 226.36267002023348,
    "kernel_usage": 7.073833438132296,
    "cpu_runtime": 0.000277401,
    "total_runtime": 0.00012254714965820312
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 259.71357965891474,
    "kernel_usage": 8.116049364341086,
    "cpu_runtime": 0.000159755,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 169.16109345573773,
    "kernel_usage": 5.286284170491804,
    "cpu_runtime": 2.4602000000000003e-05,
    "total_runtime": 1.4543533325195312e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 189.00394194051285,
    "kernel_usage": 5.906373185641026,
    "cpu_runtime": 0.00017574200000000003,
    "total_runtime": 9.298324584960938e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.6191088959233,
    "kernel_usage": 6.175597152997603,
    "cpu_runtime": 0.00039294800000000006,
    "total_runtime": 0.00019884109497070312
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 271.18555106950356,
    "kernel_usage": 8.474548470921986,
    "cpu_runtime": 0.000182329,
    "total_runtime": 6.723403930664062e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 208.54678674285717,
    "kernel_usage": 6.517087085714286,
    "cpu_runtime": 4.8727e-05,
    "total_runtime": 2.3365020751953125e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 154.90054915324677,
    "kernel_usage": 4.840642161038962,
    "cpu_runtime": 2.8437000000000002e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 266.34541298983055,
    "kernel_usage": 8.323294155932205,
    "cpu_runtime": 0.00011239800000000002,
    "total_runtime": 4.220008850097656e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 207.70193408000003,
    "kernel_usage": 6.490685440000001,
    "cpu_runtime": 9.1612e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.76540378713003,
    "kernel_usage": 6.242668868347813,
    "cpu_runtime": 0.019132557,
    "total_runtime": 0.009577512741088867
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.68582318174526,
    "kernel_usage": 11.42768197442954,
    "cpu_runtime": 1.025595049,
    "total_runtime": 0.2804579734802246
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 179.8153132065574,
    "kernel_usage": 5.6192285377049185,
    "cpu_runtime": 0.00020921200000000002,
    "total_runtime": 0.0001163482666015625
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 175.27742215757578,
    "kernel_usage": 5.477419442424243,
    "cpu_runtime": 2.7581000000000002e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 160.80596813913044,
    "kernel_usage": 5.025186504347826,
    "cpu_runtime": 2.6454e-05,
    "total_runtime": 1.6450881958007812e-05
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 366.22637128489305,
    "kernel_usage": 11.444574102652908,
    "cpu_runtime": 0.189282701,
    "total_runtime": 0.05168461799621582
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.30487712230217,
    "kernel_usage": 6.228277410071943,
    "cpu_runtime": 6.605e-05,
    "total_runtime": 3.314018249511719e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.6605662183953,
    "kernel_usage": 5.333142694324853,
    "cpu_runtime": 0.00020791899999999999,
    "total_runtime": 0.00012183189392089844
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 132.9780781511111,
    "kernel_usage": 4.155564942222222,
    "cpu_runtime": 1.4266999999999999e-05,
    "total_runtime": 1.0728836059570312e-05
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 204.10327571948054,
    "kernel_usage": 6.378227366233767,
    "cpu_runtime": 0.000149879,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 197.6668768725441,
    "kernel_usage": 6.177089902267003,
    "cpu_runtime": 0.000187096,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.73246535403587,
    "kernel_usage": 11.27288954231362,
    "cpu_runtime": 0.23825968300000003,
    "total_runtime": 0.06604886054992676
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 207.84860838554215,
    "kernel_usage": 6.495269012048192,
    "cpu_runtime": 0.000329045,
    "total_runtime": 0.0001583099365234375
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 271.11383125870026,
    "kernel_usage": 8.472307226834383,
    "cpu_runtime": 0.00030832600000000004,
    "total_runtime": 0.00011372566223144531
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.8335663345787,
    "kernel_usage": 9.307298947955584,
    "cpu_runtime": 0.016498244000000002,
    "total_runtime": 0.005539417266845703
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.60414521238667,
    "kernel_usage": 6.237629537887083,
    "cpu_runtime": 0.005301928,
    "total_runtime": 0.002656221389770508
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 213.0409490123894,
    "kernel_usage": 6.657529656637169,
    "cpu_runtime": 0.000172188,
    "total_runtime": 8.082389831542969e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.6998319931915,
    "kernel_usage": 5.959369749787235,
    "cpu_runtime": 0.00010684600000000001,
    "total_runtime": 5.602836608886719e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 197.11019935302664,
    "kernel_usage": 6.159693729782083,
    "cpu_runtime": 0.000776353,
    "total_runtime": 0.00039386749267578125
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 204.54222506666667,
    "kernel_usage": 6.391944533333334,
    "cpu_runtime": 0.000134596,
    "total_runtime": 6.580352783203125e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.85987504863778,
    "kernel_usage": 6.2456210952699305,
    "cpu_runtime": 0.027511858,
    "total_runtime": 0.013765573501586914
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 279.4943903135136,
    "kernel_usage": 8.7341996972973,
    "cpu_runtime": 0.00039448900000000004,
    "total_runtime": 0.000141143798828125
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 192.18516020512823,
    "kernel_usage": 6.005786256410257,
    "cpu_runtime": 0.00010722000000000002,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 221.83875430683918,
    "kernel_usage": 6.932461072088724,
    "cpu_runtime": 0.000572275,
    "total_runtime": 0.0002579689025878906
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 212.65660740321545,
    "kernel_usage": 6.645518981350483,
    "cpu_runtime": 0.000630724,
    "total_runtime": 0.00029659271240234375
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.19799481379312,
    "kernel_usage": 6.318687337931035,
    "cpu_runtime": 0.000167763,
    "total_runtime": 8.296966552734375e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 194.64945287356326,
    "kernel_usage": 6.082795402298852,
    "cpu_runtime": 0.00012112500000000002,
    "total_runtime": 6.222724914550781e-05
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 182.0961234376238,
    "kernel_usage": 5.690503857425743,
    "cpu_runtime": 0.00017539700000000001,
    "total_runtime": 9.632110595703125e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 202.4564672845815,
    "kernel_usage": 6.326764602643172,
    "cpu_runtime": 0.000219143,
    "total_runtime": 0.00010824203491210938
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.86117084195806,
    "kernel_usage": 6.058161588811189,
    "cpu_runtime": 0.000264379,
    "total_runtime": 0.00013637542724609375
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 184.82684534153847,
    "kernel_usage": 5.775838916923077,
    "cpu_runtime": 5.728600000000001e-05,
    "total_runtime": 3.0994415283203125e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 193.95738223304352,
    "kernel_usage": 6.06116819478261,
    "cpu_runtime": 0.00021271800000000003,
    "total_runtime": 0.00010967254638671875
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.304316283871,
    "kernel_usage": 6.759509883870969,
    "cpu_runtime": 0.00017585700000000002,
    "total_runtime": 8.130073547363281e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.7742350122228,
    "kernel_usage": 7.055444844131962,
    "cpu_runtime": 0.0009952939999999999,
    "total_runtime": 0.00044083595275878906
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.85418088563378,
    "kernel_usage": 6.182943152676056,
    "cpu_runtime": 0.000167461,
    "total_runtime": 8.463859558105469e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.6275527933884,
    "kernel_usage": 8.925861024793388,
    "cpu_runtime": 0.001318395,
    "total_runtime": 0.000461578369140625
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.7212539945702,
    "kernel_usage": 6.6162891873303185,
    "cpu_runtime": 0.00044622800000000007,
    "total_runtime": 0.00021076202392578125
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.673449472,
    "kernel_usage": 5.802295296,
    "cpu_runtime": 0.00011067,
    "total_runtime": 5.9604644775390625e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.0413080739496,
    "kernel_usage": 4.626290877310925,
    "cpu_runtime": 4.2002e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 199.95990986815303,
    "kernel_usage": 6.248747183379782,
    "cpu_runtime": 0.0018816990000000001,
    "total_runtime": 0.0009410381317138672
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.07492676297645,
    "kernel_usage": 6.721091461343014,
    "cpu_runtime": 0.00028254100000000003,
    "total_runtime": 0.00013136863708496094
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.6011220633306,
    "kernel_usage": 6.893785064479081,
    "cpu_runtime": 0.000641138,
    "total_runtime": 0.0002906322479248047
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.41742775402986,
    "kernel_usage": 6.981794617313433,
    "cpu_runtime": 0.00035688800000000003,
    "total_runtime": 0.00015974044799804688
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 407.47120324340324,
    "kernel_usage": 12.733475101356351,
    "cpu_runtime": 0.002363628,
    "total_runtime": 0.0005800724029541016
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.72245210515808,
    "kernel_usage": 5.77257662828619,
    "cpu_runtime": 0.000264688,
    "total_runtime": 0.00014328956604003906
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 229.33891621463417,
    "kernel_usage": 7.166841131707318,
    "cpu_runtime": 0.000269019,
    "total_runtime": 0.00011730194091796875
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.85518279111113,
    "kernel_usage": 6.339224462222223,
    "cpu_runtime": 0.00032646000000000004,
    "total_runtime": 0.0001609325408935547
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 203.00278839854548,
    "kernel_usage": 6.343837137454546,
    "cpu_runtime": 0.000532396,
    "total_runtime": 0.00026226043701171875
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.25690663384617,
    "kernel_usage": 7.633028332307693,
    "cpu_runtime": 0.0007949130000000001,
    "total_runtime": 0.0003254413604736328
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.25512989223745,
    "kernel_usage": 5.78922280913242,
    "cpu_runtime": 0.00019345700000000001,
    "total_runtime": 0.00010442733764648438
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 146.5703644862745,
    "kernel_usage": 4.5803238901960786,
    "cpu_runtime": 3.5644e-05,
    "total_runtime": 2.4318695068359375e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 209.9617144348631,
    "kernel_usage": 6.561303576089472,
    "cpu_runtime": 0.001298024,
    "total_runtime": 0.0006182193756103516
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.77033029818182,
    "kernel_usage": 6.305322821818182,
    "cpu_runtime": 0.000423331,
    "total_runtime": 0.000209808349609375
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 197.03178550798722,
    "kernel_usage": 6.157243297124601,
    "cpu_runtime": 0.000147035,
    "total_runtime": 7.462501525878906e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 218.01870617971014,
    "kernel_usage": 6.813084568115942,
    "cpu_runtime": 0.00053799,
    "total_runtime": 0.0002467632293701172
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.70102018848578,
    "kernel_usage": 6.240656880890181,
    "cpu_runtime": 0.012793937000000003,
    "total_runtime": 0.006406545639038086
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 192.98350357829457,
    "kernel_usage": 6.030734486821705,
    "cpu_runtime": 0.000237416,
    "total_runtime": 0.00012302398681640625
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 169.33074378210117,
    "kernel_usage": 5.291585743190661,
    "cpu_runtime": 0.00010375500000000001,
    "total_runtime": 6.127357482910156e-05
  }
]