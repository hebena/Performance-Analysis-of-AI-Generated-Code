[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 210.00636352590982,
    "kernel_usage": 6.562698860184682,
    "cpu_runtime": 0.000921778,
    "total_runtime": 0.00043892860412597656
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 200.0653155302491,
    "kernel_usage": 6.252041110320285,
    "cpu_runtime": 0.00040210500000000004,
    "total_runtime": 0.0002009868621826172
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 138.0028316097561,
    "kernel_usage": 4.312588487804878,
    "cpu_runtime": 2.6980000000000003e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.37025947826086,
    "kernel_usage": 5.199070608695652,
    "cpu_runtime": 7.2985e-05,
    "total_runtime": 4.38690185546875e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 285.5652778955933,
    "kernel_usage": 8.92391493423729,
    "cpu_runtime": 0.00040169600000000005,
    "total_runtime": 0.00014066696166992188
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 204.82496211974524,
    "kernel_usage": 6.400780066242039,
    "cpu_runtime": 0.000153339,
    "total_runtime": 7.486343383789062e-05
  },
  {
    "task_id": "HumanEval_6.py",
    "status": "success",
    "cpu_usage": 224.1396420011572,
    "kernel_usage": 7.0043638125361625,
    "cpu_runtime": 0.0005541630000000001,
    "total_runtime": 0.0002472400665283203
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 203.73583202274884,
    "kernel_usage": 6.366744750710901,
    "cpu_runtime": 0.00010249200000000001,
    "total_runtime": 5.030632019042969e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.88293041832063,
    "kernel_usage": 4.80884157557252,
    "cpu_runtime": 4.8062e-05,
    "total_runtime": 3.123283386230469e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 193.90565863071163,
    "kernel_usage": 6.059551832209738,
    "cpu_runtime": 0.00012343600000000002,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.6163200636816,
    "kernel_usage": 6.67551000199005,
    "cpu_runtime": 0.000204739,
    "total_runtime": 9.584426879882812e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 286.8379648,
    "kernel_usage": 8.9636864,
    "cpu_runtime": 0.000213369,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 200.71731415578947,
    "kernel_usage": 6.272416067368421,
    "cpu_runtime": 9.0924e-05,
    "total_runtime": 4.5299530029296875e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.3626600727273,
    "kernel_usage": 4.917583127272728,
    "cpu_runtime": 2.8889000000000004e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 210.684102539738,
    "kernel_usage": 6.583878204366813,
    "cpu_runtime": 0.000115029,
    "total_runtime": 5.459785461425781e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 297.262907392,
    "kernel_usage": 9.289465856,
    "cpu_runtime": 0.000283492,
    "total_runtime": 9.5367431640625e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.41797057306124,
    "kernel_usage": 6.200561580408164,
    "cpu_runtime": 0.00011590100000000001,
    "total_runtime": 5.841255187988281e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 215.889917982266,
    "kernel_usage": 6.746559936945813,
    "cpu_runtime": 0.00020897700000000003,
    "total_runtime": 9.679794311523438e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 207.89547393721972,
    "kernel_usage": 6.496733560538116,
    "cpu_runtime": 0.000221065,
    "total_runtime": 0.00010633468627929688
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 255.5458053885058,
    "kernel_usage": 7.985806418390807,
    "cpu_runtime": 0.00042405100000000005,
    "total_runtime": 0.0001659393310546875
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 210.3082448231275,
    "kernel_usage": 6.572132650722734,
    "cpu_runtime": 0.000381576,
    "total_runtime": 0.00018143653869628906
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.0539233289827,
    "kernel_usage": 7.0016851040307095,
    "cpu_runtime": 0.000278311,
    "total_runtime": 0.00012421607971191406
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 216.22753946508877,
    "kernel_usage": 6.757110608284024,
    "cpu_runtime": 8.7124e-05,
    "total_runtime": 4.029273986816406e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 172.09961650793656,
    "kernel_usage": 5.3781130158730175,
    "cpu_runtime": 2.5850000000000005e-05,
    "total_runtime": 1.5020370483398438e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 175.67384305287356,
    "kernel_usage": 5.489807595402299,
    "cpu_runtime": 7.2878e-05,
    "total_runtime": 4.1484832763671875e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 196.88559403285026,
    "kernel_usage": 6.152674813526571,
    "cpu_runtime": 0.000388673,
    "total_runtime": 0.00019741058349609375
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 214.76041739770113,
    "kernel_usage": 6.71126304367816,
    "cpu_runtime": 0.000178186,
    "total_runtime": 8.296966552734375e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 205.71607648316834,
    "kernel_usage": 6.4286273900990105,
    "cpu_runtime": 4.9537000000000004e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 176.4793227341772,
    "kernel_usage": 5.514978835443038,
    "cpu_runtime": 3.324e-05,
    "total_runtime": 1.8835067749023438e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.5111301885058,
    "kernel_usage": 8.265972818390805,
    "cpu_runtime": 0.00010973200000000001,
    "total_runtime": 4.1484832763671875e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 204.65422765966852,
    "kernel_usage": 6.395444614364641,
    "cpu_runtime": 8.831600000000001e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 187.67590296504167,
    "kernel_usage": 5.864871967657552,
    "cpu_runtime": 0.00037630900000000007,
    "total_runtime": 0.00020051002502441406
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 222.18643233927713,
    "kernel_usage": 6.94332601060241,
    "cpu_runtime": 0.000879358,
    "total_runtime": 0.00039577484130859375
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 187.4640618305085,
    "kernel_usage": 5.858251932203391,
    "cpu_runtime": 2.6370000000000003e-05,
    "total_runtime": 1.4066696166992188e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 163.79618963287675,
    "kernel_usage": 5.118630926027398,
    "cpu_runtime": 2.8508000000000006e-05,
    "total_runtime": 1.7404556274414062e-05
  },
  {
    "task_id": "HumanEval_36.py",
    "status": "success",
    "cpu_usage": 212.2131641658712,
    "kernel_usage": 6.631661380183475,
    "cpu_runtime": 0.442270472,
    "total_runtime": 0.20840859413146973
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 211.57528264347826,
    "kernel_usage": 6.611727582608696,
    "cpu_runtime": 0.000313254,
    "total_runtime": 0.0001480579376220703
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 357.89572138576176,
    "kernel_usage": 11.184241293305055,
    "cpu_runtime": 0.190694932,
    "total_runtime": 0.05328226089477539
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 296.46724446650677,
    "kernel_usage": 9.264601389578337,
    "cpu_runtime": 0.064839204,
    "total_runtime": 0.02187061309814453
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 192.8797297777778,
    "kernel_usage": 6.027491555555557,
    "cpu_runtime": 0.00044698500000000006,
    "total_runtime": 0.00023174285888671875
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 132.88585251929825,
    "kernel_usage": 4.15268289122807,
    "cpu_runtime": 1.8059e-05,
    "total_runtime": 1.3589859008789062e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 204.136460318797,
    "kernel_usage": 6.379264384962406,
    "cpu_runtime": 6.4731e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 191.82736511687045,
    "kernel_usage": 5.994605159902202,
    "cpu_runtime": 0.00037411400000000004,
    "total_runtime": 0.00019502639770507812
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 171.11178984560144,
    "kernel_usage": 5.347243432675045,
    "cpu_runtime": 0.000227235,
    "total_runtime": 0.0001327991485595703
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 131.2257911466667,
    "kernel_usage": 4.100805973333334,
    "cpu_runtime": 1.4079000000000002e-05,
    "total_runtime": 1.0728836059570312e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 215.83766488771468,
    "kernel_usage": 6.744927027741084,
    "cpu_runtime": 0.00038955,
    "total_runtime": 0.0001804828643798828
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 202.9207370627306,
    "kernel_usage": 6.3412730332103315,
    "cpu_runtime": 0.00013110999999999998,
    "total_runtime": 6.461143493652344e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 152.61928354909094,
    "kernel_usage": 4.769352610909092,
    "cpu_runtime": 4.0026000000000006e-05,
    "total_runtime": 2.6226043701171875e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 255.69484693054835,
    "kernel_usage": 7.990463966579636,
    "cpu_runtime": 0.00023348600000000003,
    "total_runtime": 9.131431579589844e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.71929462495535,
    "kernel_usage": 11.272477957029855,
    "cpu_runtime": 0.23592978500000003,
    "total_runtime": 0.06540536880493164
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 276.10769656323345,
    "kernel_usage": 8.628365517601045,
    "cpu_runtime": 0.0005049100000000001,
    "total_runtime": 0.00018286705017089844
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 270.69482360341885,
    "kernel_usage": 8.45921323760684,
    "cpu_runtime": 0.000302041,
    "total_runtime": 0.00011157989501953125
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 296.87340757586526,
    "kernel_usage": 9.27729398674579,
    "cpu_runtime": 0.016341010000000003,
    "total_runtime": 0.0055043697357177734
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.39751315911113,
    "kernel_usage": 5.512422286222223,
    "cpu_runtime": 9.4627e-05,
    "total_runtime": 5.364418029785156e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 179.75187054845364,
    "kernel_usage": 5.617245954639176,
    "cpu_runtime": 8.314100000000001e-05,
    "total_runtime": 4.6253204345703125e-05
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 187.63464245140037,
    "kernel_usage": 5.8635825766062615,
    "cpu_runtime": 0.00027154500000000004,
    "total_runtime": 0.00014472007751464844
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 212.23306506177374,
    "kernel_usage": 6.6322832831804295,
    "cpu_runtime": 0.00016546300000000002,
    "total_runtime": 7.796287536621094e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.09027233684208,
    "kernel_usage": 5.940321010526315,
    "cpu_runtime": 0.00010333199999999999,
    "total_runtime": 5.435943603515625e-05
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 197.53505229139077,
    "kernel_usage": 6.1729703841059615,
    "cpu_runtime": 0.00014223000000000003,
    "total_runtime": 7.200241088867188e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 143.6782136888889,
    "kernel_usage": 4.489944177777778,
    "cpu_runtime": 2.4664e-05,
    "total_runtime": 1.71661376953125e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 188.1246875565943,
    "kernel_usage": 5.878896486143572,
    "cpu_runtime": 0.000268666,
    "total_runtime": 0.00014281272888183594
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 203.0940958261981,
    "kernel_usage": 6.346690494568691,
    "cpu_runtime": 0.000151559,
    "total_runtime": 7.462501525878906e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 180.54990418580644,
    "kernel_usage": 5.642184505806451,
    "cpu_runtime": 0.000133444,
    "total_runtime": 7.390975952148438e-05
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 256.22592207567567,
    "kernel_usage": 8.007060064864865,
    "cpu_runtime": 0.00036164700000000004,
    "total_runtime": 0.000141143798828125
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 368.85590502203246,
    "kernel_usage": 11.526747031938514,
    "cpu_runtime": 0.001029802,
    "total_runtime": 0.0002791881561279297
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 272.32400266194696,
    "kernel_usage": 8.510125083185843,
    "cpu_runtime": 0.0005869410000000001,
    "total_runtime": 0.0002155303955078125
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 172.09056943342463,
    "kernel_usage": 5.37783029479452,
    "cpu_runtime": 0.000149758,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 332.4567473665725,
    "kernel_usage": 10.38927335520539,
    "cpu_runtime": 0.005885342000000001,
    "total_runtime": 0.0017702579498291016
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 232.31420027348582,
    "kernel_usage": 7.259818758546432,
    "cpu_runtime": 0.0012345989999999999,
    "total_runtime": 0.0005314350128173828
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 201.35810989132946,
    "kernel_usage": 6.292440934104046,
    "cpu_runtime": 0.000166106,
    "total_runtime": 8.249282836914062e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 174.10240725086703,
    "kernel_usage": 5.440700226589595,
    "cpu_runtime": 7.1811e-05,
    "total_runtime": 4.124641418457031e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 182.208954368,
    "kernel_usage": 5.694029824,
    "cpu_runtime": 0.00015204700000000002,
    "total_runtime": 8.344650268554688e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 300.6735021783867,
    "kernel_usage": 9.396046943074584,
    "cpu_runtime": 0.0009419560000000002,
    "total_runtime": 0.0003132820129394531
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 165.89842318793973,
    "kernel_usage": 5.1843257246231165,
    "cpu_runtime": 7.871100000000001e-05,
    "total_runtime": 4.744529724121094e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 201.4011188892562,
    "kernel_usage": 6.293784965289256,
    "cpu_runtime": 0.000232406,
    "total_runtime": 0.00011539459228515625
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 295.4331706118919,
    "kernel_usage": 9.232286581621622,
    "cpu_runtime": 0.000521232,
    "total_runtime": 0.00017642974853515625
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 185.1485622857143,
    "kernel_usage": 5.785892571428572,
    "cpu_runtime": 5.562e-05,
    "total_runtime": 3.0040740966796875e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 204.68203519999997,
    "kernel_usage": 6.396313599999999,
    "cpu_runtime": 0.000292312,
    "total_runtime": 0.00014281272888183594
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.35797341682976,
    "kernel_usage": 6.07368666927593,
    "cpu_runtime": 0.00023679000000000001,
    "total_runtime": 0.00012183189392089844
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 186.8962763992995,
    "kernel_usage": 5.840508637478109,
    "cpu_runtime": 0.000254435,
    "total_runtime": 0.0001361370086669922
  },
  {
    "task_id": "HumanEval_83.py",
    "status": "success",
    "cpu_usage": 167.2175412892562,
    "kernel_usage": 5.225548165289256,
    "cpu_runtime": 4.824e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 282.26947717260276,
    "kernel_usage": 8.820921161643836,
    "cpu_runtime": 0.00039302200000000003,
    "total_runtime": 0.0001392364501953125
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 256.9273344,
    "kernel_usage": 8.0289792,
    "cpu_runtime": 0.000235224,
    "total_runtime": 9.1552734375e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 234.74625404388715,
    "kernel_usage": 7.335820438871473,
    "cpu_runtime": 0.00071415,
    "total_runtime": 0.00030422210693359375
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 227.67992069214355,
    "kernel_usage": 7.114997521629486,
    "cpu_runtime": 0.001119318,
    "total_runtime": 0.0004916191101074219
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 188.48602989714288,
    "kernel_usage": 5.890188434285715,
    "cpu_runtime": 0.00012582800000000003,
    "total_runtime": 6.67572021484375e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 224.74966976919922,
    "kernel_usage": 7.0234271802874755,
    "cpu_runtime": 0.001043826,
    "total_runtime": 0.00046443939208984375
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.3920861563452,
    "kernel_usage": 6.418502692385787,
    "cpu_runtime": 0.00019293900000000002,
    "total_runtime": 9.393692016601562e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 198.2101404809117,
    "kernel_usage": 6.19406689002849,
    "cpu_runtime": 0.00016587200000000001,
    "total_runtime": 8.368492126464844e-05
  },
  {
    "task_id": "HumanEval_94.py",
    "status": "success",
    "cpu_usage": 276.63207517423973,
    "kernel_usage": 8.644752349194992,
    "cpu_runtime": 0.002949473,
    "total_runtime": 0.0010662078857421875
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 297.3685836663101,
    "kernel_usage": 9.29276823957219,
    "cpu_runtime": 0.001060637,
    "total_runtime": 0.0003566741943359375
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 364.0965823534649,
    "kernel_usage": 11.378018198545778,
    "cpu_runtime": 0.00584995,
    "total_runtime": 0.0016067028045654297
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.57772635352697,
    "kernel_usage": 6.018053948547718,
    "cpu_runtime": 0.000110653,
    "total_runtime": 5.745887756347656e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 241.93549326244207,
    "kernel_usage": 7.5604841644513145,
    "cpu_runtime": 0.00037320200000000005,
    "total_runtime": 0.00015425682067871094
  },
  {
    "task_id": "HumanEval_99.py",
    "status": "success",
    "cpu_usage": 197.37171992874497,
    "kernel_usage": 6.16786624777328,
    "cpu_runtime": 0.000116231,
    "total_runtime": 5.888938903808594e-05
  },
  {
    "task_id": "HumanEval_100.py",
    "status": "success",
    "cpu_usage": 227.0882293827815,
    "kernel_usage": 7.096507168211922,
    "cpu_runtime": 0.00016350900000000002,
    "total_runtime": 7.200241088867188e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 215.47909801247397,
    "kernel_usage": 6.7337218128898115,
    "cpu_runtime": 0.00024711,
    "total_runtime": 0.00011467933654785156
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 157.05540934492757,
    "kernel_usage": 4.9079815420289865,
    "cpu_runtime": 5.167400000000001e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.75828528054606,
    "kernel_usage": 6.273696415017064,
    "cpu_runtime": 0.000280486,
    "total_runtime": 0.00013971328735351562
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.596854188467,
    "kernel_usage": 8.674901693389593,
    "cpu_runtime": 0.00094114,
    "total_runtime": 0.0003390312194824219
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 219.36549814975686,
    "kernel_usage": 6.855171817179902,
    "cpu_runtime": 0.000322696,
    "total_runtime": 0.00014710426330566406
  },
  {
    "task_id": "HumanEval_106.py",
    "status": "success",
    "cpu_usage": 210.00114651704376,
    "kernel_usage": 6.562535828657618,
    "cpu_runtime": 0.00033195200000000005,
    "total_runtime": 0.00015807151794433594
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 197.5695551735957,
    "kernel_usage": 6.174048599174865,
    "cpu_runtime": 0.001484255,
    "total_runtime": 0.0007512569427490234
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 216.3067988550459,
    "kernel_usage": 6.759587464220185,
    "cpu_runtime": 0.00022485200000000005,
    "total_runtime": 0.00010395050048828125
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 293.32694083180917,
    "kernel_usage": 9.166466900994036,
    "cpu_runtime": 0.0007035420000000001,
    "total_runtime": 0.00023984909057617188
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 301.99674098086035,
    "kernel_usage": 9.437398155651886,
    "cpu_runtime": 0.002159329,
    "total_runtime": 0.0007150173187255859
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.45065947943664,
    "kernel_usage": 6.982833108732395,
    "cpu_runtime": 0.000378251,
    "total_runtime": 0.00016927719116210938
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 285.23514148571434,
    "kernel_usage": 8.913598171428573,
    "cpu_runtime": 0.0005712450000000001,
    "total_runtime": 0.0002002716064453125
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 232.59012080676644,
    "kernel_usage": 7.268441275211451,
    "cpu_runtime": 0.000852325,
    "total_runtime": 0.00036644935607910156
  },
  {
    "task_id": "HumanEval_115.py",
    "status": "success",
    "cpu_usage": 207.75836653381816,
    "kernel_usage": 6.4924489541818176,
    "cpu_runtime": 0.000272434,
    "total_runtime": 0.00013113021850585938
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 446.4998914349342,
    "kernel_usage": 13.953121607341695,
    "cpu_runtime": 0.003479977,
    "total_runtime": 0.0007793903350830078
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 315.64265581412695,
    "kernel_usage": 9.863832994191467,
    "cpu_runtime": 0.002098864,
    "total_runtime": 0.0006649494171142578
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 187.7725313187384,
    "kernel_usage": 5.867891603710575,
    "cpu_runtime": 0.00024130200000000001,
    "total_runtime": 0.0001285076141357422
  },
  {
    "task_id": "HumanEval_119.py",
    "status": "success",
    "cpu_usage": 245.1087877006222,
    "kernel_usage": 7.659649615644444,
    "cpu_runtime": 0.000657433,
    "total_runtime": 0.0002682209014892578
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 206.1806175725558,
    "kernel_usage": 6.443144299142369,
    "cpu_runtime": 0.00028658700000000004,
    "total_runtime": 0.00013899803161621094
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 281.05425509304814,
    "kernel_usage": 8.782945471657754,
    "cpu_runtime": 0.00037591800000000004,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 307.85375347548637,
    "kernel_usage": 9.620429796108949,
    "cpu_runtime": 0.000377266,
    "total_runtime": 0.00012254714965820312
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 205.58231010183033,
    "kernel_usage": 6.424447190682198,
    "cpu_runtime": 0.00029457800000000004,
    "total_runtime": 0.00014328956604003906
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 203.03815605287556,
    "kernel_usage": 6.344942376652361,
    "cpu_runtime": 0.0005639540000000001,
    "total_runtime": 0.0002777576446533203
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 340.83279026086956,
    "kernel_usage": 10.651024695652174,
    "cpu_runtime": 0.00080367,
    "total_runtime": 0.0002357959747314453
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 323.76579404849997,
    "kernel_usage": 10.117681064015624,
    "cpu_runtime": 0.004348213000000001,
    "total_runtime": 0.0013430118560791016
  },
  {
    "task_id": "HumanEval_127.py",
    "status": "success",
    "cpu_usage": 222.00484626432,
    "kernel_usage": 6.93765144576,
    "cpu_runtime": 0.000330813,
    "total_runtime": 0.00014901161193847656
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 300.07078196052316,
    "kernel_usage": 9.377211936266349,
    "cpu_runtime": 0.000601672,
    "total_runtime": 0.00020051002502441406
  },
  {
    "task_id": "HumanEval_130.py",
    "status": "success",
    "cpu_usage": 207.17832258064522,
    "kernel_usage": 6.474322580645163,
    "cpu_runtime": 0.0019600000000000004,
    "total_runtime": 0.000946044921875
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 183.09653603591025,
    "kernel_usage": 5.721766751122195,
    "cpu_runtime": 0.00017505100000000002,
    "total_runtime": 9.560585021972656e-05
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 339.9608183035282,
    "kernel_usage": 10.623775571985256,
    "cpu_runtime": 0.001539196,
    "total_runtime": 0.0004527568817138672
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 232.81763103219512,
    "kernel_usage": 7.275550969756098,
    "cpu_runtime": 0.0006827490000000001,
    "total_runtime": 0.0002932548522949219
  },
  {
    "task_id": "HumanEval_137.py",
    "status": "success",
    "cpu_usage": 257.50699884617694,
    "kernel_usage": 8.04709371394303,
    "cpu_runtime": 0.00040950100000000005,
    "total_runtime": 0.0001590251922607422
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.96254795294118,
    "kernel_usage": 4.530079623529412,
    "cpu_runtime": 3.5253e-05,
    "total_runtime": 2.4318695068359375e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 174.01220195096775,
    "kernel_usage": 5.437881310967742,
    "cpu_runtime": 6.4306e-05,
    "total_runtime": 3.695487976074219e-05
  },
  {
    "task_id": "HumanEval_140.py",
    "status": "success",
    "cpu_usage": 305.50067579259263,
    "kernel_usage": 9.54689611851852,
    "cpu_runtime": 0.00049165,
    "total_runtime": 0.0001609325408935547
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 190.83820508726515,
    "kernel_usage": 5.963693908977036,
    "cpu_runtime": 0.000653826,
    "total_runtime": 0.0003426074981689453
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 305.3918210494519,
    "kernel_usage": 9.543494407795372,
    "cpu_runtime": 0.001195558,
    "total_runtime": 0.0003914833068847656
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 202.10408306437944,
    "kernel_usage": 6.315752595761857,
    "cpu_runtime": 0.00047751700000000006,
    "total_runtime": 0.00023627281188964844
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 221.95655511986186,
    "kernel_usage": 6.936142347495683,
    "cpu_runtime": 0.0006127970000000001,
    "total_runtime": 0.0002760887145996094
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.04902530009466,
    "kernel_usage": 6.251532040627958,
    "cpu_runtime": 0.5503877960000001,
    "total_runtime": 0.27512645721435547
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 203.69577767028426,
    "kernel_usage": 6.365493052196383,
    "cpu_runtime": 0.000187946,
    "total_runtime": 9.226799011230469e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 286.8558139840932,
    "kernel_usage": 8.964244187002912,
    "cpu_runtime": 0.0007051190000000001,
    "total_runtime": 0.00024580955505371094
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 186.4206808615385,
    "kernel_usage": 5.825646276923078,
    "cpu_runtime": 0.00027156600000000005,
    "total_runtime": 0.0001456737518310547
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 319.9072816510953,
    "kernel_usage": 9.997102551596727,
    "cpu_runtime": 0.00288994,
    "total_runtime": 0.0009033679962158203
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 238.58055082155693,
    "kernel_usage": 7.455642213173654,
    "cpu_runtime": 0.00018998600000000003,
    "total_runtime": 7.963180541992188e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 463.95075758239824,
    "kernel_usage": 14.498461174449945,
    "cpu_runtime": 0.014529212000000001,
    "total_runtime": 0.0031316280364990234
  },
  {
    "task_id": "HumanEval_154.py",
    "status": "success",
    "cpu_usage": 188.9552294437318,
    "kernel_usage": 5.904850920116619,
    "cpu_runtime": 0.00015452300000000002,
    "total_runtime": 8.177757263183594e-05
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 302.45197233898307,
    "kernel_usage": 9.451624135593221,
    "cpu_runtime": 0.00102108,
    "total_runtime": 0.0003376007080078125
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 196.58733463357666,
    "kernel_usage": 6.143354207299271,
    "cpu_runtime": 0.000898968,
    "total_runtime": 0.0004572868347167969
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.09749764866922,
    "kernel_usage": 5.253046801520913,
    "cpu_runtime": 0.00010540400000000001,
    "total_runtime": 6.270408630371094e-05
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 332.0206273365576,
    "kernel_usage": 10.375644604267425,
    "cpu_runtime": 0.0011129879999999999,
    "total_runtime": 0.0003352165222167969
  },
  {
    "task_id": "HumanEval_159.py",
    "status": "success",
    "cpu_usage": 141.44567084137933,
    "kernel_usage": 4.420177213793104,
    "cpu_runtime": 3.9119e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 344.5838202480493,
    "kernel_usage": 10.76824438275154,
    "cpu_runtime": 0.0016003830000000001,
    "total_runtime": 0.00046443939208984375
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 224.23560984774196,
    "kernel_usage": 7.007362807741936,
    "cpu_runtime": 0.000165732,
    "total_runtime": 7.390975952148438e-05
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 271.06532115082285,
    "kernel_usage": 8.470791285963214,
    "cpu_runtime": 0.000667597,
    "total_runtime": 0.00024628639221191406
  }
]