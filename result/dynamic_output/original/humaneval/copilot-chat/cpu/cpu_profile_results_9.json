[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.6124453060134,
    "kernel_usage": 6.612888915812919,
    "cpu_runtime": 0.0009061240000000001,
    "total_runtime": 0.00042819976806640625
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 201.1878827338583,
    "kernel_usage": 6.2871213354330715,
    "cpu_runtime": 0.000426426,
    "total_runtime": 0.00021195411682128906
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 137.50501376,
    "kernel_usage": 4.29703168,
    "cpu_runtime": 2.6226999999999998e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.35100486808508,
    "kernel_usage": 5.198468902127659,
    "cpu_runtime": 7.4563e-05,
    "total_runtime": 4.482269287109375e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 284.28304921180325,
    "kernel_usage": 8.883845287868851,
    "cpu_runtime": 0.000413448,
    "total_runtime": 0.00014543533325195312
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 205.58795227084636,
    "kernel_usage": 6.424623508463949,
    "cpu_runtime": 0.000156361,
    "total_runtime": 7.605552673339844e-05
  },
  {
    "task_id": "HumanEval_6.py",
    "status": "success",
    "cpu_usage": 224.51485185598332,
    "kernel_usage": 7.016089120499479,
    "cpu_runtime": 0.000514409,
    "total_runtime": 0.00022912025451660156
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 205.12465019497492,
    "kernel_usage": 6.410145318592966,
    "cpu_runtime": 9.732200000000001e-05,
    "total_runtime": 4.744529724121094e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.84835291428573,
    "kernel_usage": 4.870261028571429,
    "cpu_runtime": 4.421700000000001e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 194.98007563861006,
    "kernel_usage": 6.093127363706564,
    "cpu_runtime": 0.00012040100000000001,
    "total_runtime": 6.175041198730469e-05
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.73656496777497,
    "kernel_usage": 6.710517655242968,
    "cpu_runtime": 0.000200181,
    "total_runtime": 9.322166442871094e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 285.835264,
    "kernel_usage": 8.932352,
    "cpu_runtime": 0.000218075,
    "total_runtime": 7.62939453125e-05
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 200.6164452910053,
    "kernel_usage": 6.269263915343916,
    "cpu_runtime": 9.04e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.0336662974359,
    "kernel_usage": 4.907302071794872,
    "cpu_runtime": 2.9203000000000005e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 210.92809829956713,
    "kernel_usage": 6.591503071861473,
    "cpu_runtime": 0.000116168,
    "total_runtime": 5.507469177246094e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 300.2254624413437,
    "kernel_usage": 9.382045701291991,
    "cpu_runtime": 0.00027701200000000004,
    "total_runtime": 9.226799011230469e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 198.71045608093388,
    "kernel_usage": 6.209701752529184,
    "cpu_runtime": 0.000121757,
    "total_runtime": 6.127357482910156e-05
  },
  {
    "task_id": "HumanEval_17.py",
    "status": "success",
    "cpu_usage": 215.92380555061732,
    "kernel_usage": 6.747618923456791,
    "cpu_runtime": 0.00020849500000000003,
    "total_runtime": 9.655952453613281e-05
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 207.89243308546256,
    "kernel_usage": 6.496638533920705,
    "cpu_runtime": 0.000225027,
    "total_runtime": 0.00010824203491210938
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 253.83257676690442,
    "kernel_usage": 7.932268023965763,
    "cpu_runtime": 0.000424234,
    "total_runtime": 0.0001671314239501953
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 209.60762588186532,
    "kernel_usage": 6.550238308808291,
    "cpu_runtime": 0.00038580200000000003,
    "total_runtime": 0.00018405914306640625
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.59906227401578,
    "kernel_usage": 7.049970696062993,
    "cpu_runtime": 0.00027323800000000003,
    "total_runtime": 0.00012111663818359375
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 214.7004298971429,
    "kernel_usage": 6.7093884342857155,
    "cpu_runtime": 8.958e-05,
    "total_runtime": 4.172325134277344e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 173.9194368,
    "kernel_usage": 5.4349824,
    "cpu_runtime": 2.6538e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 175.79710002312137,
    "kernel_usage": 5.493659375722543,
    "cpu_runtime": 7.251e-05,
    "total_runtime": 4.124641418457031e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 196.69798418156032,
    "kernel_usage": 6.14681200567376,
    "cpu_runtime": 0.00039674400000000004,
    "total_runtime": 0.00020170211791992188
  },
  {
    "task_id": "HumanEval_26.py",
    "status": "success",
    "cpu_usage": 213.51875260170945,
    "kernel_usage": 6.67246101880342,
    "cpu_runtime": 0.00017868300000000004,
    "total_runtime": 8.368492126464844e-05
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 207.6346591049505,
    "kernel_usage": 6.488583097029703,
    "cpu_runtime": 4.9999e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 173.97582824186046,
    "kernel_usage": 5.436744632558139,
    "cpu_runtime": 3.5672e-05,
    "total_runtime": 2.0503997802734375e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 264.0419811396648,
    "kernel_usage": 8.251311910614525,
    "cpu_runtime": 0.00011268500000000001,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 207.39901212444445,
    "kernel_usage": 6.481219128888889,
    "cpu_runtime": 8.900600000000001e-05,
    "total_runtime": 4.291534423828125e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 187.50692434621027,
    "kernel_usage": 5.859591385819071,
    "cpu_runtime": 0.000365688,
    "total_runtime": 0.00019502639770507812
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 220.19559519255813,
    "kernel_usage": 6.881112349767442,
    "cpu_runtime": 0.0009029779999999999,
    "total_runtime": 0.0004100799560546875
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 188.12484826229507,
    "kernel_usage": 5.878901508196721,
    "cpu_runtime": 2.736e-05,
    "total_runtime": 1.4543533325195312e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.26049009577466,
    "kernel_usage": 5.070640315492958,
    "cpu_runtime": 2.7467000000000003e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_36.py",
    "status": "success",
    "cpu_usage": 212.2728764679549,
    "kernel_usage": 6.63352738962359,
    "cpu_runtime": 0.44443752900000005,
    "total_runtime": 0.20937085151672363
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 211.0899632923557,
    "kernel_usage": 6.596561352886115,
    "cpu_runtime": 0.000322601,
    "total_runtime": 0.00015282630920410156
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 358.3338745938864,
    "kernel_usage": 11.19793358105895,
    "cpu_runtime": 0.19239955399999997,
    "total_runtime": 0.05369281768798828
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 296.45616435635384,
    "kernel_usage": 9.264255136136057,
    "cpu_runtime": 0.068157358,
    "total_runtime": 0.022990703582763672
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 193.16993857205156,
    "kernel_usage": 6.036560580376611,
    "cpu_runtime": 0.00046469800000000004,
    "total_runtime": 0.00024056434631347656
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 135.01164982857142,
    "kernel_usage": 4.219114057142857,
    "cpu_runtime": 1.8026e-05,
    "total_runtime": 1.33514404296875e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 205.60108122352943,
    "kernel_usage": 6.425033788235295,
    "cpu_runtime": 6.6666e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 191.13962525825244,
    "kernel_usage": 5.973113289320389,
    "cpu_runtime": 0.000375507,
    "total_runtime": 0.0001964569091796875
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 171.53208064456328,
    "kernel_usage": 5.3603775201426025,
    "cpu_runtime": 0.00022942900000000002,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 131.8572127255814,
    "kernel_usage": 4.120537897674419,
    "cpu_runtime": 1.3518000000000002e-05,
    "total_runtime": 1.0251998901367188e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.1775153380711,
    "kernel_usage": 6.7555473543147215,
    "cpu_runtime": 0.000406141,
    "total_runtime": 0.00018787384033203125
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 203.33766686567168,
    "kernel_usage": 6.35430208955224,
    "cpu_runtime": 0.00012992500000000003,
    "total_runtime": 6.389617919921875e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 153.4307187082569,
    "kernel_usage": 4.794709959633028,
    "cpu_runtime": 3.987300000000001e-05,
    "total_runtime": 2.5987625122070312e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 254.97654613333336,
    "kernel_usage": 7.968017066666667,
    "cpu_runtime": 0.000233438,
    "total_runtime": 9.1552734375e-05
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.9038611265853,
    "kernel_usage": 11.27824566020579,
    "cpu_runtime": 0.24284987100000005,
    "total_runtime": 0.06728935241699219
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 277.02291312746115,
    "kernel_usage": 8.656966035233161,
    "cpu_runtime": 0.0005098860000000001,
    "total_runtime": 0.00018405914306640625
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 279.49419510134874,
    "kernel_usage": 8.734193596917148,
    "cpu_runtime": 0.00034584400000000005,
    "total_runtime": 0.00012373924255371094
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.23339081205387,
    "kernel_usage": 9.319793462876683,
    "cpu_runtime": 0.01663487,
    "total_runtime": 0.005577802658081055
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 177.71172841244447,
    "kernel_usage": 5.55349151288889,
    "cpu_runtime": 9.533200000000001e-05,
    "total_runtime": 5.364418029785156e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 179.19534694400002,
    "kernel_usage": 5.599854592000001,
    "cpu_runtime": 8.544700000000001e-05,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 188.0080960321608,
    "kernel_usage": 5.875253001005025,
    "cpu_runtime": 0.000267603,
    "total_runtime": 0.0001423358917236328
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 210.38037029693254,
    "kernel_usage": 6.574386571779142,
    "cpu_runtime": 0.000163517,
    "total_runtime": 7.772445678710938e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 190.01473647304348,
    "kernel_usage": 5.937960514782609,
    "cpu_runtime": 0.000104197,
    "total_runtime": 5.4836273193359375e-05
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 197.6839025260606,
    "kernel_usage": 6.1776219539393935,
    "cpu_runtime": 0.000155534,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 146.48307126857142,
    "kernel_usage": 4.577595977142857,
    "cpu_runtime": 2.4447e-05,
    "total_runtime": 1.6689300537109375e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 187.23373056,
    "kernel_usage": 5.85105408,
    "cpu_runtime": 0.000265608,
    "total_runtime": 0.0001418590545654297
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 205.01408426666669,
    "kernel_usage": 6.406690133333334,
    "cpu_runtime": 0.000152503,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 181.35794084102562,
    "kernel_usage": 5.667435651282051,
    "cpu_runtime": 0.00013490599999999999,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 253.57976843349758,
    "kernel_usage": 7.924367763546799,
    "cpu_runtime": 0.00036819000000000006,
    "total_runtime": 0.00014519691467285156
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 367.7730074935843,
    "kernel_usage": 11.49290648417451,
    "cpu_runtime": 0.0010250250000000002,
    "total_runtime": 0.00027871131896972656
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 270.9118063770673,
    "kernel_usage": 8.465993949283353,
    "cpu_runtime": 0.000585835,
    "total_runtime": 0.0002162456512451172
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 172.2441637978022,
    "kernel_usage": 5.382630118681319,
    "cpu_runtime": 0.000149481,
    "total_runtime": 8.678436279296875e-05
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 330.8994369745611,
    "kernel_usage": 10.340607405455035,
    "cpu_runtime": 0.005842783999999999,
    "total_runtime": 0.0017657279968261719
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 231.09767705858584,
    "kernel_usage": 7.221802408080808,
    "cpu_runtime": 0.0012545809999999998,
    "total_runtime": 0.0005428791046142578
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 200.69444188424072,
    "kernel_usage": 6.271701308882522,
    "cpu_runtime": 0.00016699400000000003,
    "total_runtime": 8.320808410644531e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 175.6686988156425,
    "kernel_usage": 5.489646837988828,
    "cpu_runtime": 7.497000000000001e-05,
    "total_runtime": 4.267692565917969e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 181.77660097729733,
    "kernel_usage": 5.680518780540542,
    "cpu_runtime": 0.00016035400000000003,
    "total_runtime": 8.821487426757812e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 301.06997348045974,
    "kernel_usage": 9.408436671264367,
    "cpu_runtime": 0.000999187,
    "total_runtime": 0.000331878662109375
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 165.37428431698115,
    "kernel_usage": 5.167946384905661,
    "cpu_runtime": 8.3588e-05,
    "total_runtime": 5.054473876953125e-05
  },
  {
    "task_id": "HumanEval_77.py",
    "status": "success",
    "cpu_usage": 200.5437185158371,
    "kernel_usage": 6.266991203619909,
    "cpu_runtime": 0.000211335,
    "total_runtime": 0.00010538101196289062
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 294.7264006252375,
    "kernel_usage": 9.210200019538672,
    "cpu_runtime": 0.0005178770000000001,
    "total_runtime": 0.00017571449279785156
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.0056383488,
    "kernel_usage": 5.8126761984,
    "cpu_runtime": 5.5434000000000005e-05,
    "total_runtime": 2.9802322387695312e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 204.48719844324324,
    "kernel_usage": 6.390224951351351,
    "cpu_runtime": 0.00028862100000000003,
    "total_runtime": 0.000141143798828125
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 192.62013439999998,
    "kernel_usage": 6.0193791999999995,
    "cpu_runtime": 0.00023513199999999998,
    "total_runtime": 0.0001220703125
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 186.5962259414462,
    "kernel_usage": 5.8311320606701935,
    "cpu_runtime": 0.000252247,
    "total_runtime": 0.00013518333435058594
  },
  {
    "task_id": "HumanEval_83.py",
    "status": "success",
    "cpu_usage": 167.21879384201682,
    "kernel_usage": 5.225587307563026,
    "cpu_runtime": 4.7443e-05,
    "total_runtime": 2.8371810913085938e-05
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 281.2406365746479,
    "kernel_usage": 8.788769892957747,
    "cpu_runtime": 0.000380861,
    "total_runtime": 0.0001354217529296875
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 254.62004664812835,
    "kernel_usage": 7.956876457754011,
    "cpu_runtime": 0.000227041,
    "total_runtime": 8.916854858398438e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 234.41158202607318,
    "kernel_usage": 7.325361938314787,
    "cpu_runtime": 0.0007030720000000001,
    "total_runtime": 0.0002999305725097656
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 227.14255390445985,
    "kernel_usage": 7.09820480951437,
    "cpu_runtime": 0.001092848,
    "total_runtime": 0.0004811286926269531
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 187.92786482637365,
    "kernel_usage": 5.872745775824177,
    "cpu_runtime": 0.00012231900000000002,
    "total_runtime": 6.508827209472656e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 224.83467808987552,
    "kernel_usage": 7.02608369030861,
    "cpu_runtime": 0.0009900800000000002,
    "total_runtime": 0.00044035911560058594
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.99365251442543,
    "kernel_usage": 6.437301641075795,
    "cpu_runtime": 0.000200871,
    "total_runtime": 9.751319885253906e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.53185679331474,
    "kernel_usage": 6.172870524791086,
    "cpu_runtime": 0.00016907199999999998,
    "total_runtime": 8.559226989746094e-05
  },
  {
    "task_id": "HumanEval_94.py",
    "status": "success",
    "cpu_usage": 276.8065915852766,
    "kernel_usage": 8.650205987039893,
    "cpu_runtime": 0.002994231,
    "total_runtime": 0.001081705093383789
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 296.9941828770746,
    "kernel_usage": 9.281068214908581,
    "cpu_runtime": 0.0010069030000000002,
    "total_runtime": 0.0003390312194824219
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 363.5426164295647,
    "kernel_usage": 11.360706763423897,
    "cpu_runtime": 0.005933792,
    "total_runtime": 0.0016322135925292969
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.9293180826446,
    "kernel_usage": 6.029041190082644,
    "cpu_runtime": 0.000111315,
    "total_runtime": 5.7697296142578125e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 238.80767346546548,
    "kernel_usage": 7.462739795795796,
    "cpu_runtime": 0.00037919500000000003,
    "total_runtime": 0.00015878677368164062
  },
  {
    "task_id": "HumanEval_99.py",
    "status": "success",
    "cpu_usage": 198.84240463089432,
    "kernel_usage": 6.213825144715448,
    "cpu_runtime": 0.00011662300000000001,
    "total_runtime": 5.8650970458984375e-05
  },
  {
    "task_id": "HumanEval_100.py",
    "status": "success",
    "cpu_usage": 215.07045299112627,
    "kernel_usage": 6.720951655972696,
    "cpu_runtime": 0.000150241,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 213.51164923786007,
    "kernel_usage": 6.672239038683127,
    "cpu_runtime": 0.000247399,
    "total_runtime": 0.00011587142944335938
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 155.0828707246377,
    "kernel_usage": 4.846339710144928,
    "cpu_runtime": 5.102500000000001e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 199.91788438068966,
    "kernel_usage": 6.247433886896552,
    "cpu_runtime": 0.000276452,
    "total_runtime": 0.00013828277587890625
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.65632432160226,
    "kernel_usage": 8.67676013505007,
    "cpu_runtime": 0.0009254539999999999,
    "total_runtime": 0.0003333091735839844
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 218.52323840000003,
    "kernel_usage": 6.828851200000001,
    "cpu_runtime": 0.00031781,
    "total_runtime": 0.00014543533325195312
  },
  {
    "task_id": "HumanEval_106.py",
    "status": "success",
    "cpu_usage": 210.3886604190476,
    "kernel_usage": 6.574645638095237,
    "cpu_runtime": 0.000337079,
    "total_runtime": 0.00016021728515625
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 197.40815497449665,
    "kernel_usage": 6.16900484295302,
    "cpu_runtime": 0.0014726880000000002,
    "total_runtime": 0.0007460117340087891
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 215.20575270226243,
    "kernel_usage": 6.725179771945701,
    "cpu_runtime": 0.000226786,
    "total_runtime": 0.00010538101196289062
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 290.27149128077673,
    "kernel_usage": 9.070984102524273,
    "cpu_runtime": 0.000712823,
    "total_runtime": 0.0002455711364746094
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 302.83212042700967,
    "kernel_usage": 9.463503763344052,
    "cpu_runtime": 0.002245445,
    "total_runtime": 0.0007414817810058594
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 222.7911371777461,
    "kernel_usage": 6.9622230368045654,
    "cpu_runtime": 0.00037235400000000003,
    "total_runtime": 0.0001671314239501953
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 285.7065806953271,
    "kernel_usage": 8.928330646728972,
    "cpu_runtime": 0.0005830879999999999,
    "total_runtime": 0.0002040863037109375
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 232.39986016711111,
    "kernel_usage": 7.262495630222222,
    "cpu_runtime": 0.0008726830000000001,
    "total_runtime": 0.00037550926208496094
  },
  {
    "task_id": "HumanEval_115.py",
    "status": "success",
    "cpu_usage": 208.3587920457143,
    "kernel_usage": 6.511212251428572,
    "cpu_runtime": 0.00027818900000000003,
    "total_runtime": 0.000133514404296875
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 447.7041654774775,
    "kernel_usage": 13.990755171171172,
    "cpu_runtime": 0.003554475,
    "total_runtime": 0.0007939338684082031
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 314.80081951920204,
    "kernel_usage": 9.837525609975064,
    "cpu_runtime": 0.0021067760000000003,
    "total_runtime": 0.0006692409515380859
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 187.5912191050093,
    "kernel_usage": 5.86222559703154,
    "cpu_runtime": 0.000241069,
    "total_runtime": 0.0001285076141357422
  },
  {
    "task_id": "HumanEval_119.py",
    "status": "success",
    "cpu_usage": 246.79217146499553,
    "kernel_usage": 7.71225535828111,
    "cpu_runtime": 0.000657241,
    "total_runtime": 0.0002663135528564453
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 206.30865868020308,
    "kernel_usage": 6.447145583756346,
    "cpu_runtime": 0.0002907,
    "total_runtime": 0.00014090538024902344
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 283.6142010638146,
    "kernel_usage": 8.862943783244207,
    "cpu_runtime": 0.00037934199999999996,
    "total_runtime": 0.00013375282287597656
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 308.2780217790099,
    "kernel_usage": 9.63368818059406,
    "cpu_runtime": 0.000371171,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 204.89274431090047,
    "kernel_usage": 6.40289825971564,
    "cpu_runtime": 0.000309222,
    "total_runtime": 0.00015091896057128906
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 202.94836666448447,
    "kernel_usage": 6.34213645826514,
    "cpu_runtime": 0.000591285,
    "total_runtime": 0.0002913475036621094
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 340.6207118106122,
    "kernel_usage": 10.644397244081631,
    "cpu_runtime": 0.0007958609999999999,
    "total_runtime": 0.00023365020751953125
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 323.12403386416406,
    "kernel_usage": 10.097626058255127,
    "cpu_runtime": 0.004432811,
    "total_runtime": 0.0013718605041503906
  },
  {
    "task_id": "HumanEval_127.py",
    "status": "success",
    "cpu_usage": 222.76586078208004,
    "kernel_usage": 6.961433149440001,
    "cpu_runtime": 0.000331947,
    "total_runtime": 0.00014901161193847656
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 301.00151259858825,
    "kernel_usage": 9.406297268705883,
    "cpu_runtime": 0.000609997,
    "total_runtime": 0.00020265579223632812
  },
  {
    "task_id": "HumanEval_130.py",
    "status": "success",
    "cpu_usage": 207.55114960286738,
    "kernel_usage": 6.485973425089606,
    "cpu_runtime": 0.0019328470000000001,
    "total_runtime": 0.0009312629699707031
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 184.34791730393704,
    "kernel_usage": 5.760872415748032,
    "cpu_runtime": 0.000167457,
    "total_runtime": 9.083747863769531e-05
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 339.1440444124276,
    "kernel_usage": 10.598251387888363,
    "cpu_runtime": 0.0015354980000000002,
    "total_runtime": 0.0004527568817138672
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 232.13289164552057,
    "kernel_usage": 7.254152863922518,
    "cpu_runtime": 0.000685722,
    "total_runtime": 0.00029540061950683594
  },
  {
    "task_id": "HumanEval_137.py",
    "status": "success",
    "cpu_usage": 256.82951769347494,
    "kernel_usage": 8.025922427921092,
    "cpu_runtime": 0.000403525,
    "total_runtime": 0.0001571178436279297
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 145.75410006990293,
    "kernel_usage": 4.554815627184467,
    "cpu_runtime": 3.5793e-05,
    "total_runtime": 2.4557113647460938e-05
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 175.86551107368427,
    "kernel_usage": 5.495797221052634,
    "cpu_runtime": 6.373300000000002e-05,
    "total_runtime": 3.62396240234375e-05
  },
  {
    "task_id": "HumanEval_140.py",
    "status": "success",
    "cpu_usage": 305.79664081073025,
    "kernel_usage": 9.55614502533532,
    "cpu_runtime": 0.00048921,
    "total_runtime": 0.00015997886657714844
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 190.77603235955056,
    "kernel_usage": 5.961751011235955,
    "cpu_runtime": 0.0006477,
    "total_runtime": 0.000339508056640625
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 305.833141138896,
    "kernel_usage": 9.5572856605905,
    "cpu_runtime": 0.001136036,
    "total_runtime": 0.0003714561462402344
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.9116546089796,
    "kernel_usage": 6.309739206530613,
    "cpu_runtime": 0.00047176700000000005,
    "total_runtime": 0.00023365020751953125
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 221.62051557374255,
    "kernel_usage": 6.925641111679455,
    "cpu_runtime": 0.000619795,
    "total_runtime": 0.0002796649932861328
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 200.04986783835244,
    "kernel_usage": 6.251558369948514,
    "cpu_runtime": 0.552778233,
    "total_runtime": 0.276320219039917
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 202.6412858210269,
    "kernel_usage": 6.332540181907091,
    "cpu_runtime": 0.000197602,
    "total_runtime": 9.751319885253906e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 288.0737865142857,
    "kernel_usage": 9.002305828571428,
    "cpu_runtime": 0.000730778,
    "total_runtime": 0.0002536773681640625
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 186.38166042597405,
    "kernel_usage": 5.824426888311689,
    "cpu_runtime": 0.00027373100000000004,
    "total_runtime": 0.0001468658447265625
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 319.780356026355,
    "kernel_usage": 9.993136125823593,
    "cpu_runtime": 0.002869733,
    "total_runtime": 0.0008974075317382812
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 238.30024024327483,
    "kernel_usage": 7.446882507602338,
    "cpu_runtime": 0.000194308,
    "total_runtime": 8.153915405273438e-05
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 464.95156558546597,
    "kernel_usage": 14.529736424545812,
    "cpu_runtime": 0.014216909000000002,
    "total_runtime": 0.003057718276977539
  },
  {
    "task_id": "HumanEval_154.py",
    "status": "success",
    "cpu_usage": 188.22613722573104,
    "kernel_usage": 5.882066788304095,
    "cpu_runtime": 0.00015347800000000002,
    "total_runtime": 8.153915405273438e-05
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 302.8261218872651,
    "kernel_usage": 9.463316308977035,
    "cpu_runtime": 0.001037505,
    "total_runtime": 0.0003426074981689453
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 196.72562388223577,
    "kernel_usage": 6.147675746319868,
    "cpu_runtime": 0.0008475380000000001,
    "total_runtime": 0.00043082237243652344
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 169.0605298741036,
    "kernel_usage": 5.283141558565737,
    "cpu_runtime": 0.000101171,
    "total_runtime": 5.984306335449219e-05
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 332.22436214634155,
    "kernel_usage": 10.382011317073173,
    "cpu_runtime": 0.0010392150000000002,
    "total_runtime": 0.00031280517578125
  },
  {
    "task_id": "HumanEval_159.py",
    "status": "success",
    "cpu_usage": 138.91690192592594,
    "kernel_usage": 4.341153185185186,
    "cpu_runtime": 3.5770000000000005e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 342.6057256442338,
    "kernel_usage": 10.706428926382307,
    "cpu_runtime": 0.001551171,
    "total_runtime": 0.0004527568817138672
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 224.6918309494949,
    "kernel_usage": 7.021619717171716,
    "cpu_runtime": 0.000159105,
    "total_runtime": 7.081031799316406e-05
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 273.38439782811247,
    "kernel_usage": 8.543262432128515,
    "cpu_runtime": 0.000649192,
    "total_runtime": 0.00023746490478515625
  }
]