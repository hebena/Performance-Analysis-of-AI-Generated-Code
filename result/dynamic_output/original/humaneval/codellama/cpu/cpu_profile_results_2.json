[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 210.96951973908472,
    "kernel_usage": 6.592797491846397,
    "cpu_runtime": 0.000956185,
    "total_runtime": 0.0004532337188720703
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.55663697920002,
    "kernel_usage": 6.892394905600001,
    "cpu_runtime": 0.000920234,
    "total_runtime": 0.0004172325134277344
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 131.34708097662337,
    "kernel_usage": 4.1045962805194804,
    "cpu_runtime": 2.4113e-05,
    "total_runtime": 1.8358230590820312e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 163.90581487659577,
    "kernel_usage": 5.122056714893618,
    "cpu_runtime": 7.3467e-05,
    "total_runtime": 4.482269287109375e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 390.1069568746356,
    "kernel_usage": 12.190842402332363,
    "cpu_runtime": 0.0009570600000000001,
    "total_runtime": 0.0002453327178955078
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.90386581032863,
    "kernel_usage": 6.1532458065727695,
    "cpu_runtime": 9.9994e-05,
    "total_runtime": 5.078315734863281e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 202.83528940895522,
    "kernel_usage": 6.338602794029851,
    "cpu_runtime": 9.7203e-05,
    "total_runtime": 4.792213439941406e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.0785659870968,
    "kernel_usage": 4.783705187096775,
    "cpu_runtime": 4.525600000000001e-05,
    "total_runtime": 2.956390380859375e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.29996397202797,
    "kernel_usage": 6.759373874125874,
    "cpu_runtime": 0.000221235,
    "total_runtime": 0.00010228157043457031
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 214.70669062564104,
    "kernel_usage": 6.709584082051283,
    "cpu_runtime": 0.00015971300000000002,
    "total_runtime": 7.43865966796875e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 322.10359962546204,
    "kernel_usage": 10.065737488295689,
    "cpu_runtime": 0.00037399400000000005,
    "total_runtime": 0.00011610984802246094
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 293.74148285842693,
    "kernel_usage": 9.179421339325842,
    "cpu_runtime": 0.00024931899999999996,
    "total_runtime": 8.487701416015625e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 157.67894383589746,
    "kernel_usage": 4.9274669948717955,
    "cpu_runtime": 2.9323e-05,
    "total_runtime": 1.8596649169921875e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 199.36296653183518,
    "kernel_usage": 6.2300927041198495,
    "cpu_runtime": 0.00012691,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 235.3649821538462,
    "kernel_usage": 7.355155692307694,
    "cpu_runtime": 0.00016049000000000003,
    "total_runtime": 6.818771362304688e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.18302082529647,
    "kernel_usage": 6.224469400790515,
    "cpu_runtime": 0.00012014700000000001,
    "total_runtime": 6.031990051269531e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 214.90364328851066,
    "kernel_usage": 6.715738852765958,
    "cpu_runtime": 0.0013244770000000001,
    "total_runtime": 0.0006163120269775391
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 226.7393779150579,
    "kernel_usage": 7.085605559845559,
    "cpu_runtime": 0.000280025,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 262.21553076589146,
    "kernel_usage": 8.194235336434108,
    "cpu_runtime": 0.000161294,
    "total_runtime": 6.151199340820312e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 170.83269120000003,
    "kernel_usage": 5.338521600000001,
    "cpu_runtime": 2.6067000000000003e-05,
    "total_runtime": 1.52587890625e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 197.45978396755072,
    "kernel_usage": 6.17061824898596,
    "cpu_runtime": 0.0006035410000000001,
    "total_runtime": 0.0003056526184082031
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 206.17020652307696,
    "kernel_usage": 6.442818953846155,
    "cpu_runtime": 5.112100000000001e-05,
    "total_runtime": 2.47955322265625e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 177.07452708571435,
    "kernel_usage": 5.5335789714285735,
    "cpu_runtime": 3.546300000000001e-05,
    "total_runtime": 2.002716064453125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.43105780869564,
    "kernel_usage": 8.294720556521739,
    "cpu_runtime": 0.00011644200000000001,
    "total_runtime": 4.38690185546875e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 207.12298260983607,
    "kernel_usage": 6.472593206557377,
    "cpu_runtime": 9.0369e-05,
    "total_runtime": 4.363059997558594e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.75501140100295,
    "kernel_usage": 6.242344106281342,
    "cpu_runtime": 0.020039300000000003,
    "total_runtime": 0.010031938552856445
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.77859938625556,
    "kernel_usage": 11.430581230820486,
    "cpu_runtime": 1.077417222,
    "total_runtime": 0.2945544719696045
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.39593102504972,
    "kernel_usage": 5.637372844532804,
    "cpu_runtime": 0.00021633900000000002,
    "total_runtime": 0.00011992454528808594
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 179.46537115151514,
    "kernel_usage": 5.608292848484848,
    "cpu_runtime": 2.824e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.64173597681162,
    "kernel_usage": 5.082554249275363,
    "cpu_runtime": 2.6756000000000003e-05,
    "total_runtime": 1.6450881958007812e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 206.59495141682243,
    "kernel_usage": 6.456092231775701,
    "cpu_runtime": 0.00026352,
    "total_runtime": 0.00012755393981933594
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 298.1390377342864,
    "kernel_usage": 9.31684492919645,
    "cpu_runtime": 0.072395479,
    "total_runtime": 0.024282455444335938
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 167.75265160930235,
    "kernel_usage": 5.242270362790698,
    "cpu_runtime": 5.159400000000001e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.65517762406014,
    "kernel_usage": 6.2392243007518795,
    "cpu_runtime": 6.331e-05,
    "total_runtime": 3.170967102050781e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 171.25882164916203,
    "kernel_usage": 5.351838176536313,
    "cpu_runtime": 0.00021926400000000002,
    "total_runtime": 0.00012803077697753906
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 137.35392349090912,
    "kernel_usage": 4.29231010909091,
    "cpu_runtime": 1.4409000000000002e-05,
    "total_runtime": 1.049041748046875e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.25555482947368,
    "kernel_usage": 6.7579860884210525,
    "cpu_runtime": 0.000391851,
    "total_runtime": 0.0001811981201171875
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 209.16180227820894,
    "kernel_usage": 6.536306321194029,
    "cpu_runtime": 0.000167058,
    "total_runtime": 7.987022399902344e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 152.21922732972973,
    "kernel_usage": 4.756850854054054,
    "cpu_runtime": 4.0284e-05,
    "total_runtime": 2.6464462280273438e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.33053034892694,
    "kernel_usage": 6.197829073403967,
    "cpu_runtime": 0.0017405860000000001,
    "total_runtime": 0.0008776187896728516
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 360.1835502247237,
    "kernel_usage": 11.255735944522616,
    "cpu_runtime": 0.248880473,
    "total_runtime": 0.06909823417663574
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 280.18688180043955,
    "kernel_usage": 8.755840056263736,
    "cpu_runtime": 0.000607896,
    "total_runtime": 0.00021696090698242188
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 155.76059807244096,
    "kernel_usage": 4.86751868976378,
    "cpu_runtime": 4.7163e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 298.16913255954285,
    "kernel_usage": 9.317785392485714,
    "cpu_runtime": 0.017539804000000003,
    "total_runtime": 0.0058825016021728516
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 171.748492296063,
    "kernel_usage": 5.367140384251969,
    "cpu_runtime": 0.00010400800000000001,
    "total_runtime": 6.0558319091796875e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.63614955978872,
    "kernel_usage": 6.2386296737433975,
    "cpu_runtime": 0.005586932,
    "total_runtime": 0.0027985572814941406
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 185.34829104761906,
    "kernel_usage": 5.7921340952380955,
    "cpu_runtime": 0.00025984,
    "total_runtime": 0.00014019012451171875
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 209.96057282766571,
    "kernel_usage": 6.561267900864554,
    "cpu_runtime": 0.00017370300000000001,
    "total_runtime": 8.273124694824219e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 197.63464760456273,
    "kernel_usage": 6.176082737642585,
    "cpu_runtime": 0.00024785,
    "total_runtime": 0.00012540817260742188
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 191.18833695568404,
    "kernel_usage": 5.974635529865126,
    "cpu_runtime": 0.00023657500000000002,
    "total_runtime": 0.00012373924255371094
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 214.96362802116403,
    "kernel_usage": 6.717613375661376,
    "cpu_runtime": 9.6865e-05,
    "total_runtime": 4.506111145019531e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 187.06380379178086,
    "kernel_usage": 5.845743868493152,
    "cpu_runtime": 0.000260461,
    "total_runtime": 0.0001392364501953125
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 207.1065475121951,
    "kernel_usage": 6.472079609756097,
    "cpu_runtime": 0.000141715,
    "total_runtime": 6.842613220214844e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90429351121938,
    "kernel_usage": 6.247009172225606,
    "cpu_runtime": 0.028959238,
    "total_runtime": 0.014486551284790039
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 281.92118688667733,
    "kernel_usage": 8.810037090208667,
    "cpu_runtime": 0.000418751,
    "total_runtime": 0.00014853477478027344
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 363.55396002476795,
    "kernel_usage": 11.361061250773998,
    "cpu_runtime": 0.0013998500000000004,
    "total_runtime": 0.00038504600524902344
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.33988698148985,
    "kernel_usage": 6.385621468171558,
    "cpu_runtime": 0.0017265810000000003,
    "total_runtime": 0.0008449554443359375
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.02105872786885,
    "kernel_usage": 6.3131580852459015,
    "cpu_runtime": 0.000176286,
    "total_runtime": 8.726119995117188e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 196.76450388059703,
    "kernel_usage": 6.148890746268657,
    "cpu_runtime": 0.000125725,
    "total_runtime": 6.389617919921875e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.7444068374101,
    "kernel_usage": 6.054512713669066,
    "cpu_runtime": 0.00025682900000000003,
    "total_runtime": 0.00013256072998046875
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.50211788799996,
    "kernel_usage": 6.046941183999999,
    "cpu_runtime": 0.00027680699999999995,
    "total_runtime": 0.0001430511474609375
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.38915025454548,
    "kernel_usage": 5.824660945454546,
    "cpu_runtime": 5.865900000000001e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.0525397510374,
    "kernel_usage": 6.095391867219918,
    "cpu_runtime": 0.00022415000000000003,
    "total_runtime": 0.00011491775512695312
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 193.19801474702498,
    "kernel_usage": 6.037437960844531,
    "cpu_runtime": 0.00023998300000000004,
    "total_runtime": 0.00012421607971191406
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 280.56224643293314,
    "kernel_usage": 8.76757020102916,
    "cpu_runtime": 0.00038997600000000005,
    "total_runtime": 0.00013899803161621094
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 216.2671186099125,
    "kernel_usage": 6.758347456559766,
    "cpu_runtime": 0.00017685799999999998,
    "total_runtime": 8.177757263183594e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 294.9944554890555,
    "kernel_usage": 9.218576734032984,
    "cpu_runtime": 0.000938231,
    "total_runtime": 0.0003180503845214844
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 278.4092699047266,
    "kernel_usage": 8.700289684522707,
    "cpu_runtime": 0.001432436,
    "total_runtime": 0.0005145072937011719
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.25310159958872,
    "kernel_usage": 7.039159424987147,
    "cpu_runtime": 0.0010445530000000001,
    "total_runtime": 0.00046372413635253906
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 206.83456431882644,
    "kernel_usage": 6.463580134963326,
    "cpu_runtime": 0.00020169100000000004,
    "total_runtime": 9.751319885253906e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.83985895180055,
    "kernel_usage": 6.182495592243767,
    "cpu_runtime": 0.000170279,
    "total_runtime": 8.606910705566406e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 283.62535028213046,
    "kernel_usage": 8.863292196316577,
    "cpu_runtime": 0.001358517,
    "total_runtime": 0.00047898292541503906
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 213.0655281951219,
    "kernel_usage": 6.65829775609756,
    "cpu_runtime": 0.00049986,
    "total_runtime": 0.0002346038818359375
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.13043094261664,
    "kernel_usage": 6.28532596695677,
    "cpu_runtime": 0.003361042,
    "total_runtime": 0.0016710758209228516
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 191.71493905210087,
    "kernel_usage": 5.991091845378152,
    "cpu_runtime": 0.00010878600000000001,
    "total_runtime": 5.6743621826171875e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.99126692226415,
    "kernel_usage": 5.8122270913207545,
    "cpu_runtime": 0.00011751100000000001,
    "total_runtime": 6.318092346191406e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.79024574358976,
    "kernel_usage": 4.64969517948718,
    "cpu_runtime": 4.1505e-05,
    "total_runtime": 2.7894973754882812e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.1390565367693,
    "kernel_usage": 6.25434551677404,
    "cpu_runtime": 0.0019998140000000004,
    "total_runtime": 0.0009992122650146484
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 277.3268665421375,
    "kernel_usage": 8.666464579441797,
    "cpu_runtime": 0.000971301,
    "total_runtime": 0.0003502368927001953
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.52306958576517,
    "kernel_usage": 6.391345924555162,
    "cpu_runtime": 0.000274043,
    "total_runtime": 0.00013399124145507812
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 172.7037533356126,
    "kernel_usage": 5.396992291737893,
    "cpu_runtime": 0.00014452700000000003,
    "total_runtime": 8.368492126464844e-05
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 219.85212997337413,
    "kernel_usage": 6.870379061667942,
    "cpu_runtime": 0.000685088,
    "total_runtime": 0.0003116130828857422
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 223.4643331121952,
    "kernel_usage": 6.9832604097561,
    "cpu_runtime": 0.0003713480000000001,
    "total_runtime": 0.00016617774963378906
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 274.47233235422885,
    "kernel_usage": 8.577260386069652,
    "cpu_runtime": 0.000657665,
    "total_runtime": 0.0002396106719970703
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 239.81563256826468,
    "kernel_usage": 7.494238517758271,
    "cpu_runtime": 0.000846784,
    "total_runtime": 0.00035309791564941406
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 371.5978739489594,
    "kernel_usage": 11.61243356090498,
    "cpu_runtime": 0.0019579680000000005,
    "total_runtime": 0.0005269050598144531
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.26698087572524,
    "kernel_usage": 5.758343152366414,
    "cpu_runtime": 0.00028775900000000006,
    "total_runtime": 0.00015616416931152344
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.9410906209524,
    "kernel_usage": 7.154409081904762,
    "cpu_runtime": 0.000286565,
    "total_runtime": 0.0001251697540283203
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.57082408044695,
    "kernel_usage": 6.330338252513967,
    "cpu_runtime": 0.000345804,
    "total_runtime": 0.00017070770263671875
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 263.8123430320497,
    "kernel_usage": 8.244135719751553,
    "cpu_runtime": 0.000506327,
    "total_runtime": 0.0001919269561767578
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 263.5224753088278,
    "kernel_usage": 8.235077353400868,
    "cpu_runtime": 0.00217073,
    "total_runtime": 0.0008237361907958984
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.60140005839418,
    "kernel_usage": 7.643793751824818,
    "cpu_runtime": 0.0007989500000000001,
    "total_runtime": 0.0003266334533691406
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.7803077249564,
    "kernel_usage": 6.6806346164048875,
    "cpu_runtime": 0.001168214,
    "total_runtime": 0.0005464553833007812
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 202.56188740200773,
    "kernel_usage": 6.3300589813127415,
    "cpu_runtime": 0.000625414,
    "total_runtime": 0.00030875205993652344
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 212.08610774765103,
    "kernel_usage": 6.627690867114095,
    "cpu_runtime": 0.000301369,
    "total_runtime": 0.00014209747314453125
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.67854288592594,
    "kernel_usage": 6.9899544651851855,
    "cpu_runtime": 0.001151909,
    "total_runtime": 0.000514984130859375
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 143.18008513207548,
    "kernel_usage": 4.474377660377359,
    "cpu_runtime": 3.6185e-05,
    "total_runtime": 2.5272369384765625e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.47249148170314,
    "kernel_usage": 6.577265358803223,
    "cpu_runtime": 0.0013082070000000002,
    "total_runtime": 0.0006215572357177734
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.4421349769317,
    "kernel_usage": 6.2950667180291155,
    "cpu_runtime": 0.000428886,
    "total_runtime": 0.0002129077911376953
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.86576448916156,
    "kernel_usage": 5.745805140286299,
    "cpu_runtime": 0.00021436300000000002,
    "total_runtime": 0.00011658668518066406
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.43884682464622,
    "kernel_usage": 6.169963963270194,
    "cpu_runtime": 0.747493356,
    "total_runtime": 0.37859487533569336
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.85957888000002,
    "kernel_usage": 6.1206118400000005,
    "cpu_runtime": 0.00014942900000000002,
    "total_runtime": 7.62939453125e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.14377841777778,
    "kernel_usage": 6.785743075555556,
    "cpu_runtime": 0.0005358310000000001,
    "total_runtime": 0.0002467632293701172
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.67919066987952,
    "kernel_usage": 6.239974708433735,
    "cpu_runtime": 0.013276704,
    "total_runtime": 0.006649017333984375
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 253.02627130465635,
    "kernel_usage": 7.907070978270511,
    "cpu_runtime": 0.00027207100000000003,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.2395151096977,
    "kernel_usage": 9.351234847178054,
    "cpu_runtime": 0.008166064,
    "total_runtime": 0.0027289390563964844
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.92742654502925,
    "kernel_usage": 5.997732079532164,
    "cpu_runtime": 0.00023474400000000003,
    "total_runtime": 0.00012230873107910156
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 169.2088656238806,
    "kernel_usage": 5.287777050746269,
    "cpu_runtime": 0.000108118,
    "total_runtime": 6.389617919921875e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.4973669052631,
    "kernel_usage": 8.484292715789472,
    "cpu_runtime": 0.0007871169999999998,
    "total_runtime": 0.0002899169921875
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 233.58850982618597,
    "kernel_usage": 7.2996409320683115,
    "cpu_runtime": 0.000293496,
    "total_runtime": 0.00012564659118652344
  }
]