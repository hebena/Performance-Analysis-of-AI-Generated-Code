[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 211.09940899450316,
    "kernel_usage": 6.596856531078224,
    "cpu_runtime": 0.000952244,
    "total_runtime": 0.00045108795166015625
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 220.0501980728889,
    "kernel_usage": 6.876568689777778,
    "cpu_runtime": 0.000944353,
    "total_runtime": 0.0004291534423828125
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 131.46875848648648,
    "kernel_usage": 4.1083987027027025,
    "cpu_runtime": 2.3195e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.21913392432432,
    "kernel_usage": 5.194347935135135,
    "cpu_runtime": 7.3315e-05,
    "total_runtime": 4.410743713378906e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 390.09047577649335,
    "kernel_usage": 12.190327368015417,
    "cpu_runtime": 0.0009653900000000002,
    "total_runtime": 0.0002474784851074219
  },
  {
    "task_id": "HumanEval_5.py",
    "status": "success",
    "cpu_usage": 196.66165952300472,
    "kernel_usage": 6.145676860093897,
    "cpu_runtime": 9.9871e-05,
    "total_runtime": 5.078315734863281e-05
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 204.3049715070707,
    "kernel_usage": 6.384530359595959,
    "cpu_runtime": 9.6446e-05,
    "total_runtime": 4.7206878662109375e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 153.43179996033058,
    "kernel_usage": 4.794743748760331,
    "cpu_runtime": 4.4263e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.62195248301884,
    "kernel_usage": 6.769436015094339,
    "cpu_runtime": 0.000218982,
    "total_runtime": 0.0001010894775390625
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 215.15962447792214,
    "kernel_usage": 6.723738264935067,
    "cpu_runtime": 0.00015799800000000004,
    "total_runtime": 7.343292236328125e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 319.74352446841044,
    "kernel_usage": 9.991985139637826,
    "cpu_runtime": 0.000378877,
    "total_runtime": 0.00011849403381347656
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 296.0110156314363,
    "kernel_usage": 9.250344238482384,
    "cpu_runtime": 0.00026042,
    "total_runtime": 8.797645568847656e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 155.10536192,
    "kernel_usage": 4.84704256,
    "cpu_runtime": 2.9584000000000003e-05,
    "total_runtime": 1.9073486328125e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 197.56387580289854,
    "kernel_usage": 6.173871118840579,
    "cpu_runtime": 0.000130004,
    "total_runtime": 6.580352783203125e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 236.63552269016947,
    "kernel_usage": 7.394860084067796,
    "cpu_runtime": 0.000166434,
    "total_runtime": 7.033348083496094e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 199.2067680864865,
    "kernel_usage": 6.225211502702703,
    "cpu_runtime": 0.00012301100000000002,
    "total_runtime": 6.175041198730469e-05
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 214.09060761297934,
    "kernel_usage": 6.690331487905604,
    "cpu_runtime": 0.001384291,
    "total_runtime": 0.0006465911865234375
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 225.31155810461541,
    "kernel_usage": 7.040986190769232,
    "cpu_runtime": 0.00027933600000000004,
    "total_runtime": 0.0001239776611328125
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 260.0757742344828,
    "kernel_usage": 8.127367944827588,
    "cpu_runtime": 0.00016183800000000003,
    "total_runtime": 6.222724914550781e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 166.7871340606061,
    "kernel_usage": 5.21209793939394,
    "cpu_runtime": 2.6245000000000004e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 198.13972691112895,
    "kernel_usage": 6.19186646597278,
    "cpu_runtime": 0.0005900300000000001,
    "total_runtime": 0.00029778480529785156
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 206.69613167524753,
    "kernel_usage": 6.459254114851485,
    "cpu_runtime": 4.9773e-05,
    "total_runtime": 2.4080276489257812e-05
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 176.39268833882352,
    "kernel_usage": 5.512271510588235,
    "cpu_runtime": 3.5746999999999995e-05,
    "total_runtime": 2.0265579223632812e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 265.3695109565217,
    "kernel_usage": 8.292797217391303,
    "cpu_runtime": 0.000116415,
    "total_runtime": 4.38690185546875e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 202.7378246718232,
    "kernel_usage": 6.335557020994475,
    "cpu_runtime": 8.7489e-05,
    "total_runtime": 4.315376281738281e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.7484527542468,
    "kernel_usage": 6.242139148570213,
    "cpu_runtime": 0.020134842000000003,
    "total_runtime": 0.010080099105834961
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 365.7682406232351,
    "kernel_usage": 11.430257519476097,
    "cpu_runtime": 1.0855465700000002,
    "total_runtime": 0.2967853546142578
  },
  {
    "task_id": "HumanEval_33.py",
    "status": "success",
    "cpu_usage": 180.50576555688622,
    "kernel_usage": 5.640805173652694,
    "cpu_runtime": 0.00021561,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 178.95061566060605,
    "kernel_usage": 5.592206739393939,
    "cpu_runtime": 2.8159e-05,
    "total_runtime": 1.5735626220703125e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 162.07389842285713,
    "kernel_usage": 5.064809325714285,
    "cpu_runtime": 2.7048999999999998e-05,
    "total_runtime": 1.6689300537109375e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 206.59805123071018,
    "kernel_usage": 6.456189100959693,
    "cpu_runtime": 0.000256628,
    "total_runtime": 0.00012421607971191406
  },
  {
    "task_id": "HumanEval_39.py",
    "status": "success",
    "cpu_usage": 298.13043192345134,
    "kernel_usage": 9.316575997607854,
    "cpu_runtime": 0.07226402400000001,
    "total_runtime": 0.024239063262939453
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 168.74312486299215,
    "kernel_usage": 5.273222651968505,
    "cpu_runtime": 5.1094e-05,
    "total_runtime": 3.0279159545898438e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 201.91125255757578,
    "kernel_usage": 6.309726642424243,
    "cpu_runtime": 6.354400000000001e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.05880891039698,
    "kernel_usage": 5.3143377784499055,
    "cpu_runtime": 0.000214484,
    "total_runtime": 0.00012612342834472656
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 134.79560988444445,
    "kernel_usage": 4.212362808888889,
    "cpu_runtime": 1.4462000000000001e-05,
    "total_runtime": 1.0728836059570312e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.00440704343166,
    "kernel_usage": 6.750137720107239,
    "cpu_runtime": 0.00038418600000000007,
    "total_runtime": 0.00017786026000976562
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 207.7442482973451,
    "kernel_usage": 6.492007759292035,
    "cpu_runtime": 0.000167907,
    "total_runtime": 8.082389831542969e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 151.39939474285717,
    "kernel_usage": 4.7312310857142865,
    "cpu_runtime": 4.042800000000001e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.35378705964914,
    "kernel_usage": 6.1985558456140355,
    "cpu_runtime": 0.0017251840000000003,
    "total_runtime": 0.0008697509765625
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 359.93818480880026,
    "kernel_usage": 11.248068275275008,
    "cpu_runtime": 0.24924985400000002,
    "total_runtime": 0.06924796104431152
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 279.3476446825361,
    "kernel_usage": 8.729613896329253,
    "cpu_runtime": 0.000598749,
    "total_runtime": 0.0002143383026123047
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 155.65783040000002,
    "kernel_usage": 4.864307200000001,
    "cpu_runtime": 4.750300000000001e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 297.9340030458863,
    "kernel_usage": 9.310437595183947,
    "cpu_runtime": 0.016991094,
    "total_runtime": 0.005702972412109375
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 176.74098005333335,
    "kernel_usage": 5.523155626666667,
    "cpu_runtime": 0.00010113200000000001,
    "total_runtime": 5.7220458984375e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.61743919279778,
    "kernel_usage": 6.2380449747749305,
    "cpu_runtime": 0.005550714000000001,
    "total_runtime": 0.0027806758880615234
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.2307384888889,
    "kernel_usage": 5.819710577777778,
    "cpu_runtime": 0.000255749,
    "total_runtime": 0.0001373291015625
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 209.0748302061972,
    "kernel_usage": 6.533588443943662,
    "cpu_runtime": 0.000176958,
    "total_runtime": 8.463859558105469e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 197.94001920000002,
    "kernel_usage": 6.185625600000001,
    "cpu_runtime": 0.00024162600000000002,
    "total_runtime": 0.0001220703125
  },
  {
    "task_id": "HumanEval_59.py",
    "status": "success",
    "cpu_usage": 191.5801669423729,
    "kernel_usage": 5.986880216949153,
    "cpu_runtime": 0.000242541,
    "total_runtime": 0.0001266002655029297
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 214.44312487539267,
    "kernel_usage": 6.701347652356021,
    "cpu_runtime": 9.765300000000001e-05,
    "total_runtime": 4.553794860839844e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 186.7540927669535,
    "kernel_usage": 5.836065398967297,
    "cpu_runtime": 0.00025869399999999996,
    "total_runtime": 0.0001385211944580078
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 208.9808389242321,
    "kernel_usage": 6.530651216382253,
    "cpu_runtime": 0.000145987,
    "total_runtime": 6.985664367675781e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 199.90029936102562,
    "kernel_usage": 6.2468843550320505,
    "cpu_runtime": 0.029294662000000003,
    "total_runtime": 0.01465463638305664
  },
  {
    "task_id": "HumanEval_64.py",
    "status": "success",
    "cpu_usage": 282.3308218658268,
    "kernel_usage": 8.822838183307088,
    "cpu_runtime": 0.000427437,
    "total_runtime": 0.0001513957977294922
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 364.283328537284,
    "kernel_usage": 11.383854016790124,
    "cpu_runtime": 0.0014070010000000002,
    "total_runtime": 0.00038623809814453125
  },
  {
    "task_id": "HumanEval_69.py",
    "status": "success",
    "cpu_usage": 204.6863822377591,
    "kernel_usage": 6.396449444929972,
    "cpu_runtime": 0.001742197,
    "total_runtime": 0.0008511543273925781
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 202.19533003397262,
    "kernel_usage": 6.3186040635616445,
    "cpu_runtime": 0.00017595600000000003,
    "total_runtime": 8.702278137207031e-05
  },
  {
    "task_id": "HumanEval_72.py",
    "status": "success",
    "cpu_usage": 193.65700754285714,
    "kernel_usage": 6.051781485714286,
    "cpu_runtime": 0.000122816,
    "total_runtime": 6.341934204101562e-05
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 193.42731946666666,
    "kernel_usage": 6.044603733333333,
    "cpu_runtime": 0.00025733099999999997,
    "total_runtime": 0.00013303756713867188
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 194.0976651542673,
    "kernel_usage": 6.065552036070853,
    "cpu_runtime": 0.000287377,
    "total_runtime": 0.0001480579376220703
  },
  {
    "task_id": "HumanEval_79.py",
    "status": "success",
    "cpu_usage": 186.32463955348837,
    "kernel_usage": 5.8226449860465115,
    "cpu_runtime": 5.7305999999999996e-05,
    "total_runtime": 3.075599670410156e-05
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 194.24577319751555,
    "kernel_usage": 6.070180412422361,
    "cpu_runtime": 0.000223686,
    "total_runtime": 0.00011515617370605469
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 192.71373408316833,
    "kernel_usage": 6.02230419009901,
    "cpu_runtime": 0.00023203,
    "total_runtime": 0.00012040138244628906
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 281.6011938949565,
    "kernel_usage": 8.800037309217391,
    "cpu_runtime": 0.000386049,
    "total_runtime": 0.00013709068298339844
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 215.23485529302326,
    "kernel_usage": 6.726089227906977,
    "cpu_runtime": 0.000176527,
    "total_runtime": 8.20159912109375e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 290.27262338173,
    "kernel_usage": 9.071019480679062,
    "cpu_runtime": 0.0008560830000000001,
    "total_runtime": 0.0002949237823486328
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 277.26336621747924,
    "kernel_usage": 8.664480194296226,
    "cpu_runtime": 0.001437117,
    "total_runtime": 0.0005183219909667969
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 225.18470420983604,
    "kernel_usage": 7.037022006557376,
    "cpu_runtime": 0.001047994,
    "total_runtime": 0.00046539306640625
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.1959136077482,
    "kernel_usage": 6.412372300242131,
    "cpu_runtime": 0.00020205,
    "total_runtime": 9.846687316894531e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.09458639101123,
    "kernel_usage": 6.159205824719101,
    "cpu_runtime": 0.000167288,
    "total_runtime": 8.487701416015625e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 284.57193934813336,
    "kernel_usage": 8.892873104629167,
    "cpu_runtime": 0.0013630509999999999,
    "total_runtime": 0.00047898292541503906
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 211.7613463487514,
    "kernel_usage": 6.617542073398481,
    "cpu_runtime": 0.0004649930000000001,
    "total_runtime": 0.00021958351135253906
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.14996439609868,
    "kernel_usage": 6.285936387378084,
    "cpu_runtime": 0.0033436240000000003,
    "total_runtime": 0.0016622543334960938
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.92212318655464,
    "kernel_usage": 6.028816349579833,
    "cpu_runtime": 0.00010947100000000001,
    "total_runtime": 5.6743621826171875e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.93994909538463,
    "kernel_usage": 5.81062340923077,
    "cpu_runtime": 0.00011526200000000001,
    "total_runtime": 6.198883056640625e-05
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.84355531034484,
    "kernel_usage": 4.651361103448276,
    "cpu_runtime": 4.1165e-05,
    "total_runtime": 2.765655517578125e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.26154305491235,
    "kernel_usage": 6.258173220466011,
    "cpu_runtime": 0.001987669,
    "total_runtime": 0.0009925365447998047
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 276.805038291134,
    "kernel_usage": 8.650157446597937,
    "cpu_runtime": 0.000960234,
    "total_runtime": 0.00034689903259277344
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 205.05856090299824,
    "kernel_usage": 6.408080028218695,
    "cpu_runtime": 0.000277205,
    "total_runtime": 0.00013518333435058594
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 175.18051281586403,
    "kernel_usage": 5.474391025495751,
    "cpu_runtime": 0.00014743500000000001,
    "total_runtime": 8.416175842285156e-05
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.13486989085317,
    "kernel_usage": 6.8792146840891615,
    "cpu_runtime": 0.00068282,
    "total_runtime": 0.0003101825714111328
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 224.09877009655173,
    "kernel_usage": 7.003086565517242,
    "cpu_runtime": 0.000371868,
    "total_runtime": 0.0001659393310546875
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 275.43542041098044,
    "kernel_usage": 8.607356887843139,
    "cpu_runtime": 0.0006698230000000001,
    "total_runtime": 0.00024318695068359375
  },
  {
    "task_id": "HumanEval_114.py",
    "status": "success",
    "cpu_usage": 240.86720562291953,
    "kernel_usage": 7.527100175716235,
    "cpu_runtime": 0.0008418830000000001,
    "total_runtime": 0.0003495216369628906
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 370.38792267389346,
    "kernel_usage": 11.57462258355917,
    "cpu_runtime": 0.0019551250000000003,
    "total_runtime": 0.0005278587341308594
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.45208876436251,
    "kernel_usage": 5.764127773886329,
    "cpu_runtime": 0.000286289,
    "total_runtime": 0.0001552104949951172
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 228.99069308842508,
    "kernel_usage": 7.155959159013284,
    "cpu_runtime": 0.00028771900000000003,
    "total_runtime": 0.00012564659118652344
  },
  {
    "task_id": "HumanEval_123.py",
    "status": "success",
    "cpu_usage": 202.3524562272855,
    "kernel_usage": 6.323514257102672,
    "cpu_runtime": 0.000343019,
    "total_runtime": 0.00016951560974121094
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.96658753041305,
    "kernel_usage": 8.217705860325408,
    "cpu_runtime": 0.0005009420000000001,
    "total_runtime": 0.00019049644470214844
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 264.14846019889507,
    "kernel_usage": 8.25463938121547,
    "cpu_runtime": 0.0021658100000000002,
    "total_runtime": 0.0008199214935302734
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 244.6375540534508,
    "kernel_usage": 7.6449235641703375,
    "cpu_runtime": 0.000794402,
    "total_runtime": 0.0003247261047363281
  },
  {
    "task_id": "HumanEval_132.py",
    "status": "success",
    "cpu_usage": 213.49756024547384,
    "kernel_usage": 6.671798757671057,
    "cpu_runtime": 0.0011977189999999999,
    "total_runtime": 0.0005609989166259766
  },
  {
    "task_id": "HumanEval_133.py",
    "status": "success",
    "cpu_usage": 202.40326069034268,
    "kernel_usage": 6.325101896573209,
    "cpu_runtime": 0.000619616,
    "total_runtime": 0.00030612945556640625
  },
  {
    "task_id": "HumanEval_134.py",
    "status": "success",
    "cpu_usage": 213.03714459900164,
    "kernel_usage": 6.657410768718801,
    "cpu_runtime": 0.00030525999999999996,
    "total_runtime": 0.00014328956604003906
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 223.86822800772416,
    "kernel_usage": 6.99588212524138,
    "cpu_runtime": 0.0011608920000000002,
    "total_runtime": 0.0005185604095458984
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 144.8627162074074,
    "kernel_usage": 4.526959881481481,
    "cpu_runtime": 3.7301e-05,
    "total_runtime": 2.574920654296875e-05
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.19220240547529,
    "kernel_usage": 6.568506325171103,
    "cpu_runtime": 0.001317991,
    "total_runtime": 0.0006270408630371094
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.6319298497213,
    "kernel_usage": 6.300997807803791,
    "cpu_runtime": 0.000431213,
    "total_runtime": 0.00021386146545410156
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.2792460387097,
    "kernel_usage": 5.727476438709678,
    "cpu_runtime": 0.000216738,
    "total_runtime": 0.000118255615234375
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 197.41814790698464,
    "kernel_usage": 6.16931712209327,
    "cpu_runtime": 0.7439992550000001,
    "total_runtime": 0.3768646717071533
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 196.14932841226997,
    "kernel_usage": 6.1296665128834364,
    "cpu_runtime": 0.00015245600000000003,
    "total_runtime": 7.772445678710938e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 217.117170677303,
    "kernel_usage": 6.784911583665719,
    "cpu_runtime": 0.0005450830000000001,
    "total_runtime": 0.0002510547637939453
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.69137933462235,
    "kernel_usage": 6.240355604206949,
    "cpu_runtime": 0.013444626000000001,
    "total_runtime": 0.0067327022552490234
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 256.94679567587826,
    "kernel_usage": 8.029587364871196,
    "cpu_runtime": 0.00026158400000000004,
    "total_runtime": 0.00010180473327636719
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 299.2015710754672,
    "kernel_usage": 9.35004909610835,
    "cpu_runtime": 0.008321966,
    "total_runtime": 0.002781391143798828
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 191.52179911660235,
    "kernel_usage": 5.9850562223938235,
    "cpu_runtime": 0.00023653100000000003,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 168.5395269818182,
    "kernel_usage": 5.266860218181819,
    "cpu_runtime": 0.00010608300000000001,
    "total_runtime": 6.29425048828125e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 271.8597609074626,
    "kernel_usage": 8.495617528358206,
    "cpu_runtime": 0.0007816859999999998,
    "total_runtime": 0.0002875328063964844
  },
  {
    "task_id": "HumanEval_163.py",
    "status": "success",
    "cpu_usage": 232.67624457660375,
    "kernel_usage": 7.271132643018867,
    "cpu_runtime": 0.00029401399999999994,
    "total_runtime": 0.00012636184692382812
  }
]