[
  {
    "task_id": "HumanEval_0.py",
    "status": "success",
    "cpu_usage": 212.4910119478781,
    "kernel_usage": 6.64034412337119,
    "cpu_runtime": 0.0008475720000000001,
    "total_runtime": 0.00039887428283691406
  },
  {
    "task_id": "HumanEval_1.py",
    "status": "success",
    "cpu_usage": 221.05226053766089,
    "kernel_usage": 6.907883141801903,
    "cpu_runtime": 0.000941802,
    "total_runtime": 0.0004260540008544922
  },
  {
    "task_id": "HumanEval_2.py",
    "status": "success",
    "cpu_usage": 130.23880717837838,
    "kernel_usage": 4.069962724324324,
    "cpu_runtime": 2.2978000000000003e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_3.py",
    "status": "success",
    "cpu_usage": 166.6753607187166,
    "kernel_usage": 5.208605022459894,
    "cpu_runtime": 7.431100000000001e-05,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_4.py",
    "status": "success",
    "cpu_usage": 285.02403196836906,
    "kernel_usage": 8.907000999011533,
    "cpu_runtime": 0.000412487,
    "total_runtime": 0.00014472007751464844
  },
  {
    "task_id": "HumanEval_7.py",
    "status": "success",
    "cpu_usage": 187.1694997958159,
    "kernel_usage": 5.849046868619247,
    "cpu_runtime": 0.00010665300000000001,
    "total_runtime": 5.698204040527344e-05
  },
  {
    "task_id": "HumanEval_8.py",
    "status": "success",
    "cpu_usage": 155.5726336,
    "kernel_usage": 4.8616448,
    "cpu_runtime": 4.7477e-05,
    "total_runtime": 3.0517578125e-05
  },
  {
    "task_id": "HumanEval_9.py",
    "status": "success",
    "cpu_usage": 216.57672689577464,
    "kernel_usage": 6.7680227154929575,
    "cpu_runtime": 0.000219969,
    "total_runtime": 0.00010156631469726562
  },
  {
    "task_id": "HumanEval_10.py",
    "status": "success",
    "cpu_usage": 213.8026427515924,
    "kernel_usage": 6.6813325859872625,
    "cpu_runtime": 0.00016006000000000004,
    "total_runtime": 7.486343383789062e-05
  },
  {
    "task_id": "HumanEval_11.py",
    "status": "success",
    "cpu_usage": 210.2712172449568,
    "kernel_usage": 6.5709755389049,
    "cpu_runtime": 0.00017396000000000002,
    "total_runtime": 8.273124694824219e-05
  },
  {
    "task_id": "HumanEval_12.py",
    "status": "success",
    "cpu_usage": 209.57718230427355,
    "kernel_usage": 6.549286947008548,
    "cpu_runtime": 0.000116923,
    "total_runtime": 5.5789947509765625e-05
  },
  {
    "task_id": "HumanEval_13.py",
    "status": "success",
    "cpu_usage": 169.41078215593222,
    "kernel_usage": 5.294086942372882,
    "cpu_runtime": 4.7661e-05,
    "total_runtime": 2.8133392333984375e-05
  },
  {
    "task_id": "HumanEval_14.py",
    "status": "success",
    "cpu_usage": 197.82348416479402,
    "kernel_usage": 6.181983880149813,
    "cpu_runtime": 0.00012593,
    "total_runtime": 6.365776062011719e-05
  },
  {
    "task_id": "HumanEval_15.py",
    "status": "success",
    "cpu_usage": 185.3827420786026,
    "kernel_usage": 5.793210689956331,
    "cpu_runtime": 0.000101215,
    "total_runtime": 5.459785461425781e-05
  },
  {
    "task_id": "HumanEval_16.py",
    "status": "success",
    "cpu_usage": 220.6902954666667,
    "kernel_usage": 6.896571733333334,
    "cpu_runtime": 0.00039462500000000006,
    "total_runtime": 0.00017881393432617188
  },
  {
    "task_id": "HumanEval_18.py",
    "status": "success",
    "cpu_usage": 209.05648501171368,
    "kernel_usage": 6.533015156616052,
    "cpu_runtime": 0.00022977600000000003,
    "total_runtime": 0.00010991096496582031
  },
  {
    "task_id": "HumanEval_19.py",
    "status": "success",
    "cpu_usage": 257.0145215525926,
    "kernel_usage": 8.03170379851852,
    "cpu_runtime": 0.0005790680000000001,
    "total_runtime": 0.00022530555725097656
  },
  {
    "task_id": "HumanEval_20.py",
    "status": "success",
    "cpu_usage": 215.90643368219838,
    "kernel_usage": 6.7470760525686995,
    "cpu_runtime": 0.0012925650000000003,
    "total_runtime": 0.0005986690521240234
  },
  {
    "task_id": "HumanEval_21.py",
    "status": "success",
    "cpu_usage": 224.65801062988504,
    "kernel_usage": 7.0205628321839075,
    "cpu_runtime": 0.00027959699999999997,
    "total_runtime": 0.00012445449829101562
  },
  {
    "task_id": "HumanEval_22.py",
    "status": "success",
    "cpu_usage": 207.76683243243244,
    "kernel_usage": 6.492713513513514,
    "cpu_runtime": 0.000146625,
    "total_runtime": 7.05718994140625e-05
  },
  {
    "task_id": "HumanEval_23.py",
    "status": "success",
    "cpu_usage": 158.17842803380285,
    "kernel_usage": 4.943075876056339,
    "cpu_runtime": 2.6776000000000006e-05,
    "total_runtime": 1.6927719116210938e-05
  },
  {
    "task_id": "HumanEval_24.py",
    "status": "success",
    "cpu_usage": 188.91957016774197,
    "kernel_usage": 5.9037365677419364,
    "cpu_runtime": 0.00018151900000000002,
    "total_runtime": 9.608268737792969e-05
  },
  {
    "task_id": "HumanEval_25.py",
    "status": "success",
    "cpu_usage": 196.5677443236782,
    "kernel_usage": 6.142742010114944,
    "cpu_runtime": 0.00040772900000000007,
    "total_runtime": 0.00020742416381835938
  },
  {
    "task_id": "HumanEval_27.py",
    "status": "success",
    "cpu_usage": 226.3010078312878,
    "kernel_usage": 7.0719064947277435,
    "cpu_runtime": 0.0006242519999999999,
    "total_runtime": 0.0002758502960205078
  },
  {
    "task_id": "HumanEval_28.py",
    "status": "success",
    "cpu_usage": 152.72893065365855,
    "kernel_usage": 4.77277908292683,
    "cpu_runtime": 2.9859000000000003e-05,
    "total_runtime": 1.9550323486328125e-05
  },
  {
    "task_id": "HumanEval_29.py",
    "status": "success",
    "cpu_usage": 213.07274035199998,
    "kernel_usage": 6.6585231359999995,
    "cpu_runtime": 0.000101601,
    "total_runtime": 4.76837158203125e-05
  },
  {
    "task_id": "HumanEval_30.py",
    "status": "success",
    "cpu_usage": 207.8380770622951,
    "kernel_usage": 6.494939908196722,
    "cpu_runtime": 9.068100000000001e-05,
    "total_runtime": 4.363059997558594e-05
  },
  {
    "task_id": "HumanEval_31.py",
    "status": "success",
    "cpu_usage": 199.75774491380517,
    "kernel_usage": 6.2424295285564115,
    "cpu_runtime": 0.019481398,
    "total_runtime": 0.009752511978149414
  },
  {
    "task_id": "HumanEval_32.py",
    "status": "success",
    "cpu_usage": 366.45869797594327,
    "kernel_usage": 11.451834311748227,
    "cpu_runtime": 1.04539227,
    "total_runtime": 0.28526878356933594
  },
  {
    "task_id": "HumanEval_34.py",
    "status": "success",
    "cpu_usage": 176.0668656716418,
    "kernel_usage": 5.5020895522388065,
    "cpu_runtime": 2.8125000000000003e-05,
    "total_runtime": 1.5974044799804688e-05
  },
  {
    "task_id": "HumanEval_35.py",
    "status": "success",
    "cpu_usage": 192.19547883243246,
    "kernel_usage": 6.006108713513514,
    "cpu_runtime": 3.3909000000000003e-05,
    "total_runtime": 1.7642974853515625e-05
  },
  {
    "task_id": "HumanEval_37.py",
    "status": "success",
    "cpu_usage": 215.6166672587473,
    "kernel_usage": 6.738020851835853,
    "cpu_runtime": 0.00047602900000000005,
    "total_runtime": 0.00022077560424804688
  },
  {
    "task_id": "HumanEval_38.py",
    "status": "success",
    "cpu_usage": 367.55208521333844,
    "kernel_usage": 11.486002662916826,
    "cpu_runtime": 0.193809645,
    "total_runtime": 0.05272984504699707
  },
  {
    "task_id": "HumanEval_40.py",
    "status": "success",
    "cpu_usage": 213.51513390691827,
    "kernel_usage": 6.672347934591196,
    "cpu_runtime": 0.000809405,
    "total_runtime": 0.0003790855407714844
  },
  {
    "task_id": "HumanEval_41.py",
    "status": "success",
    "cpu_usage": 167.56879980606064,
    "kernel_usage": 5.236524993939395,
    "cpu_runtime": 5.2736000000000005e-05,
    "total_runtime": 3.147125244140625e-05
  },
  {
    "task_id": "HumanEval_42.py",
    "status": "success",
    "cpu_usage": 199.86466430144932,
    "kernel_usage": 6.245770759420291,
    "cpu_runtime": 6.575900000000002e-05,
    "total_runtime": 3.2901763916015625e-05
  },
  {
    "task_id": "HumanEval_43.py",
    "status": "success",
    "cpu_usage": 209.27753349565216,
    "kernel_usage": 6.53992292173913,
    "cpu_runtime": 0.0005738,
    "total_runtime": 0.0002741813659667969
  },
  {
    "task_id": "HumanEval_44.py",
    "status": "success",
    "cpu_usage": 170.70977674034418,
    "kernel_usage": 5.334680523135756,
    "cpu_runtime": 0.000212863,
    "total_runtime": 0.0001246929168701172
  },
  {
    "task_id": "HumanEval_45.py",
    "status": "success",
    "cpu_usage": 136.62722178723405,
    "kernel_usage": 4.269600680851064,
    "cpu_runtime": 1.531e-05,
    "total_runtime": 1.1205673217773438e-05
  },
  {
    "task_id": "HumanEval_46.py",
    "status": "success",
    "cpu_usage": 216.61162531689007,
    "kernel_usage": 6.769113291152815,
    "cpu_runtime": 0.000385266,
    "total_runtime": 0.00017786026000976562
  },
  {
    "task_id": "HumanEval_47.py",
    "status": "success",
    "cpu_usage": 209.05173736727272,
    "kernel_usage": 6.5328667927272726,
    "cpu_runtime": 0.000164478,
    "total_runtime": 7.867813110351562e-05
  },
  {
    "task_id": "HumanEval_48.py",
    "status": "success",
    "cpu_usage": 202.36498765048543,
    "kernel_usage": 6.32390586407767,
    "cpu_runtime": 0.00019878,
    "total_runtime": 9.822845458984375e-05
  },
  {
    "task_id": "HumanEval_49.py",
    "status": "success",
    "cpu_usage": 198.28927313448088,
    "kernel_usage": 6.1965397854525275,
    "cpu_runtime": 0.0017028760000000003,
    "total_runtime": 0.0008587837219238281
  },
  {
    "task_id": "HumanEval_50.py",
    "status": "success",
    "cpu_usage": 361.8785210054172,
    "kernel_usage": 11.308703781419288,
    "cpu_runtime": 0.250272541,
    "total_runtime": 0.06915926933288574
  },
  {
    "task_id": "HumanEval_51.py",
    "status": "success",
    "cpu_usage": 275.0991337835498,
    "kernel_usage": 8.596847930735931,
    "cpu_runtime": 0.0006060400000000001,
    "total_runtime": 0.00022029876708984375
  },
  {
    "task_id": "HumanEval_52.py",
    "status": "success",
    "cpu_usage": 155.22317251764707,
    "kernel_usage": 4.850724141176471,
    "cpu_runtime": 5.0331e-05,
    "total_runtime": 3.24249267578125e-05
  },
  {
    "task_id": "HumanEval_53.py",
    "status": "success",
    "cpu_usage": 299.34170891684124,
    "kernel_usage": 9.354428403651289,
    "cpu_runtime": 0.017044255000000005,
    "total_runtime": 0.005693912506103516
  },
  {
    "task_id": "HumanEval_54.py",
    "status": "success",
    "cpu_usage": 178.81613251764708,
    "kernel_usage": 5.588004141176471,
    "cpu_runtime": 0.00011596200000000001,
    "total_runtime": 6.4849853515625e-05
  },
  {
    "task_id": "HumanEval_55.py",
    "status": "success",
    "cpu_usage": 199.6177825617399,
    "kernel_usage": 6.2380557050543715,
    "cpu_runtime": 0.005470768,
    "total_runtime": 0.002740621566772461
  },
  {
    "task_id": "HumanEval_56.py",
    "status": "success",
    "cpu_usage": 186.62466843517916,
    "kernel_usage": 5.832020888599349,
    "cpu_runtime": 0.000273198,
    "total_runtime": 0.00014638900756835938
  },
  {
    "task_id": "HumanEval_57.py",
    "status": "success",
    "cpu_usage": 209.26359738181816,
    "kernel_usage": 6.5394874181818174,
    "cpu_runtime": 0.000175621,
    "total_runtime": 8.392333984375e-05
  },
  {
    "task_id": "HumanEval_58.py",
    "status": "success",
    "cpu_usage": 198.24777702101167,
    "kernel_usage": 6.195243031906615,
    "cpu_runtime": 0.000242947,
    "total_runtime": 0.00012254714965820312
  },
  {
    "task_id": "HumanEval_60.py",
    "status": "success",
    "cpu_usage": 188.6696628705883,
    "kernel_usage": 5.895926964705884,
    "cpu_runtime": 0.00017588100000000005,
    "total_runtime": 9.322166442871094e-05
  },
  {
    "task_id": "HumanEval_61.py",
    "status": "success",
    "cpu_usage": 185.35724440591136,
    "kernel_usage": 5.79241388768473,
    "cpu_runtime": 0.000269133,
    "total_runtime": 0.00014519691467285156
  },
  {
    "task_id": "HumanEval_62.py",
    "status": "success",
    "cpu_usage": 189.03172256385542,
    "kernel_usage": 5.907241330120482,
    "cpu_runtime": 0.000149628,
    "total_runtime": 7.915496826171875e-05
  },
  {
    "task_id": "HumanEval_63.py",
    "status": "success",
    "cpu_usage": 217.2558367652465,
    "kernel_usage": 6.789244898913953,
    "cpu_runtime": 0.0006200200000000001,
    "total_runtime": 0.0002853870391845703
  },
  {
    "task_id": "HumanEval_65.py",
    "status": "success",
    "cpu_usage": 193.4597950488189,
    "kernel_usage": 6.045618595275591,
    "cpu_runtime": 0.00011715600000000001,
    "total_runtime": 6.0558319091796875e-05
  },
  {
    "task_id": "HumanEval_66.py",
    "status": "success",
    "cpu_usage": 363.72379402979686,
    "kernel_usage": 11.366368563431152,
    "cpu_runtime": 0.0015366520000000001,
    "total_runtime": 0.00042247772216796875
  },
  {
    "task_id": "HumanEval_67.py",
    "status": "success",
    "cpu_usage": 220.86081389714286,
    "kernel_usage": 6.901900434285714,
    "cpu_runtime": 0.000589762,
    "total_runtime": 0.00026702880859375
  },
  {
    "task_id": "HumanEval_68.py",
    "status": "success",
    "cpu_usage": 220.67273311001645,
    "kernel_usage": 6.896022909688014,
    "cpu_runtime": 0.0006408200000000001,
    "total_runtime": 0.0002903938293457031
  },
  {
    "task_id": "HumanEval_70.py",
    "status": "success",
    "cpu_usage": 234.66662443986257,
    "kernel_usage": 7.333332013745705,
    "cpu_runtime": 0.0013024900000000001,
    "total_runtime": 0.0005550384521484375
  },
  {
    "task_id": "HumanEval_71.py",
    "status": "success",
    "cpu_usage": 200.48439355755966,
    "kernel_usage": 6.265137298673739,
    "cpu_runtime": 0.00018020299999999998,
    "total_runtime": 8.988380432128906e-05
  },
  {
    "task_id": "HumanEval_73.py",
    "status": "success",
    "cpu_usage": 196.29001025173122,
    "kernel_usage": 6.1340628203666006,
    "cpu_runtime": 0.00022978400000000005,
    "total_runtime": 0.00011706352233886719
  },
  {
    "task_id": "HumanEval_74.py",
    "status": "success",
    "cpu_usage": 194.0155511497307,
    "kernel_usage": 6.062985973429084,
    "cpu_runtime": 0.000257651,
    "total_runtime": 0.0001327991485595703
  },
  {
    "task_id": "HumanEval_76.py",
    "status": "success",
    "cpu_usage": 180.44332525119307,
    "kernel_usage": 5.6388539140997835,
    "cpu_runtime": 0.00019832700000000004,
    "total_runtime": 0.00010991096496582031
  },
  {
    "task_id": "HumanEval_78.py",
    "status": "success",
    "cpu_usage": 193.95119900634393,
    "kernel_usage": 6.060974968948248,
    "cpu_runtime": 0.000276987,
    "total_runtime": 0.00014281272888183594
  },
  {
    "task_id": "HumanEval_80.py",
    "status": "success",
    "cpu_usage": 195.3411139147541,
    "kernel_usage": 6.104409809836065,
    "cpu_runtime": 0.00022727599999999997,
    "total_runtime": 0.0001163482666015625
  },
  {
    "task_id": "HumanEval_81.py",
    "status": "success",
    "cpu_usage": 194.19627520000006,
    "kernel_usage": 6.068633600000002,
    "cpu_runtime": 0.00023983400000000005,
    "total_runtime": 0.00012350082397460938
  },
  {
    "task_id": "HumanEval_82.py",
    "status": "success",
    "cpu_usage": 186.03544775430714,
    "kernel_usage": 5.813607742322098,
    "cpu_runtime": 0.00023685200000000002,
    "total_runtime": 0.00012731552124023438
  },
  {
    "task_id": "HumanEval_83.py",
    "status": "success",
    "cpu_usage": 166.5709113344,
    "kernel_usage": 5.2053409792,
    "cpu_runtime": 4.9642000000000003e-05,
    "total_runtime": 2.9802322387695312e-05
  },
  {
    "task_id": "HumanEval_84.py",
    "status": "success",
    "cpu_usage": 283.8614868187919,
    "kernel_usage": 8.870671463087247,
    "cpu_runtime": 0.00040335999999999996,
    "total_runtime": 0.00014209747314453125
  },
  {
    "task_id": "HumanEval_85.py",
    "status": "success",
    "cpu_usage": 181.5819619935829,
    "kernel_usage": 5.674436312299465,
    "cpu_runtime": 8.0957e-05,
    "total_runtime": 4.458427429199219e-05
  },
  {
    "task_id": "HumanEval_86.py",
    "status": "success",
    "cpu_usage": 228.33908299188815,
    "kernel_usage": 7.135596343496505,
    "cpu_runtime": 0.000778496,
    "total_runtime": 0.0003409385681152344
  },
  {
    "task_id": "HumanEval_87.py",
    "status": "success",
    "cpu_usage": 243.9233986184846,
    "kernel_usage": 7.622606206827644,
    "cpu_runtime": 0.001396904,
    "total_runtime": 0.0005726814270019531
  },
  {
    "task_id": "HumanEval_88.py",
    "status": "success",
    "cpu_usage": 198.45484676129033,
    "kernel_usage": 6.201713961290323,
    "cpu_runtime": 0.000176013,
    "total_runtime": 8.869171142578125e-05
  },
  {
    "task_id": "HumanEval_89.py",
    "status": "success",
    "cpu_usage": 226.09571224721034,
    "kernel_usage": 7.065491007725323,
    "cpu_runtime": 0.0010047970000000002,
    "total_runtime": 0.0004444122314453125
  },
  {
    "task_id": "HumanEval_90.py",
    "status": "success",
    "cpu_usage": 205.9281689971015,
    "kernel_usage": 6.435255281159422,
    "cpu_runtime": 0.00020326200000000003,
    "total_runtime": 9.870529174804688e-05
  },
  {
    "task_id": "HumanEval_92.py",
    "status": "success",
    "cpu_usage": 197.72062415567567,
    "kernel_usage": 6.1787695048648645,
    "cpu_runtime": 0.00017441899999999998,
    "total_runtime": 8.821487426757812e-05
  },
  {
    "task_id": "HumanEval_93.py",
    "status": "success",
    "cpu_usage": 285.8492265766438,
    "kernel_usage": 8.932788330520118,
    "cpu_runtime": 0.001388933,
    "total_runtime": 0.0004858970642089844
  },
  {
    "task_id": "HumanEval_95.py",
    "status": "success",
    "cpu_usage": 213.35306261580612,
    "kernel_usage": 6.667283206743941,
    "cpu_runtime": 0.000482731,
    "total_runtime": 0.0002262592315673828
  },
  {
    "task_id": "HumanEval_96.py",
    "status": "success",
    "cpu_usage": 201.1457314130733,
    "kernel_usage": 6.28580410665854,
    "cpu_runtime": 0.0031474100000000002,
    "total_runtime": 0.0015647411346435547
  },
  {
    "task_id": "HumanEval_97.py",
    "status": "success",
    "cpu_usage": 192.44021640466926,
    "kernel_usage": 6.013756762645914,
    "cpu_runtime": 0.000117915,
    "total_runtime": 6.127357482910156e-05
  },
  {
    "task_id": "HumanEval_98.py",
    "status": "success",
    "cpu_usage": 185.98654192941177,
    "kernel_usage": 5.812079435294118,
    "cpu_runtime": 0.000120612,
    "total_runtime": 6.4849853515625e-05
  },
  {
    "task_id": "HumanEval_100.py",
    "status": "success",
    "cpu_usage": 214.77422009863014,
    "kernel_usage": 6.711694378082192,
    "cpu_runtime": 0.000149522,
    "total_runtime": 6.961822509765625e-05
  },
  {
    "task_id": "HumanEval_101.py",
    "status": "success",
    "cpu_usage": 222.51478920722195,
    "kernel_usage": 6.953587162725686,
    "cpu_runtime": 0.0009108970000000001,
    "total_runtime": 0.0004093647003173828
  },
  {
    "task_id": "HumanEval_102.py",
    "status": "success",
    "cpu_usage": 148.90819110082646,
    "kernel_usage": 4.653380971900827,
    "cpu_runtime": 4.2958000000000004e-05,
    "total_runtime": 2.8848648071289062e-05
  },
  {
    "task_id": "HumanEval_103.py",
    "status": "success",
    "cpu_usage": 200.23677168718183,
    "kernel_usage": 6.257399115224432,
    "cpu_runtime": 0.00206333,
    "total_runtime": 0.0010304450988769531
  },
  {
    "task_id": "HumanEval_104.py",
    "status": "success",
    "cpu_usage": 275.6723381785016,
    "kernel_usage": 8.614760568078175,
    "cpu_runtime": 0.001008885,
    "total_runtime": 0.00036597251892089844
  },
  {
    "task_id": "HumanEval_105.py",
    "status": "success",
    "cpu_usage": 204.84936507838313,
    "kernel_usage": 6.401542658699473,
    "cpu_runtime": 0.000277899,
    "total_runtime": 0.00013566017150878906
  },
  {
    "task_id": "HumanEval_106.py",
    "status": "success",
    "cpu_usage": 187.17662850554325,
    "kernel_usage": 5.8492696407982265,
    "cpu_runtime": 0.000201265,
    "total_runtime": 0.00010752677917480469
  },
  {
    "task_id": "HumanEval_107.py",
    "status": "success",
    "cpu_usage": 255.31380666840963,
    "kernel_usage": 7.978556458387801,
    "cpu_runtime": 0.004470407000000001,
    "total_runtime": 0.001750946044921875
  },
  {
    "task_id": "HumanEval_109.py",
    "status": "success",
    "cpu_usage": 221.8802485877958,
    "kernel_usage": 6.9337577683686185,
    "cpu_runtime": 0.00042479000000000003,
    "total_runtime": 0.0001914501190185547
  },
  {
    "task_id": "HumanEval_110.py",
    "status": "success",
    "cpu_usage": 175.91270487771433,
    "kernel_usage": 5.497272027428573,
    "cpu_runtime": 0.00014679300000000004,
    "total_runtime": 8.344650268554688e-05
  },
  {
    "task_id": "HumanEval_111.py",
    "status": "success",
    "cpu_usage": 220.95836249687738,
    "kernel_usage": 6.904948828027418,
    "cpu_runtime": 0.000691696,
    "total_runtime": 0.00031304359436035156
  },
  {
    "task_id": "HumanEval_112.py",
    "status": "success",
    "cpu_usage": 195.31722143274564,
    "kernel_usage": 6.103663169773301,
    "cpu_runtime": 0.00018487200000000004,
    "total_runtime": 9.465217590332031e-05
  },
  {
    "task_id": "HumanEval_113.py",
    "status": "success",
    "cpu_usage": 276.33179358778636,
    "kernel_usage": 8.635368549618324,
    "cpu_runtime": 0.0006904500000000002,
    "total_runtime": 0.0002498626708984375
  },
  {
    "task_id": "HumanEval_116.py",
    "status": "success",
    "cpu_usage": 372.0869654503046,
    "kernel_usage": 11.627717670322019,
    "cpu_runtime": 0.002038612,
    "total_runtime": 0.0005478858947753906
  },
  {
    "task_id": "HumanEval_117.py",
    "status": "success",
    "cpu_usage": 215.94229798158705,
    "kernel_usage": 6.748196811924595,
    "cpu_runtime": 0.0011743650000000001,
    "total_runtime": 0.0005438327789306641
  },
  {
    "task_id": "HumanEval_118.py",
    "status": "success",
    "cpu_usage": 184.29576692093025,
    "kernel_usage": 5.75924271627907,
    "cpu_runtime": 0.00028341000000000005,
    "total_runtime": 0.0001537799835205078
  },
  {
    "task_id": "HumanEval_120.py",
    "status": "success",
    "cpu_usage": 183.1769607144186,
    "kernel_usage": 5.724280022325582,
    "cpu_runtime": 0.000187793,
    "total_runtime": 0.00010251998901367188
  },
  {
    "task_id": "HumanEval_121.py",
    "status": "success",
    "cpu_usage": 184.50618262547422,
    "kernel_usage": 5.7658182070460695,
    "cpu_runtime": 0.00016232199999999998,
    "total_runtime": 8.797645568847656e-05
  },
  {
    "task_id": "HumanEval_122.py",
    "status": "success",
    "cpu_usage": 195.1175613771144,
    "kernel_usage": 6.097423793034825,
    "cpu_runtime": 0.000187009,
    "total_runtime": 9.584426879882812e-05
  },
  {
    "task_id": "HumanEval_124.py",
    "status": "success",
    "cpu_usage": 189.42350677333334,
    "kernel_usage": 5.919484586666667,
    "cpu_runtime": 0.000325167,
    "total_runtime": 0.000171661376953125
  },
  {
    "task_id": "HumanEval_125.py",
    "status": "success",
    "cpu_usage": 262.9185685489051,
    "kernel_usage": 8.216205267153285,
    "cpu_runtime": 0.000515268,
    "total_runtime": 0.00019598007202148438
  },
  {
    "task_id": "HumanEval_126.py",
    "status": "success",
    "cpu_usage": 191.70827912573444,
    "kernel_usage": 5.990883722679201,
    "cpu_runtime": 0.000388965,
    "total_runtime": 0.0002028942108154297
  },
  {
    "task_id": "HumanEval_128.py",
    "status": "success",
    "cpu_usage": 245.37204514787462,
    "kernel_usage": 7.667876410871082,
    "cpu_runtime": 0.0008394930000000001,
    "total_runtime": 0.0003421306610107422
  },
  {
    "task_id": "HumanEval_130.py",
    "status": "success",
    "cpu_usage": 199.69817595933284,
    "kernel_usage": 6.240567998729151,
    "cpu_runtime": 0.0005994320000000001,
    "total_runtime": 0.0003001689910888672
  },
  {
    "task_id": "HumanEval_131.py",
    "status": "success",
    "cpu_usage": 185.3532008477327,
    "kernel_usage": 5.792287526491647,
    "cpu_runtime": 0.00018516300000000002,
    "total_runtime": 9.989738464355469e-05
  },
  {
    "task_id": "HumanEval_135.py",
    "status": "success",
    "cpu_usage": 182.96706131502145,
    "kernel_usage": 5.71772066609442,
    "cpu_runtime": 0.000101641,
    "total_runtime": 5.555152893066406e-05
  },
  {
    "task_id": "HumanEval_136.py",
    "status": "success",
    "cpu_usage": 175.37972990946503,
    "kernel_usage": 5.480616559670782,
    "cpu_runtime": 0.000203215,
    "total_runtime": 0.00011587142944335938
  },
  {
    "task_id": "HumanEval_138.py",
    "status": "success",
    "cpu_usage": 199.95451009431505,
    "kernel_usage": 6.2485784404473455,
    "cpu_runtime": 0.07881803300000001,
    "total_runtime": 0.03941798210144043
  },
  {
    "task_id": "HumanEval_139.py",
    "status": "success",
    "cpu_usage": 174.30559507692308,
    "kernel_usage": 5.447049846153846,
    "cpu_runtime": 6.483e-05,
    "total_runtime": 3.719329833984375e-05
  },
  {
    "task_id": "HumanEval_140.py",
    "status": "success",
    "cpu_usage": 211.11793239428897,
    "kernel_usage": 6.59743538732153,
    "cpu_runtime": 0.000881356,
    "total_runtime": 0.00041747093200683594
  },
  {
    "task_id": "HumanEval_141.py",
    "status": "success",
    "cpu_usage": 244.4957923242872,
    "kernel_usage": 7.640493510133975,
    "cpu_runtime": 0.0016968900000000002,
    "total_runtime": 0.0006940364837646484
  },
  {
    "task_id": "HumanEval_142.py",
    "status": "success",
    "cpu_usage": 210.48988846217873,
    "kernel_usage": 6.577809014443085,
    "cpu_runtime": 0.001230027,
    "total_runtime": 0.0005843639373779297
  },
  {
    "task_id": "HumanEval_143.py",
    "status": "success",
    "cpu_usage": 221.0635317391877,
    "kernel_usage": 6.908235366849616,
    "cpu_runtime": 0.000960297,
    "total_runtime": 0.0004343986511230469
  },
  {
    "task_id": "HumanEval_144.py",
    "status": "success",
    "cpu_usage": 201.26183783298245,
    "kernel_usage": 6.289432432280702,
    "cpu_runtime": 0.000410268,
    "total_runtime": 0.00020384788513183594
  },
  {
    "task_id": "HumanEval_145.py",
    "status": "success",
    "cpu_usage": 400.512195427582,
    "kernel_usage": 12.516006107111938,
    "cpu_runtime": 0.0030881320000000004,
    "total_runtime": 0.0007710456848144531
  },
  {
    "task_id": "HumanEval_146.py",
    "status": "success",
    "cpu_usage": 183.5034546227848,
    "kernel_usage": 5.734482956962025,
    "cpu_runtime": 0.000207378,
    "total_runtime": 0.00011301040649414062
  },
  {
    "task_id": "HumanEval_147.py",
    "status": "success",
    "cpu_usage": 201.2145186646361,
    "kernel_usage": 6.287953708269878,
    "cpu_runtime": 0.5777182200000001,
    "total_runtime": 0.28711557388305664
  },
  {
    "task_id": "HumanEval_148.py",
    "status": "success",
    "cpu_usage": 195.5371619249231,
    "kernel_usage": 6.110536310153847,
    "cpu_runtime": 0.00015151400000000003,
    "total_runtime": 7.748603820800781e-05
  },
  {
    "task_id": "HumanEval_149.py",
    "status": "success",
    "cpu_usage": 219.47912967820778,
    "kernel_usage": 6.858722802443993,
    "cpu_runtime": 0.0005138600000000001,
    "total_runtime": 0.00023412704467773438
  },
  {
    "task_id": "HumanEval_150.py",
    "status": "success",
    "cpu_usage": 199.6817460876818,
    "kernel_usage": 6.240054565240056,
    "cpu_runtime": 0.012603223,
    "total_runtime": 0.006311655044555664
  },
  {
    "task_id": "HumanEval_151.py",
    "status": "success",
    "cpu_usage": 193.54599100519573,
    "kernel_usage": 6.048312218912367,
    "cpu_runtime": 0.0013322050000000002,
    "total_runtime": 0.0006883144378662109
  },
  {
    "task_id": "HumanEval_152.py",
    "status": "success",
    "cpu_usage": 256.5620566494332,
    "kernel_usage": 8.017564270294788,
    "cpu_runtime": 0.00026975600000000006,
    "total_runtime": 0.00010514259338378906
  },
  {
    "task_id": "HumanEval_153.py",
    "status": "success",
    "cpu_usage": 300.7358360772016,
    "kernel_usage": 9.39799487741255,
    "cpu_runtime": 0.008158141,
    "total_runtime": 0.002712726593017578
  },
  {
    "task_id": "HumanEval_155.py",
    "status": "success",
    "cpu_usage": 190.8190651528942,
    "kernel_usage": 5.963095786027944,
    "cpu_runtime": 0.000227929,
    "total_runtime": 0.00011944770812988281
  },
  {
    "task_id": "HumanEval_156.py",
    "status": "success",
    "cpu_usage": 186.15950115508588,
    "kernel_usage": 5.817484411096434,
    "cpu_runtime": 0.00033598600000000003,
    "total_runtime": 0.0001804828643798828
  },
  {
    "task_id": "HumanEval_157.py",
    "status": "success",
    "cpu_usage": 192.34582453527273,
    "kernel_usage": 6.010807016727273,
    "cpu_runtime": 0.000504447,
    "total_runtime": 0.00026226043701171875
  },
  {
    "task_id": "HumanEval_158.py",
    "status": "success",
    "cpu_usage": 211.81592162042554,
    "kernel_usage": 6.619247550638298,
    "cpu_runtime": 0.000830739,
    "total_runtime": 0.0003921985626220703
  },
  {
    "task_id": "HumanEval_159.py",
    "status": "success",
    "cpu_usage": 138.83520731428573,
    "kernel_usage": 4.338600228571429,
    "cpu_runtime": 3.7073e-05,
    "total_runtime": 2.6702880859375e-05
  },
  {
    "task_id": "HumanEval_160.py",
    "status": "success",
    "cpu_usage": 272.0330955420876,
    "kernel_usage": 8.501034235690238,
    "cpu_runtime": 0.0007705100000000001,
    "total_runtime": 0.00028324127197265625
  },
  {
    "task_id": "HumanEval_161.py",
    "status": "success",
    "cpu_usage": 212.35402844623115,
    "kernel_usage": 6.636063388944724,
    "cpu_runtime": 0.0006045120000000001,
    "total_runtime": 0.0002846717834472656
  },
  {
    "task_id": "HumanEval_162.py",
    "status": "success",
    "cpu_usage": 225.68186031901845,
    "kernel_usage": 7.052558134969327,
    "cpu_runtime": 0.00017541000000000003,
    "total_runtime": 7.772445678710938e-05
  }
]